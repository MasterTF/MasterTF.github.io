<?xml version="1.0" encoding="utf-8"?>
<search>
  <entry>
    <title>架构设计方法概述</title>
    <url>/2019/12/25/%E6%9E%B6%E6%9E%84%E8%AE%BE%E8%AE%A1%E6%96%B9%E6%B3%95%E6%A6%82%E8%BF%B0/</url>
    <content><![CDATA[<p>尝试用“说人话”的方式讲清楚架构设计方法。<br>如果你之前看过其他架构文章，emmm…..先忘了它</p>
<h2 id="什么是架构"><a href="#什么是架构" class="headerlink" title="什么是架构"></a>什么是架构</h2><p>对架构是否有以下疑问：</p>
<ul>
<li>成天说的架构是在说什么？</li>
<li>面试让画架构图该画什么？</li>
<li>我知道这个东西很重要，但就是不知道怎么存在？</li>
<li>什么是好的架构？</li>
<li>如何做架构设计？</li>
<li>知道有架构师岗位，他们在做什么？</li>
<li>看到过一些文章，XXX高可用架构，XXX高性能实践，XXX架构演进，怎么说的都不一样？</li>
<li>。。。欢迎补充</li>
</ul>
<a id="more"></a>
<p>“架构”这个东西不仅存在于软件领域，日常生活中随处可见！软件系统中的“架构”可能抽象了些产生上述各种疑问。</p>
<p>在谈论什么是架构之前，先看下架构如何产生的会更合适，网上有篇文章说的比较好，我摘下：</p>
<blockquote>
<p><a href="https://www.infoq.cn/article/an-informal-discussion-on-architecture-part01" target="_blank" rel="noopener">https://www.infoq.cn/article/an-informal-discussion-on-architecture-part01</a><br>总结一下，什么是架构，就是：</p>
<ol>
<li>根据要解决的问题，对目标系统的边界进行界定。</li>
<li>并对目标系统按某个原则的进行切分。切分的原则，要便于不同的角色，对切分出来的部分，并行或串行开展工作，一般并行才能减少时间。</li>
<li>并对这些切分出来的部分，设立沟通机制。</li>
<li>根据 3，使得这些部分之间能够进行有机的联系，合并组装成为一个整体，完成目标系统的所有工作。</li>
</ol>
</blockquote>
<p><strong>说人话：解决问题的方式就是架构！！</strong></p>
<p>生活中的例子：</p>
<ul>
<li>公司层面：组织架构 -&gt; 解决字节跳动整个公司的问题</li>
<li>国家层面：政府机构 -&gt; 解决整个国家面临的问题</li>
<li>学科层面：生物分类 -&gt; 解决XXX问题</li>
</ul>
<p>回到软件领域，看看我们用了哪些东西解决问题。这些“东西”组成了架构，可能包括了 服务、存储、机器、协议 等。这就是架构，它看起来可能长下面👇这个样子：<br><img src="/img/15772630513056.jpg" alt></p>
<p>画的简单了些，但基本描述了我们解决问题的方式：<br>客户端：解决用户触达问题<br>api层：解决与客户端通信问题<br>服务层：解决数据读写问题<br>存储层：解决数据存储问题<br>基础组件：解决可用性、性能、统计 等问题。</p>
<h2 id="架构挑战"><a href="#架构挑战" class="headerlink" title="架构挑战"></a>架构挑战</h2><h3 id="业务"><a href="#业务" class="headerlink" title="业务"></a>业务</h3><ul>
<li>初期：探索阶段，业务策略不明确，需求变化快</li>
<li>中期：快速增长阶段，功能多，越来越复杂</li>
</ul>
<h3 id="技术"><a href="#技术" class="headerlink" title="技术"></a>技术</h3><ul>
<li>可用性</li>
<li>性能</li>
<li>扩展性</li>
<li>安全</li>
<li>正确性（幂等、一致性、业务逻辑等）<br>上面列的每一个点，都足以展开专项讲解。网上的一些架构文章通常离不开这几个方面：怎么达到4个9，怎么做故障恢复，监控怎么做，性能怎么保障，安全策略 等等等。</li>
</ul>
<p>技术架构可以通过架构五视图(架构五视图就不展开说明了)表达：</p>
<ul>
<li>逻辑架构</li>
<li>数据架构</li>
<li>运行架构</li>
<li>部署架构</li>
<li>开发架构</li>
</ul>
<p>技术维度的好坏可以评估：可用性几个9，性能多少，吞吐量多少，是否有安全问题等。</p>
<h3 id="团队"><a href="#团队" class="headerlink" title="团队"></a>团队</h3><ul>
<li>组织结构：团队职责划分、职责边界以及 及时调整组织结构。</li>
<li>人员分工：人员技能、兴趣、发展空间。</li>
</ul>
<h2 id="解决方法"><a href="#解决方法" class="headerlink" title="解决方法"></a>解决方法</h2><h3 id="目标"><a href="#目标" class="headerlink" title="目标"></a>目标</h3><p>降低复杂度、快速响应(应对变化)、风险可控</p>
<h3 id="分治"><a href="#分治" class="headerlink" title="分治"></a>分治</h3><p><strong>说人话：将大的问题拆成小的问题，逐个解决。</strong></p>
<p>拿前面管理国家例子作说明：<br>管理国家的问题域，将问题分解，建立相应政府机构：<br><img src="/img/15772632135617.jpg" alt></p>
<ul>
<li>每个政府机构解决自己领域擅长内的问题 -&gt; 复杂度降低；专业人做专业事情 -&gt; 高效。</li>
<li>需要办事、政策调整 找到相应机构即可  -&gt; 边界清晰。</li>
<li>某个机构出了问题对其他机构影响较小 -&gt; 风险可控。</li>
</ul>
<p>以上三点很好的说明了”高内聚、低耦合”系统的特点。<br>顺便提一下，耦合是必然的，因为单独模块完成不了全部功能。要做到的是尽可能降低耦合。</p>
<h3 id="抽象"><a href="#抽象" class="headerlink" title="抽象"></a>抽象</h3><p><strong>说人话：逐级分类整理。</strong></p>
<p>分治好像已经解决了所有问题为什么还需要抽象？因为上面的例子已经做了抽象。</p>
<p>将问题拆解，得到的可能是膨胀的问题域，相应的解决方案也会膨胀。需要对问题域进行归纳总结。<br>继续拿国家举例子，问题域可能有这些：</p>
<ul>
<li>足球如何发展</li>
<li>流行歌曲发展方向</li>
<li>会计标准是否要改</li>
<li>铁矿石进口量</li>
<li>小麦增收</li>
<li>养老金和退休政策如何制定</li>
<li>要不要再建个水电站</li>
<li>药品定价</li>
<li>等等等等等等<br>如果任由问题域膨胀，不做梳理，问题域依然复杂。所以需要对问题进行抽象，统一管理，让“专业人做专业事情”。</li>
<li>足球、体操、游泳 怎么抽象? -&gt; 体育</li>
<li>国画、芭蕾、钢琴 怎么抽象? -&gt; 艺术</li>
<li>体育、艺术、音乐 怎么抽象? -&gt; 文化</li>
</ul>
<p>抽象可以很好地将问题收敛，做到“高内聚”。<br>上面国务院政府机构图已经是对所有问题域高度抽象后的表示，每个政府机构还可以拆解成很多层。</p>
<h4 id="如何抽象"><a href="#如何抽象" class="headerlink" title="如何抽象"></a>如何抽象</h4><ul>
<li>有最佳实践按照最佳实践。如政府机构设置，都发展上千年了，大的框架不会变，照着弄就行。</li>
<li>从未接触过的问题域：从下到上，将问题不重不漏列出来，做归纳总结。举个例子：生物分类，人类一开始不可能知道全部生物，随着知道的生物越多，归纳总结出一套分类方法：<br><img src="/img/15772632971263.jpg" alt></li>
</ul>
<ul>
<li>说人话：没有对错，团队讨论达成一致就行，你说这样抽象那就这样抽象。 比如图书分类，一本书既是传记又是历史，但只能把他放到一个架子上，放哪个都说得通。这种情况需要让子弹飞一会儿，对业务有了更深理解后再去看如何调整。所以业务初期的方案满足当下需求就好，预估变化做预案，不需要实现，一旦发生变化能及时调整。<h3 id="迭代演进"><a href="#迭代演进" class="headerlink" title="迭代演进"></a>迭代演进</h3><strong>说人话：不可能一次做“对”，后续可以改。</strong></li>
</ul>
<p>架构设计不可能一蹴而就，也不可能一套方案能够应对后面所有变化。<br>或许经常看到以下新闻：</p>
<ul>
<li>某某政府机构撤销、合并</li>
<li>XXX公司组织结构升级</li>
<li>养老金&amp;退休政策调整</li>
<li>XXXX的发现可能推翻现有科学体系</li>
</ul>
<p>调整原因大部分是面临的问题域发生了变化，原有的架构不能满足。<br>同样，软件架构体系也需要迭代演进。若不调整，可能出现各种各样的问题，表现可能是：</p>
<ul>
<li>业务出错变多</li>
<li>性能变差</li>
<li>可用性降低</li>
<li>迭代变慢</li>
<li>人员流失 </li>
<li>等等等等。</li>
</ul>
<p>同理，软件架构的迭代演进可能是理解上的演进，也可能是架构的演进，需要 移动、合并、分解、新增等。<br><img src="/img/15772633736611.jpg" alt><br>讲个段子：<br>员工造了轮子，兴奋地跟老板说“我造了几个轮子，可牛X了，能解决XXXX问题，给我升职加薪！”<br>老板：好。<br>过段时间。<br>员工：“我融合掉了好几个轮子，节省了很多开销，给我升职加薪！”<br>老板内心os：“你tm逗我呢”</p>
<p>这里解释下“理解上的演进”:</p>
<blockquote>
<p>冲突不在于客观事实本身，而在于人们的思考方式上。</p>
</blockquote>
<p>同一事实，看问题的角度不同，得到的结果也不同。</p>
<ul>
<li>应该都听过三个工人立墙的故事。一个人认为就是在立一面墙，一个人认为是在造一栋楼，一个人认为是在造一座城。</li>
<li>再比如“写单测”。刚毕业同学可能认为没必要，多此一举；服务负责人认为是提升代码质量；项目负责人认为是“提升服务可用性”；换一个党员来看，可能认为在建设美好社会主义😆。<h4 id="在什么时间点调整"><a href="#在什么时间点调整" class="headerlink" title="在什么时间点调整"></a>在什么时间点调整</h4>可参考《重构》里提到的代码重构时机。</li>
</ul>
<ol>
<li>当前版本调整：已经识别到此次需求需要调整架构，那么当前版本不仅要完成产品需求，还要完成技术改造。</li>
<li>发生case时：找到case的根本原因，使用长期方案解决问题。短期方案是头痛医头，脚痛医脚。长期方案若需要对架构进行调整，不要担心成本大，果断执行，长期看收益还是值得的。</li>
<li>专门的调整：某些问题已经很严重，单独的项目来做。</li>
</ol>
<h2 id="如何落地"><a href="#如何落地" class="headerlink" title="如何落地"></a>如何落地</h2><h3 id="业务-1"><a href="#业务-1" class="headerlink" title="业务"></a>业务</h3><p>DDD: 领域、限界上下文划分对服务化做了很好的指导。(不展开讲DDD,简单理解为面向对象的升级。)<br>比如供应链领域业务划分：</p>
<ul>
<li>核心域：系统的核心价值所在，承载着一个系统的重中之重。</li>
<li>支撑域：专注于业务系统某一重要业务，支撑和完善业务系统。</li>
<li>通用域：提供通用服务。<br><img src="/img/15772634271371.jpg" alt></li>
</ul>
<p>每个虚线圈是一个子领域，每个实线圈是一个限界上下文。</p>
<ul>
<li>一个服务 &lt;= 一个领域，避免服务内领域歧义</li>
<li><p>一个服务 &gt;= 一个聚合，避免分布式事务。<br>按照上图的划分，技术架构应该有订单域、商品域等，里面会有订单服务、商品服务等，通过业务就能知道一些服务，技术架构也要体现业务含义。</p>
</li>
<li><p>虚线最重要的意义在于 合理划分边界，为后面的“高内聚、低耦合”打下基础。<br>细胞之所以会存在，是细胞膜定义了什么在细胞内，什么在细胞外，并且确定了什么物质可以通过细胞膜。</p>
<ul>
<li>业务架构没有量化指标看好坏，谁也不能确定业务这样划分、这样做一定是最好的。不同人理解不一样，团队内部达成一致即可。需要注意的是，这里的“团队”不仅仅指的是技术团队，而是和业务相关的所有团队：产品、技术、运营、设计等。大家讨论得出结论即可。这个划分不是一成不变，后续随着业务调整，对业务理解加深，相应的术语、划分都需要调整。题外话，为什么招聘有时候要求“相关经验”? “相关经验”的人对问题域理解深刻，可以避免采坑，来回调整多伤。</li>
<li>这个大圈体现的是“供应链业务”，每个虚线圈还可以继续按照这种方式拆解：“供应链业务”就是从更大的圈中细化出来的。比如，“供应链业务”是在 “XX电商业务”的一个子域。想象有一个放大镜🔍，在电商业务看“供应链业务”就得到了这个圈。同样，“电商业务”可能是某个bg的子域，bg业务又是公司所有业务的一个子域。（ps:看到抽象了没）</li>
</ul>
</li>
</ul>
<h3 id="技术-1"><a href="#技术-1" class="headerlink" title="技术"></a>技术</h3><p>关注点分离。</p>
<ul>
<li>职责划分：功能维度，如优惠券场景，发券、领券等。</li>
<li>稳定通用：变&amp;不变分离，通用&amp;专用分离。分层架构：横切竖割，纵向分层，横向模块化。</li>
<li><p>技术维度</p>
<ul>
<li>读写分离</li>
<li>多少分离：大v场景</li>
<li>轻重分离：业务逻辑复杂的抽出来。</li>
<li>快慢分离：耗时久的拆分出来，如一些离线任务等。</li>
</ul>
</li>
<li><p>技术架构整体上分为 核心域、通用域、支撑域，每个领域内可以按照“关注点”分离进行服务化。类似开场的那张架构图。只不过技术架构需要体现业务架构，在逻辑上需要调整下：</p>
<ul>
<li>列出现有的所有服务，根据团队达成的结论，放到相应子域内。</li>
<li>子域内部架构按照前面说的“关注点分离”进行设计，比如当前有api层、服务层等。</li>
<li>子域内重复的服务可以废弃、合并，耦合的进行迁移，该拆分的拆分，该新增的新增。</li>
<li>领域间只能通过接口访问 功能+数据。</li>
</ul>
</li>
<li>每个子域都是有生命的“对象”，对象两大特点：行为+数据。 </li>
<li><p>与过程化、模块化 建模区别：<br><img src="/img/15772637354780.jpg" alt></p>
<ul>
<li>过程化：直观化思维，关注特定功能过程化描述，不能复用。</li>
<li>模块化：归纳性思维，数据建模，功能、数据复用，缺乏数据封装。</li>
<li>领域化：抽象性思维，功能和数据聚合抽象成实体，功能和数据同等重要，统一进行封装。</li>
</ul>
</li>
<li>功能复杂度与维护效率：<br>  <img src="/img/15772637614029.jpg" alt></li>
</ul>
<h3 id="团队-1"><a href="#团队-1" class="headerlink" title="团队"></a>团队</h3><p>大的原则：人跟事走。<br>康威定律：组织结构会通过系统设计表达出来。当架构确定之后，根据架构划分进行组织结构调整。<br>这部分就说这些，可能我理解不深，觉得没什么可以再说的了。</p>
<p>此处讲解时举架构演进栗子🌰。</p>
<p>最后，一个观点结尾：<br><strong>“能用产品解决的问题不要用服务，能用服务解决的问题不要用咨询”</strong></p>
]]></content>
      <categories>
        <category>通用能力</category>
        <category>架构</category>
      </categories>
      <tags>
        <tag>架构</tag>
      </tags>
  </entry>
  <entry>
    <title>谈判力</title>
    <url>/2019/12/08/%E8%B0%88%E5%88%A4%E5%8A%9B/</url>
    <content><![CDATA[<p>《谈判力》读完了，感觉挺有用的，梳理下笔记。</p>
<a id="more"></a>
<h2 id="问题"><a href="#问题" class="headerlink" title="问题"></a>问题</h2><h3 id="好的谈判三个标准"><a href="#好的谈判三个标准" class="headerlink" title="好的谈判三个标准"></a>好的谈判三个标准</h3><ul>
<li>有效率</li>
<li>增进或至少不损害双方关系</li>
<li>明智的协议</li>
</ul>
<h3 id="立场谈判的问题"><a href="#立场谈判的问题" class="headerlink" title="立场谈判的问题"></a>立场谈判的问题</h3><ul>
<li>不能达成明智协议：把大部分价值留在了谈判桌上</li>
<li>缺乏效率：为了使结果有利于自己，双方都很极端，死守不放。</li>
<li>损害双方关系：立场上讨价还价完全是一场意志较量。每个谈判者都坚持自己的立场，本来是双方合作解决的问题，却成了一场你死我活的斗争。</li>
</ul>
<h2 id="谈判方式"><a href="#谈判方式" class="headerlink" title="谈判方式"></a>谈判方式</h2><ul>
<li>人：把人和事分开。谈判者应该是肩并肩工作，一起解决问题，而不是相互攻击</li>
<li>利益：把利益和立场分开</li>
<li>选择：为共同利益创造选择方案</li>
<li>标准：坚持使用客观标准<h3 id="把人和事分开"><a href="#把人和事分开" class="headerlink" title="把人和事分开"></a>把人和事分开</h3></li>
<li>实质利益和关系利益：不要指望靠牺牲实质利益来换取良好的人际关系</li>
<li>直接解决人际问题：目的是进行不带偏见、开放的谈判</li>
<li>人际问题从以下三方面找出路：认知、情绪、交流</li>
</ul>
<h4 id="认知"><a href="#认知" class="headerlink" title="认知"></a>认知</h4><ul>
<li>了解对方的想法不只是帮助解决自己的问题。他们的想法本身就是问题所在。</li>
<li>冲突不在于客观现实本身，而在于人们的思考方式上。双方对于事实的不同认识才是解决问题的契机。</li>
<li>人们往往只看到他们想要看到的东西。在大量事实中，挑拣能验证自己最初认知的事实，而忽略或扭曲不符合他们认知的信息。（人类误判心理学：错误衡量易得性倾向）</li>
<li>理解对方观点并不意味着表示赞同。缩小冲突范围，帮助实现新的自我利益。</li>
<li>保全面子：人们在谈判中坚持己见，往往不是因为建议本身不能接受，而只是不想表现得在对方面前败下阵来。要与谈判者的自我形象相协调，重要性不可低估（人类误判心理学：避免不一致，被剥夺超级反应倾向）</li>
</ul>
<h4 id="情绪"><a href="#情绪" class="headerlink" title="情绪"></a>情绪</h4><ul>
<li>情绪本身也许比说话更重要</li>
<li>把情绪表现出来，并承认有情绪是正常的。只有从埋在心底的情绪包袱重解脱出来，才可能集中精力思考问题。</li>
<li>让对方发泄情绪。</li>
<li>对付另一方发脾气的最好措施也许是静静地听着，并不时地让对方继续，指导他说完为止。这样，你不仅没有煽风点火、恶化形式，还给了对方说出心里话的勇气，不再留什么积怨。</li>
</ul>
<h4 id="交流"><a href="#交流" class="headerlink" title="交流"></a>交流</h4><ul>
<li>交流存在三大障碍：谈判者并不一定直接交流；对方不一定在听；误解</li>
<li>集中精力听对方说话，要求对方清楚明了地阐述其真正意图，且在模棱两可或没有把握时要求对方重复。对方说话时尽量不要回应，而要去真正理解对方。站在对方角度，考虑对方的需求，理解对方的压力。</li>
<li>理解不等于赞同。如果你能比对方更清楚的说出他们的观点，然后再进行反驳，就会大大增加双方根据实际情况进行建设性对话的可能性，也极大减少了他们认为被误解的可能。</li>
<li>谈论问题对自己的影响，而不是分析对方都做了些什么，或者为什么那么做。</li>
<li>如果希望对方倾听并且理解你的解释，先说原因再说结论。</li>
</ul>
<h3 id="利益：把利益和立场分开"><a href="#利益：把利益和立场分开" class="headerlink" title="利益：把利益和立场分开"></a>利益：把利益和立场分开</h3><ul>
<li>立场是已作的决定，利益是导致做出这一决定的原因。</li>
<li>协调双方利益而不是立场。</li>
<li>谈判的根本问题不在于双发立场冲突，而在于双发需求、愿望、想法乃至恐惧等方面的冲突。</li>
<li>利益驱动人的行为，是立场争执背后的动机。</li>
<li>大多数场景只要仔细考虑潜在的利益需求，就能发现双方共同或可调和的利益要远远多于相互对立的利益。</li>
<li>共同利益和互补的不同利益都可以成为达成明智协议的基础。</li>
</ul>
<h4 id="如何确定利益"><a href="#如何确定利益" class="headerlink" title="如何确定利益"></a>如何确定利益</h4><ul>
<li>问“为什么”。最基本的方法是站在对方的角度换位思考。分析对方采取的每一个立场，问自己对方为什么会这样做。<ul>
<li>“回头看”，找原因，认为我们的行为是由已经发生的事情决定</li>
<li>“向前看”，找目的。我们的行为取决于自己的意志。</li>
<li>向前看比回头看更符合利益,不要与对方争论已经发生的事情.</li>
</ul>
</li>
<li>问“为什么不”。对方为什么没有那样做，那样做会影响他们的什么利益？</li>
</ul>
<h4 id="具体做法"><a href="#具体做法" class="headerlink" title="具体做法"></a>具体做法</h4><ul>
<li>承认对方的利益：人类误判心理学：回馈倾向。</li>
<li>利益清单：理清双方利益，按重要性评估</li>
<li>讨论利益：如果希望对方认真考虑你的利益，明确、具体的告诉他们怎样做才符合你的利益。具体的细节不仅让你的叙述真实可信，还能增加影响力。</li>
<li>努力争取自己的利益：主动出击捍卫自己的利益。对方关注他们自己的利益往往对达成协议有过分乐观的估计。只有努力捍卫自己的利益，谈判才能取得明智结果，也就是自己获益最大，对方损失最小。谈判方都力主自己的利益，往往会激发创造性，找出对双方都有利的方案。</li>
<li>就事论事：彬彬有礼，感谢对方付出的时间和精力。让对方知道对事不对人。</li>
<li>不仅全力对付问题，还要全力支持对方：心理学认知不一致理论认为，人们不喜欢矛盾，因而会努力消除矛盾。</li>
</ul>
<h3 id="选择：为共同利益创造选择方案"><a href="#选择：为共同利益创造选择方案" class="headerlink" title="选择：为共同利益创造选择方案"></a>选择：为共同利益创造选择方案</h3><ul>
<li>善于创造多种选择方案是谈判者可以拥有的最具价值的一笔财富：分割蛋糕之前把蛋糕做大</li>
<li>谈判者“往往把钱留在谈判桌上”,未能利益最大化</li>
</ul>
<h4 id="阻碍创造多种方案的原因"><a href="#阻碍创造多种方案的原因" class="headerlink" title="阻碍创造多种方案的原因"></a>阻碍创造多种方案的原因</h4><ul>
<li>不成熟的判断</li>
<li>寻求单一的答案</li>
<li>以为蛋糕的大小是不变的</li>
<li>认为“他们的问题应该由他们自己解决”</li>
</ul>
<h4 id="解决方法"><a href="#解决方法" class="headerlink" title="解决方法"></a>解决方法</h4><ul>
<li>将创造选择方案与评判方案二者分开</li>
<li>扩大谈判桌上的选择，不要只寻求唯一方案</li>
<li>寻求共同利益：以为蛋糕大小是固定不变的，你得的少我就得的多，这种想法几乎没有一次被证明是正确的。寻找对你代价最小，对对方好处最大的方案，反之亦然。<ul>
<li>共同利益潜藏在每项谈判中，往往不是即时可见.</li>
<li>共同利益是机遇不是天上掉下来的馅饼,要让它发挥作用,你必须对此有所作为.</li>
<li>人们总是以为双方差异会造成问题，却不知差异也能解决问题：如股票交易。</li>
</ul>
</li>
<li>找到让对方容易决策的方法。</li>
</ul>
<h3 id="坚持使用客观标准"><a href="#坚持使用客观标准" class="headerlink" title="坚持使用客观标准"></a>坚持使用客观标准</h3><ul>
<li>这部分废话多点，不做记录。</li>
</ul>
<h2 id="但是…"><a href="#但是…" class="headerlink" title="但是…"></a>但是…</h2><ul>
<li>如果对方实力更强大怎么办？</li>
<li>如果对方不合作怎么办？</li>
<li>如果对方使用卑鄙手段怎么办？</li>
</ul>
<h3 id="如果对方实力更强大怎么办"><a href="#如果对方实力更强大怎么办" class="headerlink" title="如果对方实力更强大怎么办"></a>如果对方实力更强大怎么办</h3><ul>
<li>最好的结局不外乎实现下面两大目标：</li>
<li>保护自己：不至于接受本应拒绝的协议。<ul>
<li>确定底线，但可能阻碍你设计出更富新意的解决方案,妨碍接受明智的解决方案</li>
<li>准备最佳替代方案：大多数情况下，更大的风险在于你太想达成协议。由于没有确定任何替代方案，你自然对谈判破裂可能产生的后果感到过于悲观。</li>
<li>谈判能否达成，完全取决于最佳替代方案对于你的吸引力。</li>
</ul>
</li>
<li>让你的谈判资源发挥最大的效用，使达成的协议能尽量满足你的利益需求。<ul>
<li>“资源”并不等于“谈判实力”。谈判双方的相对实力主要取决于各方能在多大程度上承受谈判破裂的后果。</li>
<li>制定你的最佳替代方案。积极寻找谈判破裂后自己所面临的选择，可以大大增强你的谈判实力。</li>
<li>是否该把最佳替代方案透露给对方，取决于你对对方想法的分析。</li>
<li>对另一方替代方案的了解越多，对谈判的准备就越充分。掌握了对方的替代方案，可以实事求是地估计自己对谈判的期望。越清楚的了解了对方的利益，就越能以最小的代价更好的满足对方。</li>
<li>只有当你的条件让对方感觉比他们的最佳替代方案更有吸引力时，你才可能获得谈判的成功。如果做不到这一点，谈判奖没有意义。还不如集中精力完善自己的最佳替代方案，有可能的话，试着改变对方的最佳替代方案。</li>
<li>将实力资源与其他资源协调起来利用。</li>
</ul>
</li>
</ul>
<h3 id="如果对方不合作怎么办"><a href="#如果对方不合作怎么办" class="headerlink" title="如果对方不合作怎么办"></a>如果对方不合作怎么办</h3><p>对方一味攻击你的建议；一心只考虑最大限度满足自己的利益；人身攻击；怎样才能让对方从立场整治转到摆事实、讲道理上来？</p>
<ul>
<li>关注自己能做什么：以身作则</li>
<li>关注对方能做什么：把对方注意力转移到实际问题上来，阻止对方陷入立场之争，这一战术成为“谈判柔术”</li>
<li>关注第三方能做什么    </li>
</ul>
<h4 id="谈判柔术"><a href="#谈判柔术" class="headerlink" title="谈判柔术"></a>谈判柔术</h4><h5 id="如何避免陷入攻击和辩解的恶性循环中？"><a href="#如何避免陷入攻击和辩解的恶性循环中？" class="headerlink" title="如何避免陷入攻击和辩解的恶性循环中？"></a>如何避免陷入攻击和辩解的恶性循环中？</h5><ul>
<li>不要回击：选择避开对方的攻击，并将对方的攻击直指问题本身。好比东方武术中的柔道和柔术一样，避免与对方直接对抗，运用躲闪技巧，借助对方的力量达到自己的目的。</li>
<li>不要对抗对方的力量，相反，要把对方的力量引导到探讨双方利益、制定共同受益的选择方案和寻求客观标准上来</li>
</ul>
<h5 id="对方的攻击手段"><a href="#对方的攻击手段" class="headerlink" title="对方的攻击手段"></a>对方的攻击手段</h5><ul>
<li>直截了当表明了自己的立场：既不接受也不拒绝<br>  不要攻击对方立场，透过立场看利益。把对方的立场当做一种可能的选择，找到其遵循的原则,并考虑解决方案。</li>
<li>反驳你的观点：不要辩解<ul>
<li>欢迎批评和建议：谈判的大部分时间都花在相互职责上。</li>
<li>通过换位思考，征求对方意见的方式把批评引向建设性轨道上。</li>
</ul>
</li>
<li>对你进行人身攻击：不要反唇相讥<ul>
<li>克制住为自己辩护或干脆攻击对方的冲动。不动声色，让对方发泄怨气。</li>
<li>表现出你愿意尊重他们的意见。等他们诉说完将注意力从对自己的攻击转移到对问题的批评上来。</li>
<li>提问与停顿：提问不是批评，而是启发。</li>
<li>在你提问之后，先停顿一下不要急于提出新问题或发表自己的评论，给对方逃避尖锐问题的机会。有时，最有效的谈判是在你没有开口时发生的。</li>
<li>沉默是你最好的武器，要充分利用它。如果对方提出不合理方案或是采取在你看来站不住脚的攻击，最好的手段是一言不发。如果他们对你开诚布公的提问未作充分回答，那就等一等。人们总是对沉默感觉不舒服，尤其是对自己阐述的理由有疑问时更是如此。（人类误判心理学：避免怀疑倾向）</li>
</ul>
</li>
</ul>
<h5 id="其他技巧"><a href="#其他技巧" class="headerlink" title="其他技巧"></a>其他技巧</h5><ul>
<li>陈述事实往往会带有威胁性，因此，尽可能用问问题的形式取而代之。</li>
<li>一名优秀的谈判者很少当场作出决定。表示友好和让步的心理压力是巨大的。利用时间和空间的变化可以帮助谈判者把人与事分开。</li>
<li>进行原则谈判时，你应当在拿出任何方案之前说出自己的理由。如果事后提出理由，只会被认为是为主管立场进行的辩解，而不是适用于任何方案的客观标准。</li>
</ul>
<h3 id="如果对方使用卑鄙手段怎么办"><a href="#如果对方使用卑鄙手段怎么办" class="headerlink" title="如果对方使用卑鄙手段怎么办"></a>如果对方使用卑鄙手段怎么办</h3><ul>
<li>发现诡计</li>
<li>揭穿诡计</li>
<li>质疑诡计的合理性与可取性</li>
</ul>
<h4 id="常见的诡计"><a href="#常见的诡计" class="headerlink" title="常见的诡计"></a>常见的诡计</h4><h5 id="故意欺骗"><a href="#故意欺骗" class="headerlink" title="故意欺骗"></a>故意欺骗</h5><ul>
<li>将人与事分开，除非有充分的理由，否则不要相信别人。这并不意味着把对方看成骗子，而是说把谈判与信任问题分开。</li>
<li>模糊的权限：不能只因为对方在和你谈判就认为他们拥有全部权利。做决定前确定对方的权限</li>
<li>未完全透露不等于欺骗。在事实和意图上故意欺骗别人与不完全透露自己当时的想法是两码事。诚实的谈判并不需要完全透露自己的想法。如果双发不信任，可以依赖彼此信任的第三方来处理</li>
</ul>
<h5 id="心理战术"><a href="#心理战术" class="headerlink" title="心理战术"></a>心理战术</h5><ul>
<li>环境压抑：问问自己是否感觉紧张，如果是也许是对方故意安排，好让你觉得必须尽早结束谈判。如果发现环境对你不利，要立即指出来，必要的话可以终止谈判离席而去。</li>
<li>人身攻击：用各种言语或非语言的交流形式使你感觉不自在<br>红白脸战术</li>
<li>威胁：往往适得其反，不但不解决问题，反而会带来压力。让对方在实施威胁时冒极大的风险。</li>
</ul>
<h5 id="在立场上施压"><a href="#在立场上施压" class="headerlink" title="在立场上施压"></a>在立场上施压</h5><ul>
<li>拒绝谈判：把同意谈判作为讨价还价的筹码。这一招的另一种形式是为谈判设置先决条件。解决方法：提出一些选择方案，比如通过第三方谈判或通过信函进行协商</li>
<li>过分的要求：让对方用原则来解释其立场,看是否有充分的理由,直到连他们自己也觉得荒谬为止.</li>
<li>变本加厉：提醒对方注意，然后不妨中断谈判，考虑是否继续进行谈判或基于什么原则谈判。这样避免了在指出对方行为严重性时表现冲动，从而做到坚持原则。</li>
<li>锁定战术：不要把对方的锁定当回事，将他的重要性淡化，这样对方才能体面的做出让步。</li>
<li>强硬的同伴：用来拒绝对方的要求，谈判者本人称自己不反对，但同伴反对。认识到这点后不要和对方继续讨论,而是让他接受所适用的原则。并在可能的情况下,与那位强硬的同伴直接谈判。</li>
<li>故意拖延：除了指出对方的拖延战术并与之谈判外，考虑不给对方机会，如设置deadline等。</li>
<li>要不要请便：通常这是不可改变的事实没有什么错，只不过在措辞上应该礼貌。可以指出达不成协议他们会损失什么，并寻找一种保全脸面的方法，让对方走出困境。</li>
</ul>
<h2 id="结论"><a href="#结论" class="headerlink" title="结论"></a>结论</h2><ul>
<li>时时做到心中有数<ul>
<li>本书观点与你的经验和直觉越一致越好</li>
</ul>
</li>
<li>从实践中学习</li>
<li>取胜之道：<ul>
<li>不时提醒自己，首先要在谈判方法上取胜：避免自己在应得的利益与公平之间进行选择，因为原则谈判方法使你二者兼得</li>
</ul>
</li>
</ul>
]]></content>
      <categories>
        <category>通用能力</category>
        <category>只有偏执狂才能生存</category>
      </categories>
      <tags>
        <tag>心理学</tag>
      </tags>
  </entry>
  <entry>
    <title>穷查理宝典</title>
    <url>/2019/10/31/%E7%A9%B7%E6%9F%A5%E7%90%86%E5%AE%9D%E5%85%B8/</url>
    <content><![CDATA[<p>整理芒格的演讲，对提升认知有非常大的帮助。<br>总结起来有以下收获：</p>
<ul>
<li>终生学习</li>
<li>谦虚</li>
<li>开放的心态，不自我设限</li>
<li>检查清单</li>
<li>多元模型</li>
</ul>
<a id="more"></a>
<h2 id="普世智慧"><a href="#普世智慧" class="headerlink" title="普世智慧"></a>普世智慧</h2><ul>
<li>必须拥有多元思维模型，因为只拥有一两个，研究人性的心理学表明，你将会扭曲现实，直到它符合你的思维模型在头脑里形成一个由各种思维模型构成的框架。然后将你们的实际经验和间接经验(通过阅读等手段得来的经验）悬挂在这强大的思维模型架上。使用这种方法可以让你们将各种知识融会贯通，加深对现实的认知。</li>
<li>数学：复利原理、排列组合原理、决策树模型</li>
<li>会计学（熟悉后才能理解会计学的局限性）</li>
<li>工程学：质量控制理论、后备系统、断点理论</li>
<li>物理学：临界质量概念</li>
<li>生物学/生理学</li>
<li>心理学</li>
<li>微观经济学：让人辨别什么时候技术将帮助你，什么时候它将摧毁你。大多数人并没想通这个问题，但巴菲特想通了。</li>
</ul>
<h2 id="学习"><a href="#学习" class="headerlink" title="学习"></a>学习</h2><ul>
<li>你必须知道重要学科的重要理论，并经常使用它们，要全部都用上，而不是只有几种</li>
<li>跨学科学习</li>
<li>没有规则要求你不能增加一两个新的模型，即使你已经步入晚年(保持开放心态，不给自己设限)</li>
<li>通过广泛的阅读把自己培养成一个终生自学者：培养好奇心，每天努力使自己聪明一点点。</li>
<li>如果我们再某个阶段停滞不前，满足于拥有的知识，我们的业绩要比现在差得多。所以诀窍就在于不断学习。</li>
</ul>
<h2 id="生活"><a href="#生活" class="headerlink" title="生活"></a>生活</h2><ul>
<li>直面你的大问题，别把它隐藏起来</li>
<li>不断地挑战和主动地修正你“最爱的观念”</li>
<li>能力会让你到达巅峰，但只有品德才能让你留在那里</li>
<li>芒格在意的并不是他本人是否能赢牌，而是是否能把手上的牌打好</li>
<li>说真话，你将无需记住你的谎言</li>
<li>如果你把葡萄干和大便搅在一起，你得到的仍然是大便</li>
<li>人生不同阶段遇到非常棘手的问题，有三点有助于应付这些困难：别期望太高；拥有幽默感；让自己置身于朋友和家人的爱之中。</li>
<li>为了养家糊口，你不妨偶尔替那些丧失理智的自大狂服务。但你应该像格兰特-麦克费登那样为人处世。</li>
<li>容忍对某一些人有一点不公平，以便对所有人更为公平。</li>
</ul>
<h2 id="决策"><a href="#决策" class="headerlink" title="决策"></a>决策</h2><ul>
<li>最重要的是别愚弄你自己，而且要记住，你是最容易被自己愚弄的人</li>
<li>抵制追求虚假的精确和错误的确定性的欲望</li>
<li>当别人贪婪时要害怕；当别人害怕时要贪婪</li>
<li>比求胜的意愿更重要的是做好准备的意愿</li>
<li>凡事往简单处想，往认真处行</li>
<li>让那些最有能力和最愿意成为学习机器的人发挥最大的作用(机会留给核心人员)</li>
<li>你们想要让最好的球员打很长时间的比赛</li>
<li>逆向思考</li>
</ul>
<h2 id="投资"><a href="#投资" class="headerlink" title="投资"></a>投资</h2><ul>
<li>股价公道的伟大企业比股价超低的普通企业好</li>
<li>等待好球的出现</li>
<li>我们偏向于把大量的钱投在我们不用再另做决策的地方</li>
<li>在漫长的人生中，你只要培养自己的智慧，抓住一两次这样的好机会，就能够赚许许多多的钱</li>
<li>聪明人发现好机会就狠狠下注，其他时间则按兵不动</li>
<li>伯克希尔的方法是依据现实的投资问题不断调整变化</li>
</ul>
<h2 id="误判心理学"><a href="#误判心理学" class="headerlink" title="误判心理学"></a>误判心理学</h2><ul>
<li>奖励和惩罚 超级反应倾向</li>
<li>喜欢/热爱倾向</li>
<li>讨厌/憎恨倾向</li>
<li>避免怀疑倾向：人类的大脑天生就有一种尽快作出决定，以此消除怀疑倾向。</li>
<li>避免不一致倾向：为了节省运算空间，人类的大脑会不愿意做出改变。这是一种避免不一致性的形式。</li>
<li>好奇心倾向</li>
<li>康德式公平倾向：每个人在自身维护公平的同事希望得到公平，如果得不到就会很不满</li>
<li>艳羡/妒忌倾向</li>
<li>回馈倾向：以德报德，以牙还牙</li>
<li>受简单联想影响的倾向</li>
<li>简单的、避免痛苦的心里否认</li>
<li>自视过高的倾向</li>
<li>过度乐观倾向</li>
<li>被剥夺超级反应倾向：失去造成的伤害比得到带来的快乐多得多。如果某个人即将得到某样他非常渴望的东西，而这样东西却在最后一刻飞走了，那么他的反应就会像这件东西应拥有了很久却突然被夺走一样。</li>
<li>社会认同倾向：自动根据他看到的周边人们的思考和行动方式去思考和行动的倾向。如果一个人自动依照他所观察到的周围人们的思考和行动方式去思考和行动，那么他就能够把一些原本很复杂的行为进行简化。而且这种从中的做法往往是有效的。人们在感到困惑或者有压力的时候，尤其是在既困惑又有压力的时候，最容易受到社会认同倾向影响。</li>
<li>对比错误反应倾向</li>
<li>压力影响倾向</li>
<li>错误衡量易得性倾向：人类大脑会高估容易得到的东西的重要性倾向。</li>
<li>不用就忘倾向</li>
<li>化学物质错误影响倾向</li>
<li>衰老-错误影响倾向</li>
<li>权威-错误影响倾向</li>
<li>废话倾向</li>
<li>重视理由倾向</li>
<li>数种心理倾向共同作用造成极端后果的倾向</li>
</ul>
<h2 id="推荐书单"><a href="#推荐书单" class="headerlink" title="推荐书单"></a>推荐书单</h2><ul>
<li>人类&amp;社会<ul>
<li>苏格兰人如何发明现代世界</li>
<li>枪炮、病菌与铁：人类社会的命运</li>
<li>第三种猩猩：人类的身世与未来</li>
<li>基因组：人种自传23章</li>
<li>温度，决定一切</li>
<li>深奥的简洁</li>
<li>自私的基因</li>
</ul>
</li>
<li>经济<ul>
<li>洛克菲勒：一个关于财富的神话</li>
<li>国富国穷</li>
<li>生活在极限之内：生态学、经济学和人口禁忌</li>
<li>沃伦巴菲特的投资组合:掌握集中投资战略的秘诀</li>
<li>诚信的背后：华尔街圈钱游戏的真相</li>
</ul>
</li>
<li>心理学<ul>
<li>影响力</li>
<li>谈判力</li>
</ul>
</li>
<li>自传<ul>
<li>我生活的种种模式 赫尔伯特-西蒙自传</li>
<li>富兰克林自传</li>
</ul>
</li>
<li>其他<ul>
<li>只有偏执狂才能生存</li>
</ul>
</li>
<li>编辑推荐的书<ul>
<li>勒斯施瓦伯：因业绩而骄傲</li>
<li>凡人与大亨：经商的故事</li>
<li>筚路蓝缕的先行者：1840至1900年的西部大开发</li>
</ul>
</li>
</ul>
]]></content>
      <categories>
        <category>通用能力</category>
        <category>穷查理宝典</category>
      </categories>
      <tags>
        <tag>认知</tag>
      </tags>
  </entry>
  <entry>
    <title>思考,快与慢</title>
    <url>/2019/08/27/%E6%80%9D%E8%80%83-%E5%BF%AB%E4%B8%8E%E6%85%A2/</url>
    <content><![CDATA[]]></content>
      <categories>
        <category>通用能力</category>
        <category>思考,快与慢</category>
      </categories>
      <tags>
        <tag>系统思考</tag>
      </tags>
  </entry>
  <entry>
    <title>只有偏执狂才能生存</title>
    <url>/2018/07/15/%E5%8F%AA%E6%9C%89%E5%81%8F%E6%89%A7%E7%8B%82%E6%89%8D%E8%83%BD%E7%94%9F%E5%AD%98/</url>
    <content><![CDATA[<p>《Only the Paranoid Survive》，读下来没感觉到和“偏执狂”有什么关系。</p>
<p>这本书主要讲随着时代发展，企业及个人如何发现变化及时做出调整。主要讲企业，企业由高管带领，讲述高管应如何做。</p>
<p>记录一些看的懂得重点。</p>
<a id="more"></a>
<h2 id="10倍速变化"><a href="#10倍速变化" class="headerlink" title="10倍速变化"></a>10倍速变化</h2><h3 id="影响企业竞争力六个因素"><a href="#影响企业竞争力六个因素" class="headerlink" title="影响企业竞争力六个因素"></a>影响企业竞争力六个因素</h3><ol>
<li>现有竞争对手的实力、活力和能力<ul>
<li>竞争对手数量多吗？资本是否雄厚？</li>
<li>是否清楚的瞄准了你？</li>
</ul>
</li>
<li>公司潜在竞争对手的实力、活力和能力.<ul>
<li>形势一变，他们就能加入进来</li>
<li>可能比现有的竞争对手更加强大。</li>
</ul>
</li>
<li>公司的供应商的实力、活力和能力<ul>
<li>供应商数据是否足够多让你的业务有足够的选择余地；</li>
<li>还是只有几家，他们可以掐住你的咽喉？</li>
<li>他们是充满挑衅，贪得无厌还是较为谨慎稳妥，并把客户情况的长远评价作为企业指导？</li>
</ul>
</li>
<li>企业客户数量<ul>
<li>是很多还是仅靠一两家主要客户做生意？</li>
<li>他们是倚恃激烈的竞争对你求全责备还是采用较为温和的态度？</li>
</ul>
</li>
<li>你的产品或服务项目采用其他方式投产或发送的可能性<ul>
<li>这常常叫做“替代方式”,<strong>作者认为这是最致命的一点。</strong></li>
<li>新技术、新方法可以垫付旧秩序，建立新规则，是商业环境发生翻天覆地变化。类似于超时对小商店的冲击，微处理器对运算的冲击，以及数字媒体对娱乐的冲击。</li>
</ul>
</li>
<li>互补企业因素<ul>
<li>为客户提供互补型产品的其他企业。</li>
<li>每个公司的产品都要和其他公司产品互相结合才能发挥更大的作用。</li>
</ul>
</li>
</ol>
<p>这是传统行业的六大因素，当今互联网行业也可以参考，主要区别在于供应商及”替代方式“：</p>
<ol>
<li>供应商及客户可以理解为企业的上下游。对互联网公司产品来说，供应商就是使用者，客户就是能够创造利润的。如Google，供应商就是C端用户，客户就是广告主。</li>
<li>”替代方式“：指的不是被其他产品替代，而是产品能否适应时代发展。</li>
</ol>
<h3 id="超竞争因素"><a href="#超竞争因素" class="headerlink" title="超竞争因素"></a>超竞争因素</h3><p>当某一个因素发生了重大变化，超过了企业能够承受的程度，成败就在此一举。这就是”10倍速变化“，意为该因素在短期内实力增至原来10倍。<br><img src="/img/15316649124960.jpg" alt></p>
<p>企业由此进入战略转折点，要么上升到新高度，要么走向低谷。<br><img src="/img/15316649360996.jpg" alt></p>
<p>战略转折点的出现不容易精确找出。再前行过程中，终于在某个点停了下来说：我们迷路了。这时就是战略转折点。</p>
<h3 id="哪些会产生10倍速变化"><a href="#哪些会产生10倍速变化" class="headerlink" title="哪些会产生10倍速变化"></a>哪些会产生10倍速变化</h3><ol>
<li>竞争</li>
<li>技术</li>
<li>用户</li>
<li>供应商</li>
<li>互补企业</li>
<li>营运规则</li>
</ol>
<h3 id="哪些情况意味着转折点"><a href="#哪些情况意味着转折点" class="headerlink" title="哪些情况意味着转折点"></a>哪些情况意味着转折点</h3><ol>
<li>第一阶段，有些不安，感觉清醒与以往有些不同</li>
<li>第二阶段是你对公司业务的看法和实际情况大相径庭</li>
<li>最后出现了新立场、新看法和新举措，一套新的公司声明诞生了，高层领导班子也改组。</li>
</ol>
<p>最好的情况是在公司仍然健全、外部业务仍能支撑在内部实验新的经营方式的时候进行改革。</p>
<p>时间是一切，意味着需要在情报尚不完全、情况不清楚的时候采取行动。可悲的是，<strong>一旦进入了战略转折点，就只有感觉和个人判断能够作为指导。</strong></p>
<h2 id="如何察觉他们"><a href="#如何察觉他们" class="headerlink" title="如何察觉他们"></a>如何察觉他们</h2><p>如何从”噪声“中分辨出”信号“？</p>
<ol>
<li>对于可能成为企业10倍速因素的发展变化，要保持长久警惕。</li>
<li>主要竞争对手是否将要发生某种变化。首先判断主要竞争对手是谁？自问：如果枪里只有一颗子弹，你会用在哪个竞争对手身上。</li>
<li>互补企业是否就要发生变化。</li>
<li>周围的人是否变得迷惑不知所从。</li>
<li>保持开放的心态，倾听一线员工的。（要消除员工对战略讨论会发言的后顾之忧，没有多年时间是不行的。）</li>
<li>倾听一线观点，要分辨哪些消息是待琢璞玉(需要再次加工分析），又有哪些人利用你的兼听之明，用噪声来包围你。</li>
<li>避开最初模型的陷阱。不能只凭最初模型的质量来判断他是否具有战略转折点意义。如果你认为改进10倍之后，这件事足以引起人们的兴奋而成为新的威胁因素，你就可能出在观察一个战略转折点开端的边缘。应该训练自己深入的思考问题，把最初模型优劣与该产品或技术的长期潜能和长远意义区分开来。（很多互联网产品估值那么高都源于此。）</li>
<li>与数据争论。数据说明过去，战略转折点表示未来。应该清楚何时使用数据，何时离开。</li>
</ol>
<h2 id="推荐阅读"><a href="#推荐阅读" class="headerlink" title="推荐阅读"></a>推荐阅读</h2><p>一篇讲增长的文章：<a href="https://mp.weixin.qq.com/s/w83PtvGewwCjwvuIBDa2bw" target="_blank" rel="noopener">https://mp.weixin.qq.com/s/w83PtvGewwCjwvuIBDa2bw</a> 根据很多资料总结的。</p>
]]></content>
      <categories>
        <category>通用能力</category>
        <category>只有偏执狂才能生存</category>
      </categories>
      <tags>
        <tag>企业</tag>
      </tags>
  </entry>
  <entry>
    <title>如何做项目管理</title>
    <url>/2018/04/21/%E5%A6%82%E4%BD%95%E5%81%9A%E9%A1%B9%E7%9B%AE%E7%AE%A1%E7%90%86/</url>
    <content><![CDATA[<p>本周参加了公司内部通用能力培训，总结一下。本篇是强哥关于项目管理的分享。<br>之前带过一些项目，自己的一些做法暗合分享内容。但不成体系，拾人牙慧，整理一下。</p>
<a id="more"></a>
<h2 id="项目管理是什么"><a href="#项目管理是什么" class="headerlink" title="项目管理是什么"></a>项目管理是什么</h2><blockquote>
<p>在既定的资源和要求的约束下，为实现某种目的而相互联系的一次性工作任务。<br><a href="https://baike.baidu.com/item/%E9%A1%B9%E7%9B%AE%E7%AE%A1%E7%90%86/85389?fr=aladdin" target="_blank" rel="noopener">https://baike.baidu.com/item/%E9%A1%B9%E7%9B%AE%E7%AE%A1%E7%90%86/85389?fr=aladdin</a></p>
</blockquote>
<p>具有以下关键信息。<br>1.目的<br>2.资源和要求的约束<br>3.相互联系<br>4.一次性工作</p>
<h3 id="目的"><a href="#目的" class="headerlink" title="目的"></a>目的</h3><p>可以理解成目标，按照smart原则设定。</p>
<h3 id="资源和要求的约束"><a href="#资源和要求的约束" class="headerlink" title="资源和要求的约束"></a>资源和要求的约束</h3><ol>
<li>资源 = 人力 + 时间</li>
<li>要求约束<ul>
<li>功能约束(需求、交互)</li>
<li>非功能约束(性能、可用性、安全、架构)</li>
</ul>
</li>
</ol>
<h4 id="如何应对"><a href="#如何应对" class="headerlink" title="如何应对"></a>如何应对</h4><p><img src="/img/15262834463445.jpg" alt><br><strong>scope</strong>：可以理解为做得事情<br><strong>cost</strong>:投入的资源。<br><strong>核心</strong>：质量不能妥协。</p>
<h4 id="三边如何取舍"><a href="#三边如何取舍" class="headerlink" title="三边如何取舍"></a>三边如何取舍</h4><ol>
<li>深刻理解业务 </li>
<li>深刻理解技术</li>
</ol>
<h3 id="相互联系"><a href="#相互联系" class="headerlink" title="相互联系"></a>相互联系</h3><ol>
<li>项目外有哪些外部联系</li>
<li>项目中的事情是如何关联的</li>
<li>任务拆解：分配人做合适的事</li>
<li>关键路径：关注路径最长的。</li>
<li>哪些人会关心这个项目：干系人。</li>
</ol>
<h3 id="一次性"><a href="#一次性" class="headerlink" title="一次性"></a>一次性</h3><ol>
<li>要有明确的开始和结束时间</li>
<li><strong>一次性</strong>: 一次性把事情做对(在华为时从培训开始公司就一直强调)</li>
<li>快速迭代 != 目标打折</li>
<li>一次性工作 != 临时性工作</li>
</ol>
<h2 id="项目管理怎么做"><a href="#项目管理怎么做" class="headerlink" title="项目管理怎么做"></a>项目管理怎么做</h2><p><img src="/img/15301771013809.jpg" alt></p>
<h2 id="迭代的两种方式"><a href="#迭代的两种方式" class="headerlink" title="迭代的两种方式"></a>迭代的两种方式</h2><ol>
<li><strong>MVP</strong>(Minimum Viable Product): 最小可行产品。适用于新领域，快速接收反馈，调整策略。</li>
<li><strong>MAP</strong>(Mimimum Awesome Product):最低完成度但足够能让人惊艳的产品。适用于成熟市场，有其他竞品。</li>
</ol>
<h2 id="常见的坑"><a href="#常见的坑" class="headerlink" title="常见的坑"></a>常见的坑</h2><h3 id="启动"><a href="#启动" class="headerlink" title="启动"></a>启动</h3><ol>
<li>启动过快:启动容易收尾难。这一点做线上CRM一期体会较深。需求有很多不合理地方，推动理清问题及评估方案可行性才开始做。</li>
<li>目标是上线</li>
</ol>
<h3 id="资源"><a href="#资源" class="headerlink" title="资源"></a>资源</h3><ol>
<li>兵马先行，粮草没有</li>
<li>名义资源:项目组人员身兼数职，投入项目时间不可控。</li>
<li>万能资源:不考虑人的技能特点，简单数人头。</li>
</ol>
<h3 id="排期"><a href="#排期" class="headerlink" title="排期"></a>排期</h3><ol>
<li>倒排</li>
<li>WBS(work breakdown structure)太粗</li>
<li>搞不清任务依赖关系</li>
<li>看不到项目关键路径</li>
</ol>
<h3 id="沟通"><a href="#沟通" class="headerlink" title="沟通"></a>沟通</h3><ol>
<li>不沟通</li>
<li>尽量不给老大添麻烦 -&gt; 给他“惊喜”</li>
<li>都听听没坏处 -&gt;开大会</li>
<li>会议内容：大会小开，小会大开。小会详细讨论；大会之前私下有过交流，会上再次确认。</li>
</ol>
<h4 id="沟通的方法"><a href="#沟通的方法" class="headerlink" title="沟通的方法"></a>沟通的方法</h4><ol>
<li>每日站会</li>
<li>周会</li>
<li>项目周报</li>
</ol>
<h3 id="风险管理"><a href="#风险管理" class="headerlink" title="风险管理"></a>风险管理</h3><ol>
<li>只讲问题，不讲方法</li>
<li>过程管理</li>
<li>契约精神：认为还有时间，项目成员应确保在dealline前完成。</li>
<li>无声变更：接PM需求只有自己知道。</li>
<li>事情会按计划进行：缺少监控</li>
</ol>
<h2 id="参考资料"><a href="#参考资料" class="headerlink" title="参考资料"></a>参考资料</h2><ol>
<li>强哥的分享</li>
<li>MVP和MAP：<a href="https://medium.com/swlh/the-mvp-is-dead-long-life-to-the-map-minimum-awesome-product-404df90fef7f(翻译版本到处都是)" target="_blank" rel="noopener">https://medium.com/swlh/the-mvp-is-dead-long-life-to-the-map-minimum-awesome-product-404df90fef7f(翻译版本到处都是)</a></li>
</ol>
]]></content>
      <categories>
        <category>通用能力</category>
        <category>项目管理</category>
      </categories>
      <tags>
        <tag>项目管理</tag>
      </tags>
  </entry>
  <entry>
    <title>Kafka生产者</title>
    <url>/2018/04/18/Kafka%E7%94%9F%E4%BA%A7%E8%80%85/</url>
    <content><![CDATA[<h2 id="发送消息步骤"><a href="#发送消息步骤" class="headerlink" title="发送消息步骤"></a>发送消息步骤</h2><p><img src="/img/15255335466815.jpg" alt></p>
<p>ProducerRecord 对象需要包含目标主题和要发送的内容。我们还可以指定键或分区。</p>
<a id="more"></a>
<ol>
<li>在发送 ProducerRecord 对象时，生产者要先把键和值对象序列化成字节数组，这样它们才能够在网络上传输。</li>
<li>数据被传给分区器。如果之前在 ProducerRecord 对象里指定了分区，那么分区器就不会再做任何事情，直接把指定的分区返回。如果没有指定分区，那么分区器会根据 ProducerRecord 对象的键来选择一个分区。选好分区以后，生产者就知道该往哪个主题和分区发送这条记录了。</li>
<li>紧接着，这条记录被添加到一个记录批次里，这个批次里的所有消息会被发送到相同的主题和分区上。</li>
<li>有一个独立的线程负责把这些记录批次发送到相应的 broker 上。<br>———–<strong>问题是这样节省了带宽，不会影响实时性么？生产者并不会等待批次满了才发，半满甚至只包含一个消息就会发。感觉有个间隔，间隔到了不管有多少都发。</strong></li>
<li>服务器在收到这些消息时会返回一个响应。如果消息成功写入 Kafka，就返回一个 RecordMetaData 对象，它包含了主题和分区信息，以及记录在分区里的偏移量。如果写入失败，则会返回一个错误</li>
<li>生产者在收到错误之后会尝试重新发送消息，几次之后如果还是失败，就返回错误信息。</li>
</ol>
<h2 id="发送消息方式"><a href="#发送消息方式" class="headerlink" title="发送消息方式"></a>发送消息方式</h2><h3 id="发送并忘记（fire-and-forget）"><a href="#发送并忘记（fire-and-forget）" class="headerlink" title="发送并忘记（fire-and-forget）"></a>发送并忘记（fire-and-forget）</h3><p>我们把消息发送给服务器，但并不关心它是否正常到达。大多数情况下，消息会正常到达，因为 Kafka 是高可用的，而且生产者会自动尝试重发(可通过参数配置)。不过，使用这种方式有时候也会丢失一些消息。</p>
<figure class="highlight java"><table><tr><td class="code"><pre><span class="line">ProducerRecord&lt;String, String&gt; record =</span><br><span class="line">        <span class="keyword">new</span> ProducerRecord&lt;&gt;(<span class="string">"CustomerCountry"</span>, <span class="string">"Precision Products"</span>,</span><br><span class="line">          <span class="string">"France"</span>); ➊</span><br><span class="line"><span class="keyword">try</span> &#123;</span><br><span class="line">  producer.send(record); ➋</span><br><span class="line">&#125; <span class="keyword">catch</span> (Exception e) &#123;</span><br><span class="line">        e.printStackTrace(); ➌</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<p>❶ 生产者的 send() 方法将 ProducerRecord 对象作为参数，所以我们要先创建一个 ProducerRecord 对象。它需要目标主题的名字和要发送的键和值对象，它们都是字符串。键和值对象的类型必须与序列化器和生产者对象相匹配。</p>
<p>❷ 我们使用生产者的 send() 方法发送 ProducerRecord 对象。从生产者的架构图里可以看到，消息先是被放进缓冲区，然后使用单独的线程发送到服务器端。send() 方法会返回一个包含 RecordMetadata 的 Future 对象，不过因为我们会忽略返回值，所以无法知道消息是否发送成功。如果不关心发送结果，那么可以使用这种发送方式。比如，记录 Twitter 消息日志，或记录不太重要的应用程序日志。</p>
<p>❸ 我们可以忽略发送消息时可能发生的错误或在服务器端可能发生的错误，但在发送消息之前，生产者还是有可能发生其他的异常。这些异常有可能是 SerializationException（说明序列化消息失败）、BufferExhaustedException 或 TimeoutException（说明缓冲区已满），又或者是 InterruptException（说明发送线程被中断）。</p>
<h3 id="同步发送"><a href="#同步发送" class="headerlink" title="同步发送"></a>同步发送</h3><p>我们使用 send() 方法发送消息，它会返回一个 Future 对象，调用 get() 方法进行等待，就可以知道消息是否发送成功。</p>
<figure class="highlight java"><table><tr><td class="code"><pre><span class="line">ProducerRecord&lt;String, String&gt; record =</span><br><span class="line">        <span class="keyword">new</span> ProducerRecord&lt;&gt;(<span class="string">"CustomerCountry"</span>, <span class="string">"Precision Products"</span>, <span class="string">"France"</span>);</span><br><span class="line"><span class="keyword">try</span> &#123;</span><br><span class="line">        producer.send(record).get(); ➊</span><br><span class="line">&#125; <span class="keyword">catch</span> (Exception e) &#123;</span><br><span class="line">        e.printStackTrace(); ➋</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<p>❶ 在这里，producer.send() 方法先返回一个 Future 对象，然后调用 Future 对象的 get() 方法等待 Kafka 响应。如果服务器返回错误，get() 方法会抛出异常。如果没有发生错误，我们会得到一个 RecordMetadata 对象，可以用它获取消息的偏移量。</p>
<p>❷ 如果在发送数据之前或者在发送过程中发生了任何错误，比如 broker 返回了一个不允许重发消息的异常或者已经超过了重发的次数，那么就会抛出异常。我们只是简单地把异常信息打印出来。</p>
<p>KafkaProducer 一般会发生两类错误。其中一类是可重试错误，这类错误可以通过重发消息来解决。比如对于连接错误，可以通过再次建立连接来解决，“无主（no leader）”错误则可以通过重新为分区选举首领来解决。KafkaProducer 可以被配置成自动重试，如果在多次重试后仍无法解决问题，应用程序会收到一个重试异常。另一类错误无法通过重试解决，比如“消息太大”异常。对于这类错误，KafkaProducer 不会进行任何重试，直接抛出异常。</p>
<h3 id="异步发送"><a href="#异步发送" class="headerlink" title="异步发送"></a>异步发送</h3><p>我们调用 send() 方法，并指定一个回调函数，服务器在返回响应时调用该函数。</p>
<figure class="highlight java"><table><tr><td class="code"><pre><span class="line"><span class="keyword">private</span> <span class="class"><span class="keyword">class</span> <span class="title">DemoProducerCallback</span> <span class="keyword">implements</span> <span class="title">Callback</span> </span>&#123;➊</span><br><span class="line">        <span class="meta">@Override</span></span><br><span class="line">    <span class="function"><span class="keyword">public</span> <span class="keyword">void</span> <span class="title">onCompletion</span><span class="params">(RecordMetadata recordMetadata, Exception e)</span> </span>&#123;</span><br><span class="line">     <span class="keyword">if</span> (e != <span class="keyword">null</span>) &#123;</span><br><span class="line">         e.printStackTrace(); ➋</span><br><span class="line">        &#125;</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line">ProducerRecord&lt;String, String&gt; record =</span><br><span class="line">        <span class="keyword">new</span> ProducerRecord&lt;&gt;(<span class="string">"CustomerCountry"</span>, <span class="string">"Biomedical Materials"</span>, <span class="string">"USA"</span>); ➌</span><br><span class="line">producer.send(record, <span class="keyword">new</span> DemoProducerCallback()); ➍</span><br></pre></td></tr></table></figure>
<p>❶ 为了使用回调，需要一个实现了 org.apache.kafka.clients.producer.Callback 接口的类，这个接口只有一个 onCompletion 方法。</p>
<p>❷ 如果 Kafka 返回一个错误，onCompletion 方法会抛出一个非空（non null）异常。这里我们只是简单地把它打印出来，但是在生产环境应该有更好的处理方式。</p>
<p>❸ 记录与之前的一样。</p>
<p>❹ 在发送消息时传进去一个回调对象。</p>
<h2 id="生产者参数"><a href="#生产者参数" class="headerlink" title="生产者参数"></a>生产者参数</h2><h3 id="acks"><a href="#acks" class="headerlink" title="acks"></a>acks</h3><p>acks 参数指定了必须要有多少个分区副本收到消息，生产者才会认为消息写入是成功的。这个参数对消息丢失的可能性有重要影响”</p>
<p>acks = 0:生产者在成功写入消息之前不会等待任何来自服务器的响应。也就是说，如果当中出现了问题，导致服务器没有收到消息，那么生产者就无从得知，消息也就丢失了</p>
<p>acks = 1:只要集群的首领节点收到消息，生产者就会收到一个来自服务器的成功响应。</p>
<p>acks = all:只有当所有参与复制的节点全部收到消息时，生产者才会收到一个来自服务器的成功响应。</p>
<h3 id="buffer-memory"><a href="#buffer-memory" class="headerlink" title="buffer.memory"></a>buffer.memory</h3><p>该参数用来设置生产者内存缓冲区的大小，生产者用它缓冲要发送到服务器的消息。</p>
<p>如果应用程序发送消息的速度超过发送到服务器的速度，会导致生产者空间不足。</p>
<p>这个时候， send() 方法调用要么被阻塞，要么抛出异常.</p>
<p>取决于如何设置 block.on.buffer.full 参数（在 0.9.0.0 版本里被替换成了 max.block.ms，表示在抛出异常之前可以阻塞一段时间）。</p>
<p>retries<br>产者从服务器收到的错误有可能是临时性的错误（比如分区找不到首领）。</p>
<p>在这种情况下，retries 参数的值决定了生产者可以重发消息的次数，如果达到这个次数，生产者会放弃重试并返回错误。</p>
<p>默认情况下，生产者会在每次重试之间等待 100ms，不过可以通过 retry.backoff.ms 参数来改变这个时间间隔。</p>
<p>建议在设置重试次数和重试时间间隔之前，先测试一下恢复一个崩溃节点需要多少时间（比如所有分区选举出首领需要多长时间），让总的重试时间比 Kafka 集群从崩溃中恢复的时间长，否则生产者会过早地放弃重试。不过有些错误不是临时性错误，没办法通过重试来解决（比如“消息太大”错误）。</p>
<p>一般情况下，因为生产者会自动进行重试，所以就没必要在代码逻辑里处理那些可重试的错误。只需要处理那些不可重试的错误或重试次数超出上限的情况。 </p>
<h3 id="batch-size"><a href="#batch-size" class="headerlink" title="batch.size"></a>batch.size</h3><p>“当有多个消息需要被发送到同一个分区时，生产者会把它们放在同一个批次里。</p>
<p>该参数指定了一个批次可以使用的内存大小，按照字节数计算（而不是消息个数）。</p>
<p>当批次被填满，批次里的所有消息会被发送出去。不过生产者并不一定都会等到批次被填满才发送，半满的批次，甚至只包含一个消息的批次也有可能被发送。</p>
<p>所以就算把批次大小设置得很大，也不会造成延迟，只是会占用更多的内存而已。但如果设置得太小，因为生产者需要更频繁地发送消息，会增加一些额外的开销”</p>
<h3 id="linger-ms"><a href="#linger-ms" class="headerlink" title="linger.ms"></a>linger.ms</h3><p>指定生产者在发送批次之前等待更多消息加入批次的时间。</p>
<p>KafkaProducer 会在批次填满或 linger.ms 达到上限时把批次发送出去。</p>
<p>默认情况下，只要有可用的线程，生产者就会把消息发送出去，就算批次里只有一个消息。</p>
<p>把 linger.ms 设置成比 0 大的数，让生产者在发送批次之前等待一会儿，使更多的消息加入到这个批次。</p>
<p>虽然这样会增加延迟，但也会提升吞吐量（因为一次性发送更多的消息，每个消息的开销就变小了）。</p>
<h2 id="分区"><a href="#分区" class="headerlink" title="分区"></a>分区</h2><h3 id="默认分区策略"><a href="#默认分区策略" class="headerlink" title="默认分区策略"></a>默认分区策略</h3><p>kafka消息可以是一个个键值对，键有两个作用：一个是作为消息的附加信息，也可以决定消息被写道主题哪个分区。</p>
<p>key为空且使用默认分区器，分区器使用轮询算法将消息均衡分不到各个分区。</p>
<p>如果key不为空且使用默认分区器，对key进行散列(kafka自己的散列算法)，每次都是散列到同一分区。<br>可能散列到的分区不可用，出现问题。<br>增加新分区也会出现问题，所以永远不要增加新分区</p>
<h3 id="自定义分区策略"><a href="#自定义分区策略" class="headerlink" title="自定义分区策略"></a>自定义分区策略</h3><p>实现Partitioner接口</p>
<h2 id="参考资料"><a href="#参考资料" class="headerlink" title="参考资料"></a>参考资料</h2><p>《kafka权威指南》</p>
]]></content>
      <categories>
        <category>技术</category>
        <category>消息队列</category>
        <category>Kafka</category>
      </categories>
      <tags>
        <tag>Kafka</tag>
      </tags>
  </entry>
  <entry>
    <title>Raft概述</title>
    <url>/2018/04/16/Raft%E6%A6%82%E8%BF%B0/</url>
    <content><![CDATA[<h2 id="概述"><a href="#概述" class="headerlink" title="概述"></a>概述</h2><p>RAFT协议作用是保证分布式系统同一数据的一致性（与2pc不同，2pc是保证多个数据的原子性）。</p>
<p>采取的方式是分布式系统中只有一个节点接收数据，然后向其他节点复制</p>
<p>在一个由 Raft 协议组织的集群中有三类角色：</p>
<ol>
<li>Leader（领袖）</li>
<li>Follower（群众）</li>
<li>Candidate（候选人）</li>
</ol>
<p>Raft将问题分解和具体化：Leader统一处理变更操作请求，一致性协议的作用具化为保证节点间操作日志副本(log replication)一致，以term作为逻辑时钟(logical clock)保证时序，节点运行相同状态机(state machine)得到一致结果。Raft协议具体过程如下：</p>
<a id="more"></a>
<p><img src="/img/15254237788398.jpg" alt></p>
<ol>
<li>Client发起请求，每一条请求包含操作指令</li>
<li>请求交由Leader处理，Leader将操作指令(entry)追加(append)至操作日志，紧接着对Follower发起AppendEntries请求、尝试让操作日志副本在Follower落地</li>
<li>如果Follower多数派(quorum)同意AppendEntries请求，Leader进行commit操作、把指令交由状态机处理</li>
<li>状态机处理完成后将结果返回给Client<br>指令通过log index(指令id)和term number保证时序，正常情况下Leader、Follower状态机按相同顺序执行指令，得出相同结果、状态一致。</li>
</ol>
<p>宕机、网络分化等情况可引起Leader重新选举(每次选举产生新Leader的同时，产生新的term)、Leader/Follower间状态不一致。Raft中Leader为自己和所有Follower各维护一个nextIndex值，其表示Leader紧接下来要处理的指令id以及将要发给Follower的指令id，LnextIndex不等于FnextIndex时代表Leader操作日志和Follower操作日志存在不一致，这时将从Follower操作日志中最初不一致的地方开始，由Leader操作日志覆盖Follower，直到LnextIndex、FnextIndex相等。</p>
<p>Paxos中Leader的存在是为了提升决议效率，Leader的有无和数目并不影响决议一致性，Raft要求具备唯一Leader，并把一致性问题具体化为保持日志副本的一致性，以此实现相较Paxos而言更容易理解、更容易实现的目标。</p>
<h3 id="RAFT论文"><a href="#RAFT论文" class="headerlink" title="RAFT论文"></a>RAFT论文</h3><p>论文讲的很详细了</p>
<blockquote>
<p><a href="https://github.com/maemual/raft-zh_cn" target="_blank" rel="noopener">https://github.com/maemual/raft-zh_cn</a></p>
</blockquote>
<h3 id="一个简单的例子"><a href="#一个简单的例子" class="headerlink" title="一个简单的例子"></a>一个简单的例子</h3><blockquote>
<p><a href="https://mp.weixin.qq.com/s/MZlJFSOCm0c7ak7CIKL5MQ" target="_blank" rel="noopener">https://mp.weixin.qq.com/s/MZlJFSOCm0c7ak7CIKL5MQ</a></p>
</blockquote>
<h3 id="动画方式展示原理"><a href="#动画方式展示原理" class="headerlink" title="动画方式展示原理"></a>动画方式展示原理</h3><blockquote>
<p><a href="http://thesecretlivesofdata.com/raft/" target="_blank" rel="noopener">http://thesecretlivesofdata.com/raft/</a></p>
</blockquote>
<p>相比于Paxos，Raft最大的特点就是可理解性。<br>Raft把一致性问题，分解成三个比较独立的子问题，并给出每个子问题的解决方法。</p>
<h2 id="选举"><a href="#选举" class="headerlink" title="选举"></a>选举</h2><p>当现存的领导人不存在时，需要选举新的领导人。</p>
<h3 id="任期-term"><a href="#任期-term" class="headerlink" title="任期(term)"></a>任期(term)</h3><p><img src="/img/15254217092487.jpg" alt></p>
<p>Raft 算法将时间划分成为任意不同长度的任期（term）。任期用连续的数字进行表示。<br>每一个任期的开始都是一次选举（election），一个或多个候选人会试图成为领导人。每次选举任期号都增加。<br>如果一个候选人赢得了选举，它就会在该任期的剩余时间担任领导人。<br>在某些情况下，选票会被瓜分，有可能没有选出领导人，那么，将会开始<strong>另一个任期</strong>，并且立刻开始下一次选举。<br>Raft 算法保证在给定的一个任期最多只有一个领导人。</p>
<h3 id="触发条件"><a href="#触发条件" class="headerlink" title="触发条件"></a>触发条件</h3><ol>
<li>一般情况下，追随者接到领导者的心跳时，把ElectionTimeout（后面会讲election timeout）清零，不会触发；</li>
<li>领导者故障，追随者的ElectionTimeout超时发生时，会变成候选者，触发领导人选取</li>
</ol>
<h3 id="选举过程"><a href="#选举过程" class="headerlink" title="选举过程"></a>选举过程</h3><ol>
<li>每个节点以follower启动。</li>
<li>每个节点设置一个150-300ms的随机超时时间（election timeout)，没有接收到leader消息时，变成candinate。</li>
<li>candinate要求其他节点投票。</li>
<li>各节点投票。</li>
<li>如果超过半数投票，candinate变成leader。</li>
</ol>
<p>有两个超时时间控制选举过程。</p>
<h3 id="election-timeout"><a href="#election-timeout" class="headerlink" title="election timeout"></a>election timeout</h3><ol>
<li>follower等待这个时间，超过这个时间变为candinate，发起新的选举。</li>
<li>如果其他follower在该任期内没投过票，就会给发起投票的candinate投票。并重置自己的election timeout。</li>
<li>超过半数投票，candinate变为leader</li>
<li>leader开始向followers发送Append Entries(包含心跳信息及日志）消息。</li>
</ol>
<h3 id="heartbeat-timeout"><a href="#heartbeat-timeout" class="headerlink" title="heartbeat timeout"></a>heartbeat timeout</h3><ol>
<li>leader 必须在 heartbeat timeout 间隔内发送Append Entries消息。</li>
<li>follower会响应每个Append Entries消息，重置自己的election timeout。</li>
<li>在follower停止接收heartbeats并且成为candinate时，停止选举过程</li>
</ol>
<h2 id="日志复制"><a href="#日志复制" class="headerlink" title="日志复制"></a>日志复制</h2><p>描述Raft的leader是如何把日志复制到集群的各个节点上的。</p>
<p>领导人必须从客户端接收日志然后复制到集群中的其他节点，并且强制要求其他节点的日志保持和自己相同。</p>
<h3 id="日志复制过程"><a href="#日志复制过程" class="headerlink" title="日志复制过程"></a>日志复制过程</h3><ol>
<li>客户端请求只经过leader。</li>
<li>每个变化都作为entry加到leader日志中。</li>
<li>log entry是uncomitted状态，所以不会更新节点值。</li>
<li>将日志同步到follower节点，完成更新节点值。</li>
<li>leader等待超过半数follower更新成功。</li>
<li>leader entry状态变为commited。</li>
<li>leader通知entry状态为commited。</li>
<li>响应客户端。</li>
</ol>
<h2 id="安全性"><a href="#安全性" class="headerlink" title="安全性"></a>安全性</h2><table>
<thead>
<tr>
<th>特性</th>
<th>解释</th>
</tr>
</thead>
<tbody>
<tr>
<td>日志匹配原则</td>
<td>如果两个日志在相同的索引位置的日志条目的任期号相同，那么我们就认为这个日志从头到这个索引位置之间全部完全相同（5.3 log replication 节）if two logs contain an entry with the same index and term, then the logs are identical in all entries up through the given index.</td>
</tr>
<tr>
<td>状态机安全特性</td>
<td>如果一个领导人已经在给定的索引值位置的日志条目应用到状态机中，那么其他任何的服务器在这个索引位置不会提交一个不同的日志（5.4.3 安全性论证 节）if a server has applied a particular log entry to its state machine, then no other server may apply a different command for the same log.</td>
</tr>
<tr>
<td>选举安全特性</td>
<td>对于一个给定的任期号，最多只会有一个领导人被选举出来（5.2 leader election 节）at most one leader can be elected in a given term.</td>
</tr>
<tr>
<td>领导人只附加原则</td>
<td>领导人绝对不会删除或者覆盖自己的日志，只会增加（5.3 log replication 节）a leader can only append new entries to its logs (it can neither overwrite nor delete entries).</td>
</tr>
<tr>
<td>领导人完全特性</td>
<td>如果某个日志条目在某个任期号中已经被提交，那么这个条目必然出现在更大任期号的所有领导人中（5.4 安全性 节）if a log entry is committed in a given term then it will be present in the logs of the leaders since this term</td>
</tr>
</tbody>
</table>
<p>一个跟随者可能会进入不可用状态同时领导人已经提交了若干的日志条目，然后这个跟随者可能会被选举为领导人并且覆盖这些日志条目；因此，不同的状态机可能会执行不同的指令序列。</p>
<p>这一节通过在领导选举的时候增加一些限制来完善 Raft 算法。这一限制保证了任何的领导人对于给定的任期号，都拥有了之前任期的所有被提交的日志条目。</p>
<p>增加这一选举时的限制，我们对于提交时的规则也更加清晰。</p>
<p><strong>Raft 保证，只有包含了所有已经提交的日志条目的候选人才有可能赢得选举。</strong><br>候选人为了赢得选举必须联系集群中的大部分节点，这意味着每一个已经提交的日志条目在这些服务器节点中肯定存在于至少一个节点上。</p>
<p>如果候选人的日志至少和大多数的服务器节点一样新（这个新的定义会在下面讨论），那么他一定持有了所有已经提交的日志条目。</p>
<p>请求投票 RPC 实现了这样的限制： RPC 中包含了候选人的日志信息，然后投票人会拒绝掉那些日志没有自己新的投票请求。</p>
<p>Raft 通过比较两份日志中最后一条日志条目的索引值和任期号定义谁的日志比较新：</p>
<ul>
<li>如果两份日志最后的条目的任期号不同，那么任期号大的日志更加新。</li>
<li>如果两份日志最后的条目任期号相同，那么日志比较长的那个就更加新。</li>
</ul>
<p>**Raft 永远不会通过计算副本数目的方式去提交一个之前任期内的日志条目。只有领导人当前任期里的日志条目通过计算副本数目可以被提交；</p>
<p>一旦当前任期的日志条目以这种方式被提交，那么由于日志匹配特性，之前的日志条目也都会被间接的提交。（Leader可以复制前面任期的日志，但是不会主动提交前面任期的日志。而是通过提交当前任期的日志，而间接地提交前面任期的日志）</p>
<p>在某些情况下，领导人可以安全的知道一个老的日志条目是否已经被提交（例如，该条目是否存储到所有服务器上），但是 Raft 为了简化问题使用一种更加保守的方法。</p>
<p>当领导人复制之前任期里的日志时，Raft 会为所有日志保留原始的任期号, 这在提交规则上产生了额外的复杂性。在其他的一致性算法中，如果一个新的领导人要重新复制之前的任期里的日志时，它必须使用当前新的任期号。Raft 使用的方法更加容易辨别出日志，因为它可以随着时间和日志的变化对日志维护着同一个任期编号。另外，和其他的算法相比，Raft 中的新领导人只需要发送更少日志条目（其他算法中必须在他们被提交之前发送更多的冗余日志条目来为他们重新编号).**</p>
<p>为了消除上述场景就规定Leader可以复制前面任期的日志，但是不会主动提交前面任期的日志。而是通过提交当前任期的日志，而间接地提交前面任期的日志。</p>
<h3 id="时间和可用性"><a href="#时间和可用性" class="headerlink" title="时间和可用性"></a>时间和可用性</h3><p>Raft 的要求之一就是安全性不能依赖时间：整个系统不能因为某些事件运行的比预期快一点或者慢一点就产生了错误的结果。但是，可用性（系统可以及时的响应客户端）不可避免的要依赖于时间。例如，如果消息交换在服务器崩溃时花费更多的时间，候选人将不会等待太长的时间来赢得选举；没有一个稳定的领导人，Raft 将无法工作。</p>
<p>领导人选举是 Raft 中对时间要求最为关键的方面。Raft 可以选举并维持一个稳定的领导人,只要系统满足下面的时间要求：</p>
<blockquote>
<p>广播时间（broadcastTime） &lt;&lt; 选举超时时间（electionTimeout） &lt;&lt; 平均故障间隔时间（MTBF）</p>
</blockquote>
<p>在这个不等式中，广播时间指的是从一个服务器并行的发送 RPCs 给集群中的其他服务器并接收响应的平均时间；</p>
<p>选举超时时间就是在 5.2 节中介绍的选举的超时时间限制；</p>
<p>然后平均故障间隔时间就是对于一台服务器而言，两次故障之间的平均时间。</p>
<p>广播时间必须比选举超时时间小一个量级，这样领导人才能够发送稳定的心跳消息来阻止跟随者开始进入选举状态；通过随机化选举超时时间的方法，这个不等式也使得选票瓜分的情况变得不可能。</p>
<p>选举超时时间应该要比平均故障间隔时间小上几个数量级，这样整个系统才能稳定的运行。当领导人崩溃后，整个系统会大约相当于选举超时的时间里不可用；我们希望这种情况在整个系统的运行中很少出现。</p>
<p>广播时间和平均故障间隔时间是由系统决定的，但是选举超时时间是我们自己选择的。Raft 的 RPCs 需要接收方将信息持久化的保存到稳定存储中去，所以广播时间大约是 0.5 毫秒到 20 毫秒，取决于存储的技术。因此，选举超时时间可能需要在 10 毫秒到 500 毫秒之间。大多数的服务器的平均故障间隔时间都在几个月甚至更长，很容易满足时间的需求。</p>
<h2 id="应用"><a href="#应用" class="headerlink" title="应用"></a>应用</h2><ol>
<li>ETCD</li>
<li>百度云 braft</li>
</ol>
<h2 id="推荐资料"><a href="#推荐资料" class="headerlink" title="推荐资料"></a>推荐资料</h2><ol>
<li><a href="http://thesecretlivesofdata.com/raft/" target="_blank" rel="noopener">http://thesecretlivesofdata.com/raft/</a> </li>
<li><a href="https://github.com/maemual/raft-zh_cn/blob/master/raft-zh_cn.md" target="_blank" rel="noopener">https://github.com/maemual/raft-zh_cn/blob/master/raft-zh_cn.md</a></li>
<li><a href="https://www.cnblogs.com/mindwind/p/5231986.html" target="_blank" rel="noopener">https://www.cnblogs.com/mindwind/p/5231986.html</a></li>
<li><a href="https://raft.github.io/" target="_blank" rel="noopener">https://raft.github.io/</a></li>
<li><a href="https://cloud.tencent.com/developer/article/1005803" target="_blank" rel="noopener">https://cloud.tencent.com/developer/article/1005803</a></li>
</ol>
]]></content>
      <categories>
        <category>技术</category>
        <category>分布式</category>
        <category>一致性</category>
        <category>Raft</category>
      </categories>
      <tags>
        <tag>分布式</tag>
        <tag>Raft</tag>
      </tags>
  </entry>
  <entry>
    <title>访问者模式</title>
    <url>/2018/03/18/%E8%AE%BF%E9%97%AE%E8%80%85%E6%A8%A1%E5%BC%8F/</url>
    <content><![CDATA[<h2 id="定义"><a href="#定义" class="headerlink" title="定义"></a>定义</h2><p>提供一个作用于某对象结构中的各元素的操作表示，它使我们可以在不改变各元素的类的前提下定义作用于这些元素的新操作，属于行为型模式(创建型、结构型、行为型）</p>
<h2 id="解决问题"><a href="#解决问题" class="headerlink" title="解决问题"></a>解决问题</h2><p>操作<strong>复杂对象结构</strong>，将数据与操作分离。稳定的数据结构和易变的操作耦合问题。</p>
<h2 id="何时使用"><a href="#何时使用" class="headerlink" title="何时使用"></a>何时使用</h2><p>需要对一个对象结构中的对象进行很多不同的并且不相关的操作，而需要避免让这些操作”污染”这些对象的类，使用访问者模式将这些封装到类中。</p>
<a id="more"></a>
<h2 id="应用实例"><a href="#应用实例" class="headerlink" title="应用实例"></a>应用实例</h2><p>在医生开具处方单（药单）后，很多医院都存在如下处理流程：</p>
<ol>
<li>划价人员拿到  <strong>处方单</strong>  之后根据 <strong>药品名称和数量</strong>    <strong>计算总价</strong></li>
<li>药房工作人员根据 <strong>药品名称和数量</strong>   <strong>准备药品</strong></li>
</ol>
<p><img src="/img/15255288247167.jpg" alt></p>
<ol>
<li>我们可以将处方单看成一个药品信息的集合，里面包含了一种或多种不同类型的药品信息。</li>
<li>不同类型的工作人员（如划价人员和药房工作人员）在操作同一个药品信息集合时将提供不同的处理方式，而且可能还会增加新类型的工作人员来操作处方单。</li>
</ol>
<h2 id="如何解决"><a href="#如何解决" class="headerlink" title="如何解决"></a>如何解决</h2><p>在被访问的类里面加一个对外提供接待访问者的接口。</p>
<h2 id="类图"><a href="#类图" class="headerlink" title="类图"></a>类图</h2><p><img src="/img/15255288648498.jpg" alt></p>
<p>在访问者模式结构图中包含如下几个角色：</p>
<p>●Vistor（抽象访问者）：抽象访问者为对象结构中每一个具体元素类ConcreteElement声明一个访问操作，从这个操作的名称或参数类型可以清楚知道需要访问的具体元素的类型，具体访问者需要实现这些操作方法，定义对这些元素的访问操作。</p>
<p>●ConcreteVisitor（具体访问者）：具体访问者实现了每个由抽象访问者声明的操作，每一个操作用于访问对象结构中一种类型的元素。</p>
<p>●Element（抽象元素）：抽象元素一般是抽象类或者接口，它定义一个accept()方法，该方法通常以一个抽象访问者作为参数。【稍后将介绍为什么要这样设计。】</p>
<p>●ConcreteElement（具体元素）：具体元素实现了accept()方法，在accept()方法中调用访问者的访问方法以便完成对一个元素的操作。</p>
<p>● ObjectStructure（对象结构）：对象结构是一个元素的集合，它用于存放元素对象，并且提供了遍历其内部元素的方法。它可以结合组合模式来实现，也可以是一个简单的集合对象，如一个List对象或一个Set对象。</p>
<h2 id="关键代码"><a href="#关键代码" class="headerlink" title="关键代码"></a>关键代码</h2><p>在数据基础类里面有一个方法接受访问者，将自身引用传入访问者。</p>
<h3 id="类结构"><a href="#类结构" class="headerlink" title="类结构"></a>类结构</h3><p><img src="/img/15255288942840.jpg" alt></p>
<h3 id="抽象元素-药"><a href="#抽象元素-药" class="headerlink" title="抽象元素 药"></a>抽象元素 药</h3><figure class="highlight java"><table><tr><td class="code"><pre><span class="line"><span class="keyword">package</span> com.ytf.pattern.visitor.element;</span><br><span class="line"> </span><br><span class="line"><span class="keyword">import</span> com.ytf.pattern.visitor.visitor.MedicalStaff;</span><br><span class="line"> </span><br><span class="line"><span class="comment">/**</span></span><br><span class="line"><span class="comment"> * Created by yutianfang</span></span><br><span class="line"><span class="comment"> * DATE: 18/3/18星期日.</span></span><br><span class="line"><span class="comment"> */</span></span><br><span class="line"><span class="keyword">public</span> <span class="keyword">abstract</span> <span class="class"><span class="keyword">class</span> <span class="title">AbstractMedicine</span> </span>&#123;</span><br><span class="line">    <span class="keyword">protected</span> <span class="keyword">int</span> price;</span><br><span class="line">    <span class="keyword">protected</span> String name;</span><br><span class="line"> </span><br><span class="line">    <span class="function"><span class="keyword">public</span> <span class="keyword">int</span> <span class="title">getPrice</span><span class="params">()</span> </span>&#123;</span><br><span class="line">        <span class="keyword">return</span> price;</span><br><span class="line">    &#125;</span><br><span class="line"> </span><br><span class="line">    <span class="function"><span class="keyword">public</span> AbstractMedicine <span class="title">setPrice</span><span class="params">(<span class="keyword">int</span> price)</span> </span>&#123;</span><br><span class="line">        <span class="keyword">this</span>.price = price;</span><br><span class="line">        <span class="keyword">return</span> <span class="keyword">this</span>;</span><br><span class="line">    &#125;</span><br><span class="line"> </span><br><span class="line">    <span class="function"><span class="keyword">public</span> String <span class="title">getName</span><span class="params">()</span> </span>&#123;</span><br><span class="line">        <span class="keyword">return</span> name;</span><br><span class="line">    &#125;</span><br><span class="line"> </span><br><span class="line">    <span class="function"><span class="keyword">public</span> AbstractMedicine <span class="title">setName</span><span class="params">(String name)</span> </span>&#123;</span><br><span class="line">        <span class="keyword">this</span>.name = name;</span><br><span class="line">        <span class="keyword">return</span> <span class="keyword">this</span>;</span><br><span class="line">    &#125;</span><br><span class="line"> </span><br><span class="line">    <span class="function"><span class="keyword">public</span> <span class="keyword">abstract</span> <span class="keyword">void</span> <span class="title">accept</span><span class="params">(MedicalStaff medicalStaff)</span></span>;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<h3 id="具体元素"><a href="#具体元素" class="headerlink" title="具体元素"></a>具体元素</h3><h4 id="感冒药"><a href="#感冒药" class="headerlink" title="感冒药"></a>感冒药</h4><figure class="highlight java"><table><tr><td class="code"><pre><span class="line"><span class="keyword">package</span> com.ytf.pattern.visitor.element.impl;</span><br><span class="line"> </span><br><span class="line"><span class="keyword">import</span> com.ytf.pattern.visitor.element.AbstractMedicine;</span><br><span class="line"><span class="keyword">import</span> com.ytf.pattern.visitor.visitor.MedicalStaff;</span><br><span class="line"> </span><br><span class="line"><span class="comment">/**</span></span><br><span class="line"><span class="comment"> * Created by yutianfang</span></span><br><span class="line"><span class="comment"> * DATE: 18/3/18星期日.</span></span><br><span class="line"><span class="comment"> */</span></span><br><span class="line"><span class="keyword">public</span> <span class="class"><span class="keyword">class</span> <span class="title">ColdMedicine</span> <span class="keyword">extends</span> <span class="title">AbstractMedicine</span> </span>&#123;</span><br><span class="line"> </span><br><span class="line">    <span class="meta">@Override</span></span><br><span class="line">    <span class="function"><span class="keyword">public</span> <span class="keyword">void</span> <span class="title">accept</span><span class="params">(MedicalStaff medicalStaff)</span> </span>&#123;</span><br><span class="line">        medicalStaff.visit(<span class="keyword">this</span>);</span><br><span class="line">    &#125;</span><br><span class="line"> </span><br><span class="line">    <span class="function"><span class="keyword">public</span> <span class="title">ColdMedicine</span><span class="params">()</span></span>&#123;</span><br><span class="line">        <span class="keyword">super</span>();</span><br><span class="line">        <span class="keyword">this</span>.name = <span class="string">"感冒药"</span>;</span><br><span class="line">        <span class="keyword">this</span>.price = <span class="number">10</span>;</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<h4 id="晕车药"><a href="#晕车药" class="headerlink" title="晕车药"></a>晕车药</h4><figure class="highlight java"><table><tr><td class="code"><pre><span class="line"><span class="keyword">package</span> com.ytf.pattern.visitor.element.impl;</span><br><span class="line"> </span><br><span class="line"><span class="keyword">import</span> com.ytf.pattern.visitor.element.AbstractMedicine;</span><br><span class="line"><span class="keyword">import</span> com.ytf.pattern.visitor.visitor.MedicalStaff;</span><br><span class="line"> </span><br><span class="line"><span class="comment">/**</span></span><br><span class="line"><span class="comment"> * Created by yutianfang</span></span><br><span class="line"><span class="comment"> * DATE: 18/3/18星期日.</span></span><br><span class="line"><span class="comment"> */</span></span><br><span class="line"><span class="keyword">public</span> <span class="class"><span class="keyword">class</span> <span class="title">CarSickMedicine</span> <span class="keyword">extends</span> <span class="title">AbstractMedicine</span> </span>&#123;</span><br><span class="line">    <span class="meta">@Override</span></span><br><span class="line">    <span class="function"><span class="keyword">public</span> <span class="keyword">void</span> <span class="title">accept</span><span class="params">(MedicalStaff medicalStaff)</span> </span>&#123;</span><br><span class="line">        medicalStaff.visit(<span class="keyword">this</span>);</span><br><span class="line">    &#125;</span><br><span class="line"> </span><br><span class="line">    <span class="function"><span class="keyword">public</span> <span class="title">CarSickMedicine</span><span class="params">()</span></span>&#123;</span><br><span class="line">        <span class="keyword">this</span>.name = <span class="string">"晕车药"</span>;</span><br><span class="line">        <span class="keyword">this</span>.price = <span class="number">20</span>;</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<h3 id="对象结构"><a href="#对象结构" class="headerlink" title="对象结构"></a>对象结构</h3><h4 id="药单"><a href="#药单" class="headerlink" title="药单"></a>药单</h4><figure class="highlight java"><table><tr><td class="code"><pre><span class="line"><span class="keyword">package</span> com.ytf.pattern.visitor.element.impl;</span><br><span class="line"> </span><br><span class="line"><span class="comment">/**</span></span><br><span class="line"><span class="comment"> * Created by yutianfang</span></span><br><span class="line"><span class="comment"> * DATE: 18/3/18星期日.</span></span><br><span class="line"><span class="comment"> */</span></span><br><span class="line"> </span><br><span class="line"><span class="keyword">import</span> com.ytf.pattern.visitor.element.AbstractMedicine;</span><br><span class="line"><span class="keyword">import</span> com.ytf.pattern.visitor.visitor.MedicalStaff;</span><br><span class="line"> </span><br><span class="line"><span class="keyword">import</span> java.util.ArrayList;</span><br><span class="line"><span class="keyword">import</span> java.util.List;</span><br><span class="line"> </span><br><span class="line"><span class="comment">/**</span></span><br><span class="line"><span class="comment"> * 药单</span></span><br><span class="line"><span class="comment"> */</span></span><br><span class="line"><span class="keyword">public</span> <span class="class"><span class="keyword">class</span> <span class="title">Prescription</span> <span class="keyword">extends</span> <span class="title">AbstractMedicine</span> </span>&#123;</span><br><span class="line"> </span><br><span class="line">    <span class="keyword">private</span> List&lt;AbstractMedicine&gt; medicines = <span class="keyword">new</span> ArrayList&lt;&gt;();</span><br><span class="line"> </span><br><span class="line">    <span class="meta">@Override</span></span><br><span class="line">    <span class="function"><span class="keyword">public</span> <span class="keyword">void</span> <span class="title">accept</span><span class="params">(MedicalStaff medicalStaff)</span> </span>&#123;</span><br><span class="line">        medicines.forEach(medicine -&gt; &#123;</span><br><span class="line">            medicine.accept(medicalStaff);</span><br><span class="line">        &#125;);</span><br><span class="line">    &#125;</span><br><span class="line"> </span><br><span class="line">    <span class="function"><span class="keyword">public</span> <span class="title">Prescription</span><span class="params">()</span></span>&#123;</span><br><span class="line">        ColdMedicine coldMedicine = <span class="keyword">new</span> ColdMedicine();</span><br><span class="line">        CarSickMedicine carSickMedicine = <span class="keyword">new</span> CarSickMedicine();</span><br><span class="line">        medicines.add(coldMedicine);</span><br><span class="line">        medicines.add(carSickMedicine);</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<h3 id="抽象访问者-医护人员"><a href="#抽象访问者-医护人员" class="headerlink" title="抽象访问者 医护人员"></a>抽象访问者 医护人员</h3><figure class="highlight java"><table><tr><td class="code"><pre><span class="line"><span class="keyword">package</span> com.ytf.pattern.visitor.visitor;</span><br><span class="line"> </span><br><span class="line"><span class="keyword">import</span> com.ytf.pattern.visitor.element.impl.CarSickMedicine;</span><br><span class="line"><span class="keyword">import</span> com.ytf.pattern.visitor.element.impl.ColdMedicine;</span><br><span class="line"> </span><br><span class="line"><span class="comment">/**</span></span><br><span class="line"><span class="comment"> * Created by yutianfang</span></span><br><span class="line"><span class="comment"> * DATE: 18/3/18星期日.</span></span><br><span class="line"><span class="comment"> */</span></span><br><span class="line"> </span><br><span class="line"><span class="comment">/**</span></span><br><span class="line"><span class="comment"> * 医护人员</span></span><br><span class="line"><span class="comment"> */</span></span><br><span class="line"><span class="keyword">public</span> <span class="class"><span class="keyword">interface</span> <span class="title">MedicalStaff</span> </span>&#123;</span><br><span class="line">    <span class="function"><span class="keyword">void</span> <span class="title">visit</span><span class="params">(ColdMedicine coldMedicine)</span></span>;</span><br><span class="line">    <span class="function"><span class="keyword">void</span> <span class="title">visit</span><span class="params">(CarSickMedicine carSickMedicine)</span></span>;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<h3 id="具体访问者"><a href="#具体访问者" class="headerlink" title="具体访问者"></a>具体访问者</h3><h4 id="划价人员"><a href="#划价人员" class="headerlink" title="划价人员"></a>划价人员</h4><figure class="highlight java"><table><tr><td class="code"><pre><span class="line"><span class="keyword">package</span> com.ytf.pattern.visitor.visitor.impl;</span><br><span class="line"> </span><br><span class="line"><span class="keyword">import</span> com.ytf.pattern.visitor.element.impl.CarSickMedicine;</span><br><span class="line"><span class="keyword">import</span> com.ytf.pattern.visitor.element.impl.ColdMedicine;</span><br><span class="line"><span class="keyword">import</span> com.ytf.pattern.visitor.visitor.MedicalStaff;</span><br><span class="line"> </span><br><span class="line"><span class="comment">/**</span></span><br><span class="line"><span class="comment"> * Created by yutianfang</span></span><br><span class="line"><span class="comment"> * DATE: 18/3/18星期日.</span></span><br><span class="line"><span class="comment"> */</span></span><br><span class="line"><span class="keyword">public</span> <span class="class"><span class="keyword">class</span> <span class="title">Pricing</span> <span class="keyword">implements</span> <span class="title">MedicalStaff</span> </span>&#123;</span><br><span class="line">    <span class="meta">@Override</span></span><br><span class="line">    <span class="function"><span class="keyword">public</span> <span class="keyword">void</span> <span class="title">visit</span><span class="params">(ColdMedicine coldMedicine)</span> </span>&#123;</span><br><span class="line">        System.out.println(<span class="string">"划价："</span> + coldMedicine.getName() + <span class="string">"，价格："</span> + coldMedicine.getPrice());</span><br><span class="line">    &#125;</span><br><span class="line"> </span><br><span class="line">    <span class="meta">@Override</span></span><br><span class="line">    <span class="function"><span class="keyword">public</span> <span class="keyword">void</span> <span class="title">visit</span><span class="params">(CarSickMedicine carSickMedicine)</span> </span>&#123;</span><br><span class="line">        System.out.println(<span class="string">"划价："</span> + carSickMedicine.getName() + <span class="string">"，价格："</span> + carSickMedicine.getPrice());</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<h4 id="取药人员"><a href="#取药人员" class="headerlink" title="取药人员"></a>取药人员</h4><figure class="highlight java"><table><tr><td class="code"><pre><span class="line"><span class="keyword">package</span> com.ytf.pattern.visitor.visitor.impl;</span><br><span class="line"> </span><br><span class="line"><span class="keyword">import</span> com.ytf.pattern.visitor.element.impl.CarSickMedicine;</span><br><span class="line"><span class="keyword">import</span> com.ytf.pattern.visitor.element.impl.ColdMedicine;</span><br><span class="line"><span class="keyword">import</span> com.ytf.pattern.visitor.visitor.MedicalStaff;</span><br><span class="line"> </span><br><span class="line"><span class="comment">/**</span></span><br><span class="line"><span class="comment"> * Created by yutianfang</span></span><br><span class="line"><span class="comment"> * DATE: 18/3/18星期日.</span></span><br><span class="line"><span class="comment"> */</span></span><br><span class="line"> </span><br><span class="line"><span class="comment">/**</span></span><br><span class="line"><span class="comment"> * 药房取药</span></span><br><span class="line"><span class="comment"> */</span></span><br><span class="line"><span class="keyword">public</span> <span class="class"><span class="keyword">class</span> <span class="title">Pharmacy</span> <span class="keyword">implements</span> <span class="title">MedicalStaff</span> </span>&#123;</span><br><span class="line">    <span class="meta">@Override</span></span><br><span class="line">    <span class="function"><span class="keyword">public</span> <span class="keyword">void</span> <span class="title">visit</span><span class="params">(ColdMedicine coldMedicine)</span> </span>&#123;</span><br><span class="line">        System.out.println(<span class="string">"取药："</span> + coldMedicine.getName());</span><br><span class="line">    &#125;</span><br><span class="line"> </span><br><span class="line">    <span class="meta">@Override</span></span><br><span class="line">    <span class="function"><span class="keyword">public</span> <span class="keyword">void</span> <span class="title">visit</span><span class="params">(CarSickMedicine carSickMedicine)</span> </span>&#123;</span><br><span class="line">        System.out.println(<span class="string">"取药："</span> + carSickMedicine.getName());</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<h3 id="客户端"><a href="#客户端" class="headerlink" title="客户端"></a>客户端</h3><figure class="highlight java"><table><tr><td class="code"><pre><span class="line"><span class="keyword">package</span> com.ytf.pattern.visitor;</span><br><span class="line"> </span><br><span class="line"><span class="keyword">import</span> com.ytf.pattern.visitor.element.impl.Prescription;</span><br><span class="line"><span class="keyword">import</span> com.ytf.pattern.visitor.visitor.impl.Pharmacy;</span><br><span class="line"><span class="keyword">import</span> com.ytf.pattern.visitor.visitor.impl.Pricing;</span><br><span class="line"> </span><br><span class="line"><span class="comment">/**</span></span><br><span class="line"><span class="comment"> * Created by yutianfang</span></span><br><span class="line"><span class="comment"> * DATE: 18/3/18星期日.</span></span><br><span class="line"><span class="comment"> */</span></span><br><span class="line"><span class="keyword">public</span> <span class="class"><span class="keyword">class</span> <span class="title">Client</span> </span>&#123;</span><br><span class="line">    <span class="function"><span class="keyword">public</span> <span class="keyword">static</span> <span class="keyword">void</span> <span class="title">main</span><span class="params">(String[] args)</span></span>&#123;</span><br><span class="line">        <span class="comment">// 药单</span></span><br><span class="line">        Prescription prescription = <span class="keyword">new</span> Prescription();</span><br><span class="line"> </span><br><span class="line">        <span class="comment">// 划价</span></span><br><span class="line">        Pricing pricing = <span class="keyword">new</span> Pricing();</span><br><span class="line">        prescription.accept(pricing);</span><br><span class="line"> </span><br><span class="line">        <span class="comment">// 取药</span></span><br><span class="line">        Pharmacy pharmacy = <span class="keyword">new</span> Pharmacy();</span><br><span class="line">        prescription.accept(pharmacy);</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<h3 id="输出"><a href="#输出" class="headerlink" title="输出"></a>输出</h3><p><img src="/img/15255293069565.jpg" alt></p>
<h2 id="优点"><a href="#优点" class="headerlink" title="优点"></a>优点</h2><ol>
<li>符合单一职责原则。</li>
<li>优秀的扩展性。 </li>
<li>灵活性。</li>
</ol>
<h2 id="缺点"><a href="#缺点" class="headerlink" title="缺点"></a>缺点</h2><ol>
<li>具体元素对访问者公布细节，违反了迪米特原则。</li>
<li>具体元素变更比较困难。 增加具体元素时，访问者也需要添加。</li>
<li>违反了依赖倒置原则，依赖了具体类，没有依赖抽象。</li>
</ol>
<h3 id="使用场景"><a href="#使用场景" class="headerlink" title="使用场景"></a>使用场景</h3><ol>
<li>对象结构中对象对应的类很少改变，但经常需要在此对象结构上定义新的操作。</li>
<li>需要对一个对象结构中的对象进行很多不同的并且不相关的操作，而需要避免让这些操作”污染”这些对象的类，也不希望在增加新操作时修改这些类。</li>
</ol>
]]></content>
      <categories>
        <category>技术</category>
        <category>设计模式</category>
      </categories>
      <tags>
        <tag>设计模式</tag>
        <tag>访问者模式</tag>
      </tags>
  </entry>
  <entry>
    <title>美团点评内推</title>
    <url>/2018/02/26/%E7%BE%8E%E5%9B%A2%E7%82%B9%E8%AF%84%E5%86%85%E6%8E%A8/</url>
    <content><![CDATA[<p><strong>此内推长期有效</strong></p>
<h2 id="我是谁"><a href="#我是谁" class="headerlink" title="我是谁"></a>我是谁</h2><p>一名后端工程师，14年毕业后在华为干了两年，之后跳到新美大。目前就职新美大餐饮生态部门。</p>
<h2 id="新美大是家什么样的公司？"><a href="#新美大是家什么样的公司？" class="headerlink" title="新美大是家什么样的公司？"></a>新美大是家什么样的公司？</h2><p>“一家以科学技术追求真理的投资公司”，相信这一定位让大家吃惊不少。<br>目前新美大是中国最大的生活服务电商平台，旗下较知名产品：</p>
<h4 id="猫眼：中国最大电影O2O平台"><a href="#猫眼：中国最大电影O2O平台" class="headerlink" title="猫眼：中国最大电影O2O平台"></a>猫眼：中国最大电影O2O平台</h4><h4 id="美团外卖：中国最大外卖平台"><a href="#美团外卖：中国最大外卖平台" class="headerlink" title="美团外卖：中国最大外卖平台"></a>美团外卖：中国最大外卖平台</h4><h4 id="美团酒店：中国最大移动端酒店预定平台"><a href="#美团酒店：中国最大移动端酒店预定平台" class="headerlink" title="美团酒店：中国最大移动端酒店预定平台"></a>美团酒店：中国最大移动端酒店预定平台</h4><p>以及正在大力发展的<strong>餐饮生态</strong>、<strong>美团打车</strong>、<strong>生鲜</strong>等。<br>可以说新美大是行业内绝对的领头羊，在行业内进行最新的探索，解决最前沿的问题。</p>
<a id="more"></a>
<h2 id="加入新美大可以收获什么？"><a href="#加入新美大可以收获什么？" class="headerlink" title="加入新美大可以收获什么？"></a>加入新美大可以收获什么？</h2><pre><code>1.有竞争的薪酬。特别说明下，美团每年的普调是业界一致认可的。
2.个人能力的持续提成：
  新美大有完善的培养体系，包括不限于：
  - 导师制度；
  - 日均1.4次的分享(公司大牛们的分享，以及从业界请来的专家）
  - 每年两次的晋升机会；达到一定职级后的管理培训等。
  充满挑战的工作内容：
  - 参与解决最前沿的问题，在大牛们的带领下快速成长；
  - 作为面试官筛选优秀候选人等。
3.融洽的团队：新美大的团队氛围真的非常好，年轻人多，元气满满，欢乐多多。
我们回访过很多校招生，对新美大的团队氛围是最满意的。
4.你的终生伴侣：帅哥、美女真的很多。
</code></pre><h2 id="其他福利"><a href="#其他福利" class="headerlink" title="其他福利"></a>其他福利</h2><pre><code>1.员工俱乐部：多到我都不知道竟然还有这个俱乐部。
篮球、足球、羽毛球、桌球、网球、乒乓球、
街舞、瑜伽、游泳、跑步、健身、
公益、丘比特、摄影、吉他、桌游、自行车、美食、酷歌。。
</code></pre><p><img src="/img/15196314938824.jpg" alt></p>
<p><img src="/img/15196316813074.jpg" alt></p>
<p><img src="/img/15196324202637.jpg" alt></p>
<pre><code>2.入职纪念日：在这里的每一步成长，都值得被期待和铭记，每一年的入职纪念日都有公司定制的祝福送上。而满三年\五年\十年的同事，送上专属定制的纪念礼品。
3.图书馆、健身房。
4.八点后三十块的餐补，九点半后打车报销。
5.团建。
6.年假。入职当年七天，之后每年增加！
</code></pre><h2 id="工作时间"><a href="#工作时间" class="headerlink" title="工作时间"></a>工作时间</h2><pre><code>1.双休，即使偶尔周末加班也会给调休补回来的。
2.我是研发岗公司要求的打卡时间是上下午各一次即可。
3.我们组要求是十点半来，晚上没事即可走，没固定要求。
</code></pre><h2 id="招聘什么岗位？"><a href="#招聘什么岗位？" class="headerlink" title="招聘什么岗位？"></a>招聘什么岗位？</h2><pre><code>各岗位都要！！！！！
前端、后端、Android、iOS、机器学习、商业分析、架构师、算法、产品、运营、UE、UI……几乎常见的岗位都有。
大家可以看官方的招聘地址：
https://join.dianping.com/
</code></pre><h2 id="如何联系我们"><a href="#如何联系我们" class="headerlink" title="如何联系我们"></a>如何联系我们</h2><pre><code>1.简历直接发到我的邮箱：yutianfang@meituan.com。
2.在邮件里附上简历，
标题格式：【内推-岗位名】
正文：附上岗位超链接

如:
标题：【内推-Java-北京-商户运营研发组】
附件：姓名.pdf 
正文：https://join.dianping.com/job-detail?jobId=196147450724614145

一定要有超链接！
3.另外，我们组急缺Java开发，如果是Java开发除内推选定的岗位外也会推到我们组，优先安排面试。
</code></pre>]]></content>
      <categories>
        <category>招聘</category>
        <category>美团点评</category>
      </categories>
      <tags>
        <tag>招聘</tag>
        <tag>美团点评</tag>
      </tags>
  </entry>
  <entry>
    <title>互联网常用技术</title>
    <url>/2017/12/03/%E4%BA%92%E8%81%94%E7%BD%91%E5%B8%B8%E7%94%A8%E6%8A%80%E6%9C%AF/</url>
    <content><![CDATA[<p><img src="/img/%E4%BA%92%E8%81%94%E7%BD%91%E5%B8%B8%E7%94%A8%E6%8A%80%E6%9C%AF.png" alt="互联网常用技术"></p>
]]></content>
      <categories>
        <category>技术</category>
      </categories>
      <tags>
        <tag>架构</tag>
      </tags>
  </entry>
  <entry>
    <title>一次OOM问题定位过程</title>
    <url>/2017/08/26/%E4%B8%80%E6%AC%A1OOM%E9%97%AE%E9%A2%98%E5%AE%9A%E4%BD%8D%E8%BF%87%E7%A8%8B/</url>
    <content><![CDATA[<h2 id="背景"><a href="#背景" class="headerlink" title="背景"></a>背景</h2><p>8.21日bdop dev环境机器突然发生oom服务不可用，重启服务后也很快发生OOM。</p>
<p>之前一直运行没问题，OOM是突然发生的。</p>
<a id="more"></a>
<h2 id="排查过程"><a href="#排查过程" class="headerlink" title="排查过程"></a>排查过程</h2><h3 id="获取dump文件"><a href="#获取dump文件" class="headerlink" title="获取dump文件"></a>获取dump文件</h3><p>之前机器上使用<strong>jps -v </strong>查看过启动参数<strong>：(下面的参数不是当时的，只是日期有差别,删除了公司目录相关参数）</strong></p>
<blockquote>
<p>4597 Bootstrap -Dfile.encoding=UTF-8 -Dsun.jnu.encoding=UTF-8 -Djava.net.preferIPv6Addresses=false -Djava.io.tmpdir=/tmp -Djetty.defaultsDescriptor=WEB-INF/web.xml -Duser.timezone=GMT+08 -Xloggc:/XX/gc.log.201708251824 -XX:ErrorFile=/vmerr.log.201708251824 -XX:HeapDumpPath=/XX/XXXXX/logs/xxxx.heaperr.log.201708251824 -XX:+HeapDumpOnOutOfMemoryError -XX:+DisableExplicitGC -XX:+PrintGCDetails -XX:+PrintGCDateStamps -Denvironment=test -Dmedis_environment=test -Dcore.zookeeper=sgconfig-zk.sankuai.com:9331 </p>
</blockquote>
<p>注意 <strong>XX:HeapDumpPath=/XX/XXXXX/logs/xxxx.heaperr.log.201708251824 -XX:+HeapDumpOnOutOfMemoryError</strong> 参数，这个是配置发生内存溢出时dump出文件到该路径下 。</p>
<p>到路径下获取dump文件。</p>
<p>ps：从服务器上取文件可用 python -m SimpleHTTPServer开一个http服务获取。</p>
<p>由于dump文件很大，下载前先压缩会小很多。</p>
<h3 id="MAT工具排查"><a href="#MAT工具排查" class="headerlink" title="MAT工具排查"></a>MAT工具排查</h3><p>将下载的dump文件然后使用MAT打开，MAT介绍：</p>
<p><a href="http://www.jianshu.com/p/d8e247b1e7b2" target="_blank" rel="noopener">http://www.jianshu.com/p/d8e247b1e7b2</a></p>
<p><a href="http://wiki.eclipse.org/MemoryAnalyzer" target="_blank" rel="noopener">http://wiki.eclipse.org/MemoryAnalyzer</a></p>
<p><a href="https://www.yourkit.com/docs/java/help/sizes.jsp" target="_blank" rel="noopener">https://www.yourkit.com/docs/java/help/sizes.jsp</a></p>
<ol>
<li>在界面选择 “Dominator Tree”:<img src="/2017/08/26/一次OOM问题定位过程/dominator_tree.png" title="dominator tree"></li>
<li>按对象大小排序<img src="/2017/08/26/一次OOM问题定位过程/object_size_sorted.png" title="object size sorted">
发现databus线程对象有900M大小。databus在服务中是用来同步表数据到ES中的，继续向下看对象里包含了什么</li>
<li>线程对象持有的对象<img src="/2017/08/26/一次OOM问题定位过程/reference_objects.png" title="reference objects">
发现持有了大量的hashmap和hashset对象。hashset是使用hashmap实现，所以直接看hashset。<br>mat显示hashset中一共有450000+个数据，内存溢出很可能就是这里导致的。<br>数据内容都还是一样的：<img src="/2017/08/26/一次OOM问题定位过程/same_data.png" title="same data"></li>
<li>由于是databus线程时同步表数据，于是到表中查找包含这些拼音的数据，但并没找到。</li>
<li>继续看线程对象持有的对象，看看是否有其它信息有用信息<img src="/2017/08/26/一次OOM问题定位过程/poi_id.png" title="poi_id">
对象持有的string对象直接给出了poi_id，所以到表里直接查该数据，发现该poi的poi_name字段为“需要超长超长超长超长超长超长超长超长….”</li>
<li>表中数据找到了但为什么会导致内存溢出呢？当时使用了一个比较笨的方法，直接在项目中搜 “HashSeet”，因为hashset还是比较少用的</li>
<li>发现在databus更新ES时有用到 将门店名称拼音存到索引中。直接将该门店名称放到单测里跑，发现果然很长时间不能结束。</li>
<li>一步步打断点定位到出问题的方法：<img src="/2017/08/26/一次OOM问题定位过程/descart_method.png" title="descart method"></li>
<li>该方法会计算多音字的所有组合。目的是为了支持多音字搜索。debug时发现pinyinSets大小有49，汉字“超长超长超长…”有多个“长”，因此会有多个2的n次方中组合。<br><strong>导致内存中有大量hashset，最终导致内存溢出</strong></li>
</ol>
<h2 id="解决"><a href="#解决" class="headerlink" title="解决"></a>解决</h2><p>找到相关负责人修改，限制笛卡尔积最大长度为32，超过这个大小的多音字不再处理。</p>
<h2 id="后续"><a href="#后续" class="headerlink" title="后续"></a>后续</h2><ol>
<li>该问题发生在线下，当天就改完了但没上线。第二天线上也很巧的也发生了一样故障导致OOM。还好前一天已经定位出了问题，直接发布上线解决。不然线上服务会不可用比较长时间。</li>
<li>推荐一个比较好用的jvm命令 jcmd</li>
</ol>
<h2 id="感想"><a href="#感想" class="headerlink" title="感想"></a>感想</h2><ol>
<li>线下很奇怪的问题也需要重视，这次如果没有及时定位解决，到了第二天线上出问题就会引起比较严重的事故。会直接导致门店列表页无法展示，几乎影响M端所有系统。</li>
<li>难得的一次OOM问题排查实战，还是挺有收获的，后续需继续研究jvm及mat工具使用。</li>
</ol>
]]></content>
      <categories>
        <category>技术</category>
        <category>JAVA</category>
      </categories>
      <tags>
        <tag>JAVA</tag>
        <tag>JVM</tag>
      </tags>
  </entry>
  <entry>
    <title>MySql 锁机制</title>
    <url>/2017/08/16/MySql-%E9%94%81%E6%9C%BA%E5%88%B6/</url>
    <content><![CDATA[<h2 id="锁是什么"><a href="#锁是什么" class="headerlink" title="锁是什么"></a>锁是什么</h2><p>锁是计算机协调多个进程或纯线程并发访问某一资源的机制。在数据库中，除传统的计算资源（CPU、RAM、I/O）的争用以外，数据也是一种供许多用户共享的资源。如何保证数据并发访问的一致性、有效性是所在有数据库必须解决的一个问题，锁冲突也是影响数据库并发访问性能的一个重要因素。从这个角度来说，锁对数据库而言显得尤其重要，也更加复杂。</p>
<p>防止更新丢失，并不能单靠数据库事务控制器来解决，需要应用程序对要更新的数据加必要的锁来解决。</p>
<a id="more"></a>
<p>锁的运作？</p>
<p>事务T在度某个数据对象（如表、记录等）操作之前，先向系统发出请求，对其加锁，加锁后事务T就对数据库对象有一定的控制，在事务T释放它的锁之前，其他事务不能更新此数据对象。</p>
<h2 id="锁的分类"><a href="#锁的分类" class="headerlink" title="锁的分类"></a>锁的分类</h2><h3 id="按锁类型分"><a href="#按锁类型分" class="headerlink" title="按锁类型分"></a>按锁类型分</h3><h4 id="排他锁-又称写锁，X锁）"><a href="#排他锁-又称写锁，X锁）" class="headerlink" title="排他锁(又称写锁，X锁）"></a>排他锁(又称写锁，X锁）</h4><ul>
<li>会阻塞其他事务读和写。</li>
</ul>
<ul>
<li>若事务T对数据对象A(可能是表也可能是数据）加上X锁，则只允许T读取和修改A，其他任何事务都不能再对加任何类型的锁，直到T释放锁。这就保证了其他事务在T释放A上的锁之前不能再读取和修改A。</li>
</ul>
<h4 id="共享锁-又称读取，S锁）"><a href="#共享锁-又称读取，S锁）" class="headerlink" title="共享锁(又称读取，S锁）"></a><strong>共享锁(</strong>又称读取，S锁）</h4><ul>
<li>会阻塞其他事务修改表数据。</li>
</ul>
<ul>
<li>若事务T对数据对象A加上S锁，则其他事务只能再对A加S锁，而不能X锁，直到T释放A上的锁。这就保证了其他事务可以读A，但在T释放A上的S锁之前不能对A做任何修改。</li>
</ul>
<p>X锁和S锁都是加载某一个数据对象上的。也就是数据的粒度。</p>
<h3 id="按锁粒度分"><a href="#按锁粒度分" class="headerlink" title="按锁粒度分"></a>按锁粒度分</h3><h4 id="行级锁-row-level"><a href="#行级锁-row-level" class="headerlink" title="行级锁(row-level)"></a><strong>行级锁(row-level)</strong></h4><ul>
<li>开销大，加锁慢，<strong>针对索引加锁而不是数据</strong></li>
<li>会出现死锁。</li>
<li>锁定粒度最小，发生锁冲突的概率最低，并发度也最高。</li>
</ul>
<p>行级锁定最大的特点就是锁定对象的颗粒度很小，也是目前各大数据库管理软件所实现的锁定颗粒度最小的。由于锁定颗粒度很小，所以发生锁定资源争用的概率也最小，能够给予应用程序尽可能大的并发处理能力而提高一些需要高并发应用系统的整体性能。</p>
<p>缺陷：由于锁定资源的颗粒度很小，所以每次获取锁和释放锁需要做的事情也更多，带来的消耗自然也就更大了。此外，行级锁定也最容易发生死锁。</p>
<h4 id="表级锁-table-level"><a href="#表级锁-table-level" class="headerlink" title="表级锁(table-level)"></a><strong>表级锁(table-level)</strong></h4><ul>
<li>开销小，加锁快。</li>
<li>不会出现死锁。</li>
<li>锁定粒度大，发生锁冲突的概率最高，并发度最低。</li>
</ul>
<p>和行级锁相反，表级别的锁是MySQL各存储引擎中最大颗粒度的锁定机制。该锁定机制最大的特点是实现逻辑非常简单，带来的系统负面影响最小。所以获取锁和释放锁的速度很快。由于表级锁一次会将整个表锁定，所以可以很好的避免困扰我们的死锁问题。</p>
<p>缺陷：锁定颗粒度大所带来最大的负面影响就是出现锁定资源争用的概率也会最高，致使并发度大打折扣。</p>
<h4 id="页级锁-page-level-MySQL特有"><a href="#页级锁-page-level-MySQL特有" class="headerlink" title="页级锁(page-level) (MySQL特有)"></a><strong>页级锁(page-level) (</strong>MySQL特有)</h4><ul>
<li>开销和加锁时间界于表锁和行锁之间。</li>
<li>会出现死锁。</li>
<li>锁定粒度界于表锁和行锁之间，并发度一般。</li>
</ul>
<p>页级锁定是MySQL中比较独特的一种锁定级别，在其他数据库管理软件中也并不是太常见。页级锁定的特点是锁定颗粒度介于行级锁定与表级锁之间，所以获取锁定所需要的资源开销，以及所能提供的并发处理能力也同样是介于上面二者之间。</p>
<p>缺陷：页级锁定和行级锁定一样，会发生死锁。</p>
<h2 id="事务特性"><a href="#事务特性" class="headerlink" title="事务特性"></a>事务特性</h2><ul>
<li>ACID</li>
</ul>
<h2 id="事务隔离级别"><a href="#事务隔离级别" class="headerlink" title="事务隔离级别"></a>事务隔离级别</h2><ul>
<li>默认都清楚</li>
</ul>
<h2 id="InnoDB锁机制"><a href="#InnoDB锁机制" class="headerlink" title="InnoDB锁机制"></a>InnoDB锁机制</h2><p>一共三类：<strong>共享锁，排他锁，意向锁</strong>。</p>
<p>意向锁为innodb引擎特有，单独介绍：</p>
<h3 id="意向锁"><a href="#意向锁" class="headerlink" title="意向锁"></a>意向锁</h3><p>举个例子，数据库操作存在以下场景：</p>
<p>事务A锁住了表中的一行，让这一行只能读，不能写。之后，事务B申请整个表的写锁。如果事务B申请成功，那么理论上它就能修改表中的任意一行，这与A持有的行锁是冲突的。</p>
<p>数据库需要避免这种冲突，就是说要让B的申请被阻塞，直到A释放了行锁。数据库要怎么判断这个冲突呢？</p>
<p>普通认为两步：</p>
<ol>
<li>判断表是否已被其他事务用表锁锁表。</li>
<li>判断表中的每一行是否已被行锁锁住。但是这样的方法效率很低，因为要遍历整个表。</li>
</ol>
<p>所以<strong>解决方案是</strong>：意向锁。</p>
<p>在意向锁存在的情况下，事务A必须先申请表的意向共享锁，成功后再申请一行的行锁。</p>
<p>在意向锁存在的情况下，两步骤为</p>
<ol>
<li>判断表是否已被其他事务用表锁锁表。</li>
<li>发现表上有意向共享锁，说明表中有些行被共享行锁锁住了，因此，事务B申请表的写锁会被阻塞。</li>
</ol>
<p>注意：申请意向锁的动作是数据库完成的，就是说，事务A申请一行的行锁的时候，数据库会自动先开始申请表的意向锁，不需要我们程序员使用代码来申请。</p>
<p><strong>意向锁目的：</strong>解决表级锁和行级锁之间的冲突</p>
<p><strong>意向锁是一种表级锁</strong>，锁的粒度是整张表。结合共享与排他锁使用，分为<strong>意向共享锁（IS）</strong>和<strong>意向排他锁（IX）</strong>。意向锁为了方便检测表级锁和行级锁之间的冲突，故在给一行记录加锁前，首先给该表加意向锁。也就是同时加意向锁和行级锁。</p>
<h3 id="锁之间的兼容性"><a href="#锁之间的兼容性" class="headerlink" title="锁之间的兼容性"></a>锁之间的兼容性</h3><table>
<thead>
<tr>
<th>请求锁模式/是否兼容/当前锁模式</th>
<th>共享锁</th>
<th>排他锁</th>
<th>意向共享锁</th>
<th>意向排他锁</th>
</tr>
</thead>
<tbody>
<tr>
<td>共享锁</td>
<td>兼容</td>
<td>冲突</td>
<td>兼容</td>
<td>冲突</td>
</tr>
<tr>
<td>排他锁</td>
<td>冲突</td>
<td>冲突</td>
<td>冲突</td>
<td>冲突</td>
</tr>
<tr>
<td>意向共享锁</td>
<td>兼容</td>
<td>冲突</td>
<td>兼容</td>
<td>兼容</td>
</tr>
<tr>
<td>意向排他锁</td>
<td>冲突</td>
<td>冲突</td>
<td>兼容</td>
<td>兼容</td>
</tr>
</tbody>
</table>
<p>注意：</p>
<p>如果一个事务请求的锁模式与当前的锁模式兼容，innodb就将请求的锁授予该事务；反之，如果两者不兼容，该事务就要等待锁释放。</p>
<p><strong>意向锁是Innodb自动加的，不需要用户干预</strong>。</p>
<p>对于UPDATE、DELETE、INSERT语句，Innodb会自动给涉及的数据集加排他锁（X）；对于普通SELECT语句，Innodb不会加任何锁。</p>
<p>若读操作想加锁需显示指定：</p>
<blockquote>
<p><code>//显示共享锁(S)</code></p>
<p><code>SELECT * FROM table_name WHERE .... LOCK IN SHARE MODE</code></p>
<p><code>//显示排他锁(X)</code></p>
<p><code>SELECT * FROM table_name WHERE .... FOR UPDATE.</code></p>
</blockquote>
<h3 id="间隙锁"><a href="#间隙锁" class="headerlink" title="间隙锁"></a>间隙锁</h3><h4 id="定义"><a href="#定义" class="headerlink" title="定义"></a>定义</h4><p>当我们用范围条件而不是相等条件检索数据，并请求共享或排他锁时，InnoDB会给符合条件的已有数据的索引项加锁；对于键值在条件范围内但并不存在的记录，叫做“间隙(GAP)”，InnoDB也会对这个“间隙”加锁，这种锁机制就是所谓的间隙锁（Next-Key锁）。</p>
<p>举例来说，假如user表中只有101条记录，其userid 的值分别是1,2,…,100,101，下面的SQL：SELECT * FROM user WHERE userid &gt; 100 FOR UPDATE</p>
<p>上面是一个范围条件的检索，InnoDB不仅会对符合条件的userid 值为101的记录加锁，也会对userid 大于101（这些记录并不存在）的“间隙”加锁。</p>
<h4 id="目的"><a href="#目的" class="headerlink" title="目的"></a>目的</h4><p>一方面是为了防止幻读，以满足相关隔离级别的要求，对于上面的例子，要是不使用间隙锁，如果其他事务插入了userid 大于100的任何记录，那么本事务如果再次执行上述语句，就会发生幻读；另一方面，是为了满足其恢复和复制的需要。有关其恢复和复制对机制的影响，以及不同隔离级别下InnoDB使用间隙锁的情况。</p>
<p>实际开发：</p>
<p>可见，在使用范围条件检索并锁定记录时，InnoDB这种加锁机制会阻塞符合条件范围内键值的并发插入，这往往会造成严重的锁等待。因此，在实际开发中，尤其是并发插入比较多的应用，我们要尽量优化业务逻辑，尽量使用相等条件来访问更新数据，避免使用范围条件。</p>
<h3 id="何时使用表锁"><a href="#何时使用表锁" class="headerlink" title="何时使用表锁"></a>何时使用表锁</h3><p>对于InnoDB表，在绝大部分情况下都应该使用行级锁，因为事务和行锁往往是我们之所以选择InnoDB表的理由。但在个另特殊事务中，也可以考虑使用表级锁。</p>
<ol>
<li>第一种情况是：事务需要更新大部分或全部数据，表又比较大，如果使用默认的行锁，不仅这个事务执行效率低，而且可能造成其他事务长时间锁等待和锁冲突，这种情况下可以考虑使用表锁来提高该事务的执行速度。</li>
<li>第二种情况是：事务涉及多个表，比较复杂，很可能引起死锁，造成大量事务回滚。这种情况也可以考虑一次性锁定事务涉及的表，从而避免死锁、减少数据库因事务回滚带来的开销。</li>
</ol>
<p>在InnoDB下 ，<strong>使用表锁要注意以下两点。</strong></p>
<p>（１）使用LOCK TALBES虽然可以给InnoDB加表级锁，但必须说明的是，表锁不是由InnoDB存储引擎层管理的，而是由其上一层ＭySQL Server负责的，仅当autocommit=0、innodb_table_lock=1（默认设置）时，InnoDB层才能知道MySQL加的表锁，ＭySQL Server才能感知InnoDB加的行锁，这种情况下，InnoDB才能自动识别涉及表级锁的死锁；否则，InnoDB将无法自动检测并处理这种死锁。</p>
<p>如果需要写表t1并从表t读，可以按如下做：</p>
<blockquote>
<p>mysql&gt; SET AUTOCOMMIT=<code>0</code>;</p>
<p>mysql&gt; LOCAK TABLES t1 WRITE, t2 READ, …;`</p>
<p>[<code></code>do<code></code>something with tables t1 and here];`</p>
<p>mysql&gt; COMMIT;`</p>
<p>mysql&gt; UNLOCK TABLES;`</p>
</blockquote>
<h3 id="事务引擎导致的死锁"><a href="#事务引擎导致的死锁" class="headerlink" title="事务引擎导致的死锁"></a><strong>事务引擎导致的死锁</strong></h3><p>发生死锁后，InnoDB一般都能自动检测到，并使一个事务释放锁并退回，另一个事务获得锁，继续完成事务。但在涉及外部锁，或涉及锁的情况下，InnoDB并不能完全自动检测到死锁，这需要通过设置锁等待超时参数innodb_lock_wait_timeout来解决。<strong>需要说明的是，这个参数并不是只用来解决死锁问题</strong>，在并发访问比较高的情况下，如果大量事务因无法立即获取所需的锁而挂起，会占用大量计算机资源，造成严重性能问题，甚至拖垮数据库。我们通过设置合适的锁等待超时阈值，可以避免这种情况发生。</p>
<p>通常来说，死锁都是应用设计的问题，通过调整业务流程、数据库对象设计、事务大小、以及访问数据库的SQL语句，绝大部分都可以避免。</p>
<p>下面就通过实例来介绍几种死锁的常用避免和解决方法。</p>
<ol>
<li>在应用中，如果不同的程序会并发存取多个表，应尽量约定以相同的顺序为访问表，这样可以大大降低产生死锁的机会。如果两个session访问两个表的顺序不同，发生死锁的机会就非常高！但如果以相同的顺序来访问，死锁就可能避免。</li>
<li>在程序以批量方式处理数据的时候，如果事先对数据排序，保证每个线程按固定的顺序来处理记录，也可以大大降低死锁的可能。</li>
<li>在事务中，如果要更新记录，应该直接申请足够级别的锁，即排他锁，而不应该先申请共享锁，更新时再申请排他锁，甚至死锁。</li>
<li>在REPEATEABLE-READ隔离级别下，如果两个线程同时对相同条件记录用SELECT…ROR UPDATE加排他锁，在没有符合该记录情况下，两个线程都会加锁成功。程序发现记录尚不存在，就试图插入一条新记录，如果两个线程都这么做，就会出现死锁。这种情况下，将隔离级别改成READ COMMITTED，就可以避免问题。</li>
<li>当隔离级别为READ COMMITED时，如果两个线程都先执行SELECT…FOR UPDATE，判断是否存在符合条件的记录，如果没有，就插入记录。此时，只有一个线程能插入成功，另一个线程会出现锁等待，当第１个线程提交后，第２个线程会因主键重出错，但虽然这个线程出错了，却会获得一个排他锁！这时如果有第３个线程又来申请排他锁，也会出现死锁。对于这种情况，可以直接做插入操作，然后再捕获主键重异常，或者在遇到主键重错误时，总是执行ROLLBACK释放获得的排他锁。</li>
</ol>
<p>尽管通过上面的设计和优化等措施，可以大减少死锁，但死锁很难完全避免。因此，在程序设计中总是捕获并处理死锁异常是一个很好的编程习惯。</p>
<p>如果出现死锁，可以用SHOW INNODB STATUS命令来确定最后一个死锁产生的原因和改进措施。</p>
<h2 id="TODO"><a href="#TODO" class="headerlink" title="TODO"></a>TODO</h2><h3 id="next-key-锁"><a href="#next-key-锁" class="headerlink" title="next-key 锁"></a>next-key 锁</h3><h3 id="表锁问题"><a href="#表锁问题" class="headerlink" title="表锁问题"></a>表锁问题</h3><h2 id="参考资料"><a href="#参考资料" class="headerlink" title="参考资料"></a>参考资料</h2><p><a href="http://blog.csdn.net/jack__frost/article/details/73347688" target="_blank" rel="noopener">http://blog.csdn.net/jack__frost/article/details/73347688</a></p>
]]></content>
      <categories>
        <category>技术</category>
        <category>数据库</category>
        <category>MySql</category>
      </categories>
      <tags>
        <tag>MySql</tag>
        <tag>数据库</tag>
      </tags>
  </entry>
  <entry>
    <title>Zookeeper概述</title>
    <url>/2017/07/10/zookeeper%E6%A6%82%E8%BF%B0/</url>
    <content><![CDATA[<p>ZooKeeper是一个用于分布式应用的开源分布式协调服务。它提供了简单的原语集合，分布式应用可在这些原语之上构建用于同步、配置维护、分组和命名的高层服务。ZooKeeper的设计使得编程容易，并且使用类似于广泛熟知的文件系统目录树结构的数据模型。它运行在Java环境中，但是有Java和C语言绑定。分布式协调服务是出了名的难得编写正确，很容易出现竞争条件和死锁之类的错误。ZooKeeper的动机是减轻为分布式应用开发协调服务的负担。<br><a id="more"></a></p>
<h2 id="设计目标"><a href="#设计目标" class="headerlink" title="设计目标"></a>设计目标</h2><h3 id="简单"><a href="#简单" class="headerlink" title="简单"></a>简单</h3><p>ZooKeeper让分布式进程通过共享的、与标准文件系统类似的分层名字空间相互协调。名字空间由数据寄存器（在ZooKeeper世界中称作znode）构成，这与文件和目录类似。与典型文件系统不同的是，ZooKeeper在内存中保存数据，这让其可以达到高吞吐量和低延迟。</p>
<p>ZooKeeper的实现很重视高性能、高可用性，以及严格的顺序访问。高性能意味着可将ZooKeeper用于大的分布式系统。可靠性使之可避免单点失败。严格的顺序访问使得客户端可以实现复杂的同步原语。</p>
<h3 id="自我复制"><a href="#自我复制" class="headerlink" title="自我复制"></a>自我复制</h3><p>与它所协调的进程一样，ZooKeeper本身也会试图在集群中进行复制。</p>
<img src="/2017/07/10/zookeeper概述/ZooKeeper-Service.jpg" title="ZooKeeper Service">
<p>组成ZooKeeper服务的各个服务器必须相互知道对方。它们在内存中维护状态和事务日志，还在永久存储中维护快照。只要大部分(majority)服务器可用，ZooKeeper服务就是可用的。</p>
<h3 id="有序"><a href="#有序" class="headerlink" title="有序"></a>有序</h3><p>ZooKeeper为每次更新设置一个反映所有ZooKeeper事务顺序的序号。后续操作可使用序号来实现更高层抽象，如同步原语。</p>
<h3 id="高速"><a href="#高速" class="headerlink" title="高速"></a>高速</h3><p>在读多的应用中zookeeper尤其快，读写比例10:1时表现最好</p>
<h2 id="数据模型与分层的命名空间"><a href="#数据模型与分层的命名空间" class="headerlink" title="数据模型与分层的命名空间"></a>数据模型与分层的命名空间</h2><p>ZooKeeper提供的名字空间与标准文件系统非常相似。名字是一个由斜杠/分隔的路径元素序列。ZooKeeper名字空间中的每个节点都由其路径标识。</p>
<img src="/2017/07/10/zookeeper概述/zknamespace.jpg" title="zk namespace">
<h3 id="节点与临时节点"><a href="#节点与临时节点" class="headerlink" title="节点与临时节点"></a>节点与临时节点</h3><p>与标准文件系统不同，ZooKeeper名字空间中的每个节点都可以有关联的数据以及子节点。这就像一个允许文件也是目录的文件系统。（ZooKeeper设计用于存储协调数据：状态信息、配置、位置信息等，所以通常存储在每个节点中的数据很小，在字节到千字节范围内）讨论ZooKeeper数据节点时，我们用术语znode来明确指示。</p>
<p>Znode会维护一个stat结构体，其中包含数据和ACL的版本号与时间戳，以便于进行缓存验证和协调更新。每次修改znode数据时，版本号会增长。客户端获取数据的时候，也同时获取数据的版本。</p>
<p>对znode数据的读写操作是原子的。读取操作获取节点的所有数据，写入操作替换所有数据。节点的访问控制列表（ACL）控制可以进行操作的用户。</p>
<p>ZooKeeper具有临时节点的概念。只要创建节点的会话是活动的，临时节点就存在。一旦会话终止，临时节点会被删除。临时节点对于实现tbd是很有用的。</p>
<h3 id="条件更新和观察"><a href="#条件更新和观察" class="headerlink" title="条件更新和观察"></a>条件更新和观察</h3><p>ZooKeeper支持观察的概念。客户端可以在znode上设置观察。观察将在znode修改时被触发和移除。观察被触发时客户端会收到一个数据包，指示znode已经被修改。如果与ZooKeeper服务之间的连接断开，客户端会收到一个本地通知。这可用于tbd。</p>
<h3 id="保证"><a href="#保证" class="headerlink" title="保证"></a>保证</h3><p>ZooKeeper非常高效和简单。基于其目标：成为构建如同步这样的更复杂服务的基础，ZooKeeper提供下述保证：</p>
<p>顺序一致性：客户端的更新将以请求发送的次序被应用。</p>
<p>原子性：更新要么成功，要么失败，没有部分更新。</p>
<p>单一系统镜像：无论连接到哪个服务器，客户端将看到一样的视图。</p>
<p>可靠性：更新操作的结果将是持续的，直到客户端覆盖了更新。</p>
<p>及时性：在某个时间范围内，客户端视图确保是最新的。</p>
<p>关于这些保证的详细信息，以及如何使用这些保证，请参看tbd。</p>
<h3 id="简单的API"><a href="#简单的API" class="headerlink" title="简单的API"></a>简单的API</h3><p>ZooKeeper的设计目标之一是提供非常简单的编程接口。ZooKeeper仅支持这些操作：</p>
<p>create：在树中某位置创建一个节点。</p>
<p>delete：删除一个节点。</p>
<p>exists：测试某位置是否存在某节点。</p>
<p>get data：读取节点数据。</p>
<p>set data：向节点写入数据。</p>
<p>get children：获取子节点列表。</p>
<p>sync：等待数据传播。</p>
<p>关于这些操作的更深入讨论，以及如何使用它们来实现更高层的操作，请参看tbd。</p>
<h3 id="实现"><a href="#实现" class="headerlink" title="实现"></a>实现</h3><p>下图显示了ZooKeeper服务的高层组件。除了请求处理器(Request Processor)之外，组成ZooKeeper服务的每个服务器拥有每个组件的自有拷贝。</p>
<img src="/2017/07/10/zookeeper概述/zkcomponents.jpg" title="zk components">
<p>自我复制数据库(replicated database)是一个包含整个数据树的内存数据库。更新会记录到磁盘中以便可以恢复，并且将写操作应用到内存数据库之前会先写入到磁盘。</p>
<p>每个ZooKeeper服务器都为客户服务。客户端连接到一个服务器，提交请求。读请求由每个服务器数据库的本地拷贝进行服务。改变服务状态的请求和写请求由一致性协议处理。</p>
<p>作为一致性协议的一部分，客户端的所有写请求都被转发到单个服务器，也就是领导者。其他ZooKeeper服务器则是跟随者，它们接收来自领导者的建议，对传递的消息达成一致。消息层考虑了替换失败的领导者和跟随者与领导者同步的问题。</p>
<p>ZooKeeper使用定制的原子消息协议。因为消息层是原子的，ZooKeeper可保证本地拷贝不会发散（diverge）。收到写请求时，领导者计算写入操作后系统的状态，将其转换成一个捕获此状态的事务。</p>
<h3 id="使用"><a href="#使用" class="headerlink" title="使用"></a>使用</h3><p>ZooKeeper的编程接口非常简单。但是，可将其用于实现高层顺序操作，如同步原语、组成员管理、所有者关系管理等。更多信息请参看tbd。</p>
<h2 id="性能"><a href="#性能" class="headerlink" title="性能"></a>性能</h2><p>ZooKeeper被设计为高性能的。但它真的是高性能的吗？Yahoo研究中心的ZooKeeper开发团队证实了ZooKeeper的高性能，特别是在读操作比写操作多的应用中（见下图），因为写操作涉及在所有服务器间同步状态。（读操作比写操作多是协调服务的典型情况）</p>
<img src="/2017/07/10/zookeeper概述/zkthrought.png" title="zk throught">
<p>上图是ZooKeeper 3.2在配置有两个2GHz Xeon处理器和两个SATA 15K RPM驱动器的服务器上运行时的吞吐率图形。一个驱动器配置为ZooKeeper日志专用设备。快照写入到操作系统驱动器。读写操作1KB的数据。“服务器数”指的是ZooKeeper集群的大小，即组成服务的服务器个数。大约30个其他服务器用于模拟客户端。ZooKeeper集群配置为不允许客户端连接到领导者。</p>
<p>提示：3.2版的读写性能是3.1版的2倍。</p>
<p>Benchmarks也表明ZooKeeper是可靠的。下图（可靠性中的图）显示了ZooKeeper在各种失败情况下的反应。图中标记的各个事件是：</p>
<p>1．跟随者失败和恢复</p>
<p>2．另一个跟随者失败和恢复</p>
<p>3．领导者失败</p>
<p>4．两个跟随者失败和恢复</p>
<p>5．另一个领导者失败</p>
<h2 id="可靠性"><a href="#可靠性" class="headerlink" title="可靠性"></a>可靠性</h2><p>为揭示在有失败注入时系统的行为，我们在一个由7台机器组成的ZooKeeper服务上运行和先前一样的benchmark测试，但是让写操作的百分比固定为30%，这是预期负载比例的保守估计。</p>
<img src="/2017/07/10/zookeeper概述/zkperfreliability.jpg" title="zk performance reliability">
<p>此图有几处值得仔细观察。首先，如果跟随者失败后快速恢复，则ZooKeeper可以维持高吞吐率。但更重要的是，领导者选举算法让系统可以足够快地恢复，以阻止吞吐率有实质性的下降。据我们观察，ZooKeeper选举一个新的领导者的时间小于200ms。第三，一旦跟随者恢复并且开始处理请求，ZooKeeper可以恢复高吞吐率。</p>
<h2 id="ZooKeeper-项目"><a href="#ZooKeeper-项目" class="headerlink" title="ZooKeeper 项目"></a>ZooKeeper 项目</h2><p>ZooKeeper已经在很多工业应用中<a href="http://wiki.apache.org/hadoop/ZooKeeper/PoweredBy" target="_blank" rel="noopener">成功使用</a>。Yahoo!在Yahoo! Message Broker中使用ZooKeeper作为协调和故障恢复服务。Yahoo! Message Broker是一个高度扩展的发布-订阅系统，管理着成千上万个需要拷贝和数据传递的话题。Yahoo!的很多广告系统也使用ZooKeeper来实现可靠服务。</p>
<p>我们鼓励用户和开发者加入社区，贡献技能。更多信息请看<a href="http://hadoop.apache.org/zookeeper/" target="_blank" rel="noopener">Apache的ZooKeeper工程</a>。</p>
<h2 id="参考资料"><a href="#参考资料" class="headerlink" title="参考资料"></a>参考资料</h2><p><a href="https://zookeeper.apache.org/doc/trunk/zookeeperOver.html" target="_blank" rel="noopener">https://zookeeper.apache.org/doc/trunk/zookeeperOver.html</a></p>
]]></content>
      <categories>
        <category>技术</category>
        <category>ZooKeeper</category>
      </categories>
      <tags>
        <tag>zookeeper</tag>
      </tags>
  </entry>
  <entry>
    <title>Vgrant使用入门</title>
    <url>/2017/06/26/Vgrant%E4%BD%BF%E7%94%A8%E5%85%A5%E9%97%A8/</url>
    <content><![CDATA[<p>前面讲了Vagrant的几个命令：</p>
<ul>
<li>vagrant box add 添加box的操作</li>
<li>vagrant init 初始化box的操作</li>
<li>vagrant up 启动虚拟机的操作</li>
<li>vagrant ssh 登录虚拟机的操作</li>
</ul>
<a id="more"></a>
<p>Vagrant还包括如下一些操作：</p>
<ul>
<li><p>vagrant box list<br>显示当前已经添加的box列表<br>$ vagrant box list<br>base (virtualbox)<br>vagrant box remove</p>
</li>
<li><p>删除相应的box<br>$ vagrant box remove base virtualbox<br>Removing box ‘base’ with provider ‘virtualbox’…</p>
</li>
<li><p>vagrant destroy<br>停止当前正在运行的虚拟机并销毁所有创建的资源<br>$ vagrant destroy<br>Are you sure you want to destroy the ‘default’ VM? [y/N] y<br>[default] Destroying VM and associated drives…</p>
</li>
<li><p>vagrant halt<br>关机</p>
<p>$ vagrant halt<br>[default] Attempting graceful shutdown of VM…</p>
</li>
<li><p>vagrant package<br>打包命令，可以把当前的运行的虚拟机环境进行打包</p>
<p>$ vagrant package<br>[default] Attempting graceful shutdown of VM…<br>[default] Clearing any previously set forwarded ports…<br>[default] Creating temporary directory for export…<br>[default] Exporting VM…<br>[default] Compressing package to: /Users/astaxie/vagrant/package.box</p>
</li>
<li><p>vagrant plugin<br>用于安装卸载插件</p>
</li>
<li><p>vagrant provision</p>
</li>
</ul>
<p>通常情况下Box只做最基本的设置，而不是设置好所有的环境，因此Vagrant通常使用Chef或者Puppet来做进一步的环境搭建。那么Chef或者Puppet称为provisioning，而该命令就是指定开启相应的provisioning。按照Vagrant作者的说法，所谓的provisioning就是”The problem of installing software on a booted system”的意思。除了Chef和Puppet这些主流的配置管理工具之外，我们还可以使用Shell来编写安装脚本。</p>
<p>例如： vagrant provision –provision-with chef</p>
<ul>
<li>vagrant reload</li>
</ul>
<p>重新启动虚拟机，主要用于重新载入配置文件</p>
<p>  $ vagrant reload<br>  [default] Attempting graceful shutdown of VM…<br>  [default] Setting the name of the VM…<br>  [default] Clearing any previously set forwarded ports…<br>  [default] Creating shared folders metadata…<br>  [default] Clearing any previously set network interfaces…<br>  [default] Preparing network interfaces based on configuration…<br>  [default] Forwarding ports…<br>  [default] – 22 =&gt; 2222 (adapter 1)<br>  [default] Booting VM…<br>  [default] Waiting for VM to boot. This can take a few minutes.<br>  [default] VM booted and ready for use!<br>  [default] Setting hostname…<br>  [default] Mounting shared folders…<br>  [default] – /vagrant</p>
<ul>
<li><p>vagrant resume<br>恢复前面被挂起的状态</p>
<p>$vagrant resume<br>[default] Resuming suspended VM…<br>[default] Booting VM…<br>[default] Waiting for VM to boot. This can take a few minutes.<br>[default] VM booted and ready for use!</p>
</li>
<li><p>vagrant ssh-config<br>输出用于ssh连接的一些信息</p>
<p>$vagrant ssh-config<br>Host default<br>  HostName 127.0.0.1<br>  User vagrant<br>  Port 2222<br>  UserKnownHostsFile /dev/null<br>  StrictHostKeyChecking no<br>  PasswordAuthentication no<br>  IdentityFile “/Users/astaxie/.vagrant.d/insecure_private_key”<br>  IdentitiesOnly yes<br>  LogLevel FATAL</p>
</li>
<li><p>vagrant status<br>获取当前虚拟机的状态</p>
<p>$vagrant status<br>Current machine states:</p>
<p>default                   running (virtualbox)</p>
<p>The VM is running. To stop this VM, you can run <code>vagrant halt</code> to<br>shut it down forcefully, or you can run <code>vagrant suspend</code> to simply<br>suspend the virtual machine. In either case, to restart it again,<br>simply run <code>vagrant up</code>.</p>
</li>
<li><p>vagrant suspend<br>挂起当前的虚拟机</p>
<p>$ vagrant suspend<br>[default] Saving VM state and suspending execution…</p>
</li>
</ul>
<h2 id="模拟打造多机器的分布式系统"><a href="#模拟打造多机器的分布式系统" class="headerlink" title="模拟打造多机器的分布式系统"></a>模拟打造多机器的分布式系统</h2><p>前面这些单主机单虚拟机主要是用来自己做开发机，从这部分开始的内容主要将向大家介绍如何在单机上通过虚拟机来打造分布式造集群系统。这种多机器模式特别适合以下几种人：</p>
<ol>
<li><p>快速建立产品网络的多机器环境，例如web服务器、db服务器</p>
</li>
<li><p>建立一个分布式系统，学习他们是如何交互的</p>
</li>
<li><p>测试API和其他组件的通信</p>
</li>
<li><p>容灾模拟，网络断网、机器死机、连接超时等情况</p>
</li>
</ol>
<p>Vagrant支持单机模拟多台机器，而且支持一个配置文件Vagrntfile就可以跑分布式系统。</p>
<p>现在我们来建立多台VM跑起來，並且让他们之间能够相通信，假设一台是应用服务器、一台是DB服务器，那么这个结构在Vagrant中非常简单，其实和单台的配置差不多，你只需要通过config.vm.define来定义不同的角色就可以了，现在我们打开配置文件进行如下设置：</p>
<p>Vagrant.configure(“2”) do |config|<br>  config.vm.define :web do |web|<br>    web.vm.provider “virtualbox” do |v|<br>          v.customize [“modifyvm”, :id, “–name”, “web”, “–memory”, “512”]<br>    end<br>    web.vm.box = “base”<br>    web.vm.hostname = “web”<br>    web.vm.network :private_network, ip: “11.11.1.1”<br>  end</p>
<p>  config.vm.define :db do |db|<br>    db.vm.provider “virtualbox” do |v|<br>          v.customize [“modifyvm”, :id, “–name”, “db”, “–memory”, “512”]<br>    end<br>    db.vm.box = “base”<br>    db.vm.hostname = “db”<br>    db.vm.network :private_network, ip: “11.11.1.2”<br>  end<br>end<br>这里的设置和前面我们单机设置配置类似，只是我们使用了:web以及:db分別做了两个VM的设置，并且给每个VM设置了不同的hostname和IP，设置好之后再使用vagrant up将虚拟机跑起来：</p>
<blockquote>
<p>$ vagrant up<br>Bringing machine ‘web’ up with ‘virtualbox’ provider…<br>Bringing machine ‘db’ up with ‘virtualbox’ provider…<br>[web] Setting the name of the VM…<br>[web] Clearing any previously set forwarded ports…<br>[web] Creating shared folders metadata…<br>[web] Clearing any previously set network interfaces…<br>[web] Preparing network interfaces based on configuration…<br>[web] Forwarding ports…<br>[web] – 22 =&gt; 2222 (adapter 1)<br>[web] Running any VM customizations…<br>[web] Booting VM…<br>[web] Waiting for VM to boot. This can take a few minutes.<br>[web] VM booted and ready for use!<br>[web] Setting hostname…<br>[web] Configuring and enabling network interfaces…<br>[web] Mounting shared folders…<br>[web] – /vagrant<br>[db] Setting the name of the VM…<br>[db] Clearing any previously set forwarded ports…<br>[db] Fixed port collision for 22 =&gt; 2222. Now on port 2200.<br>[db] Creating shared folders metadata…<br>[db] Clearing any previously set network interfaces…<br>[db] Preparing network interfaces based on configuration…<br>[db] Forwarding ports…<br>[db] – 22 =&gt; 2200 (adapter 1)<br>[db] Running any VM customizations…<br>[db] Booting VM…<br>[db] Waiting for VM to boot. This can take a few minutes.<br>[db] VM booted and ready for use!<br>[db] Setting hostname…<br>[db] Configuring and enabling network interfaces…<br>[db] Mounting shared folders…<br>[db] – /vagrant</p>
</blockquote>
<p>看到上面的信息输出后，我们就可以通过vagrant ssh登录虚拟机了，但是这次和上次使用的不一样了，这次我们需要指定相应的角色，用来告诉ssh你期望连接的是哪一台：</p>
<p>$ vagrant ssh web<br>vagrant@web:~$</p>
<p>$ vagrant ssh db<br>vagrant@db:~$<br>是不是很酷！现在接下来我们再来验证一下虚拟机之间的通信，让我们先使用ssh登录web虚拟机，然后在web虚拟机上使用ssh登录db虚拟机(默认密码是vagrant)：</p>
<blockquote>
<p>$ vagrant ssh web<br>Linux web 2.6.32-38-server #83-Ubuntu SMP Wed Jan 4 11:26:59 UTC 2012 x86_64 GNU/Linux<br>Ubuntu 10.04.4 LTS</p>
</blockquote>
<blockquote>
<p>Welcome to the Ubuntu Server!</p>
<ul>
<li>Documentation:  <a href="http://www.ubuntu.com/server/doc" target="_blank" rel="noopener">http://www.ubuntu.com/server/doc</a><br>New release ‘precise’ available.<br>Run ‘do-release-upgrade’ to upgrade to it.</li>
</ul>
</blockquote>
<blockquote>
<p>Welcome to your Vagrant-built virtual machine.<br>Last login: Thu Aug  8 18:55:44 2013 from 10.0.2.2<br>vagrant@web:~$ ssh 11.11.1.2<br>The authenticity of host ‘11.11.1.2 (11.11.1.2)’ can’t be established.<br>RSA key fingerprint is e7:8f:07:57:69:08:6e:fa:82:bc:1c:f6:53:3f:12:9e.<br>Are you sure you want to continue connecting (yes/no)? yes<br>Warning: Permanently added ‘11.11.1.2’ (RSA) to the list of known hosts.<br><a href="mailto:vagrant@11.11.1.2" target="_blank" rel="noopener">vagrant@11.11.1.2</a>‘s password:<br>Linux db 2.6.32-38-server #83-Ubuntu SMP Wed Jan 4 11:26:59 UTC 2012 x86_64 GNU/Linux<br>Ubuntu 10.04.4 LTS</p>
</blockquote>
<blockquote>
<p>Welcome to the Ubuntu Server!</p>
<ul>
<li>Documentation:  <a href="http://www.ubuntu.com/server/doc" target="_blank" rel="noopener">http://www.ubuntu.com/server/doc</a><br>New release ‘precise’ available.<br>Run ‘do-release-upgrade’ to upgrade to it.</li>
</ul>
</blockquote>
<blockquote>
<p>Welcome to your Vagrant-built virtual machine.<br>Last login: Thu Aug  8 18:58:50 2013 from 10.0.2.2<br>vagrant@db:~$</p>
</blockquote>
<p>通过上面的信息我们可以看到虚拟机之间通信是畅通的，所以现在开始你伟大的架构设计吧，你想设计怎么样的架构都可以，唯一限制你的就是你主机的硬件配置了。</p>
]]></content>
      <categories>
        <category>技术</category>
        <category>Vagrant</category>
      </categories>
      <tags>
        <tag>Vagrant</tag>
      </tags>
  </entry>
  <entry>
    <title>Vagrant安装配置</title>
    <url>/2017/06/26/Vagrant%E5%AE%89%E8%A3%85%E9%85%8D%E7%BD%AE/</url>
    <content><![CDATA[<p>实际上Vagrant只是一个让你可以方便设置你想要的虚拟机的便携式工具，它底层支持VirtualBox、VMware甚至AWS作为虚拟机系统，本书中我们将使用VirtualBox来进行说明，所以第一步需要先安裝Vagrant和VirtualBox。</p>
<a id="more"></a>
<h2 id="VirtualBox安装"><a href="#VirtualBox安装" class="headerlink" title="VirtualBox安装"></a>VirtualBox安装</h2><p>VirtualBox是Oracle开源的虚拟化系统，它支持多个平台，所以你可以到官方网站：<a href="https://www.virtualbox.org/wiki/Downloads/" target="_blank" rel="noopener">https://www.virtualbox.org/wiki/Downloads/</a> 下载适合你平台的VirtualBox最新版本并安装，它的安装过程都很傻瓜化，一步一步执行就可以完成安装了。</p>
<h2 id="Vagrant安装"><a href="#Vagrant安装" class="headerlink" title="Vagrant安装"></a>Vagrant安装</h2><p>最新版本的Vagrant已经无法通过gem命令来安装，因为依赖库太多了，所以目前无法使用gem来安装，目前网络上面很多教程还是类似这样的命令，那些都是错误的。目前唯一安装的办法就是到官方网站下载打包好的安装包：<a href="http://www.vagrantup.com/downloads.html" target="_blank" rel="noopener">http://www.vagrantup.com/downloads.html</a> 他的安装过程和VirtualBox的安装一样都是傻瓜化安装，一步一步执行就可以完成安装。尽量下载最新的程序，因为VirtualBox经常升级，升级后有些接口会变化，老的Vagrant可能无法使用。</p>
<p>要想检测安装是否成功，可以打开终端命令行工具，输入vagrant，看看程序是不是已经可以运行了。如果不行，请检查一下$PATH里面是否包含vagrant所在的路径。</p>
<h2 id="Vagrant配置"><a href="#Vagrant配置" class="headerlink" title="Vagrant配置"></a>Vagrant配置</h2><p>当我们安装好VirtualBox和Vagrant后，我们要开始考虑在VM上使用什么操作系统了，一个打包好的操作系统在Vagrant中称为Box，即Box是一个打包好的操作系统环境，目前网络上什么都有，所以你不用自己去制作操作系统或者制作Box：vagrantbox.es上面有大家熟知的大多数操作系统，你只需要下载就可以了，下载主要是为了安装的时候快速，当然Vagrant也支持在线安装。没找到Mac的，其他地方找到了 <a href="http://files.dryga.com/boxes/osx-yosemite-0.2.1.box" target="_blank" rel="noopener">http://files.dryga.com/boxes/osx-yosemite-0.2.1.box</a></p>
<h2 id="建立开发环境目录"><a href="#建立开发环境目录" class="headerlink" title="建立开发环境目录"></a>建立开发环境目录</h2><p>我们的开发机是Mac，所以我建立了如下的开发环境目录，读者可以根据自己的系统不同建立一个目录就可以：</p>
<p>/Users/mater/vagrant</p>
<h2 id="下载box"><a href="#下载box" class="headerlink" title="下载box"></a>下载box</h2><p>前面讲了box是一个操作系统环境，实际上它是一个zip包，包含了Vagrant的配置信息和VirtualBox的虚拟机镜像文件.<a href="http://files.dryga.com/boxes/osx-yosemite-0.2.1.box" target="_blank" rel="noopener">http://files.dryga.com/boxes/osx-yosemite-0.2.1.box</a></p>
<p>当然你也可以选一个自己团队在用的系统，例如CentOS、Debian等，我们可以通过上面说的地址下载开源爱好者们制作好的box。</p>
<h2 id="添加box"><a href="#添加box" class="headerlink" title="添加box"></a>添加box</h2><p>添加box的命令如下：</p>
<p>vagrant box add base 远端的box地址或者本地的box文件名<br>vagrant box add 是添加box的命令</p>
<p>base是box的名称，可以是任意的字符串，base是默认名称，主要用来标识一下你添加的box，后面的命令都是基于这个标识来操作的。</p>
<p>例子：</p>
<p>vagrant box add base <a href="http://files.vagrantup.com/lucid64.box" target="_blank" rel="noopener">http://files.vagrantup.com/lucid64.box</a><br>vagrant box add base <a href="https://dl.dropbox.com/u/7225008/Vagrant/CentOS-6.3-x86_64-minimal.box" target="_blank" rel="noopener">https://dl.dropbox.com/u/7225008/Vagrant/CentOS-6.3-x86_64-minimal.box</a><br>vagrant box add base CentOS-6.3-x86_64-minimal.box<br>vagrant box add “CentOS 6.3 x86_64 minimal” CentOS-6.3-x86_64-minimal.box<br>我在开发机上面是这样操作的，首先进入我们的开发环境目录/Users/astaxie/vagrant，执行如下的命令</p>
<p>vagrant box add base lucid64.box<br>安装过程的信息：</p>
<p>Downloading or copying the box…<br>Extracting box…te: 47.5M/s, Estimated time remaining: –:–:–)<br>Successfully added box ‘base’ with provider ‘virtualbox’!<br>box中的镜像文件被放到了：/Users/astaxie/.vagrant.d/boxes/，如果在window系统中应该是放到了： C:\Users\当前用户名.vagrant.d\boxes\目录下。</p>
<p>通过vagrant box add这样的方式安装远程的box，可能很慢，所以建议大家先下载box到本地再执行这样的操作。</p>
<h2 id="初始化"><a href="#初始化" class="headerlink" title="初始化"></a>初始化</h2><p>初始化的命令如下：</p>
<p>vagrant init<br>如果你添加的box名称不是base，那么需要在初始化的时候指定名称，例如</p>
<p>vagrant init “CentOS 6.3 x86_64 minimal”<br>初始化过程的信息：</p>
<p>A <code>Vagrantfile</code> has been placed in this directory.<br>You are now ready to <code>vagrant up</code> your first virtual environment!<br>Please read the comments in the Vagrantfile as well as documentation on <code>vagrantup.com</code> for more information on using Vagrant.<br>这样就会在当前目录生成一个 Vagrantfile的文件，里面有很多配置信息，后面我们会详细讲解每一项的含义，但是默认的配置就可以开箱即用。</p>
<h2 id="启动虚拟机"><a href="#启动虚拟机" class="headerlink" title="启动虚拟机"></a>启动虚拟机</h2><p>启动虚拟机的命令如下：</p>
<p>vagrant up<br>启动过程的信息:</p>
<p>Bringing machine ‘default’ up with ‘virtualbox’ provider…<br>[default] Importing base box ‘base’…<br>[default] Matching MAC address for NAT networking…<br>[default] Setting the name of the VM…<br>[default] Clearing any previously set forwarded ports…<br>[default] Creating shared folders metadata…<br>[default] Clearing any previously set network interfaces…<br>[default] Preparing network interfaces based on configuration…<br>[default] Forwarding ports…<br>[default] – 22 =&gt; 2222 (adapter 1)<br>[default] Booting VM…<br>[default] Waiting for VM to boot. This can take a few minutes.<br>[default] VM booted and ready for use!<br>[default] Mounting shared folders…<br>[default] – /vagrant</p>
<h2 id="连接到虚拟机"><a href="#连接到虚拟机" class="headerlink" title="连接到虚拟机"></a>连接到虚拟机</h2><p>上面已经启动了虚拟机，之后我们就可以通过ssh来连接到虚拟机了。比如在我的开发机中可以像这样来连接：</p>
<p>vagrant ssh<br>连接到虚拟机后的信息如下：</p>
<p>Linux lucid64 2.6.32-38-server #83-Ubuntu SMP Wed Jan 4 11:26:59 UTC 2012 x86_64 GNU/Linux<br>Ubuntu 10.04.4 LTS</p>
<p>Welcome to the Ubuntu Server!</p>
<ul>
<li>Documentation:  <a href="http://www.ubuntu.com/server/doc" target="_blank" rel="noopener">http://www.ubuntu.com/server/doc</a><br>New release ‘precise’ available.<br>Run ‘do-release-upgrade’ to upgrade to it.</li>
</ul>
<p>Welcome to your Vagrant-built virtual machine.<br>Last login: Fri Sep 14 07:31:39 2012 from 10.0.2.2<br>这样我们就可以像连接到一台服务器一样进行操作了。window机器不支持这样的命令，必须使用第三方客户端来进行连接，例如putty、Xshell4等.</p>
<blockquote>
<p>putty为例：</p>
</blockquote>
<blockquote>
<p>主机地址: 127.0.0.1</p>
</blockquote>
<blockquote>
<p>端口: 2222</p>
</blockquote>
<blockquote>
<p>用户名: vagrant</p>
</blockquote>
<blockquote>
<p>密码: vagrant</p>
</blockquote>
<h2 id="系统信息"><a href="#系统信息" class="headerlink" title="系统信息"></a>系统信息</h2><p>进入系统之后我们可以看一下系统的基础信息：</p>
<p>vagrant@lucid64:/vagrant$ df -h<br>Filesystem            Size  Used Avail Use% Mounted on<br>/dev/mapper/lucid64-root<br>                       78G  945M   73G   2% /<br>none                  179M  176K  179M   1% /dev<br>none                  184M     0  184M   0% /dev/shm<br>none                  184M   64K  184M   1% /var/run<br>none                  184M     0  184M   0% /var/lock<br>none                  184M     0  184M   0% /lib/init/rw<br>none                   78G  945M   73G   2% /var/lib/ureadahead/debugfs<br>/dev/sda1             228M   17M  199M   8% /boot<br>/vagrant              298G   76G  222G  26% /vagrant<br>/vagrant这个目录是自动映射的，被映射到/Users/astaxie/vagrant，这样就方便我们以后在开发机中进行开发，在虚拟机中进行运行效果测试了。</p>
<h2 id="Vagrantfile配置文件详解"><a href="#Vagrantfile配置文件详解" class="headerlink" title="Vagrantfile配置文件详解"></a>Vagrantfile配置文件详解</h2><p>在我们的开发目录下有一个文件Vagrantfile，里面包含有大量的配置信息，主要包括三个方面的配置，虚拟机的配置、SSH配置、Vagrant的一些基础配置。Vagrant是使用Ruby开发的，所以它的配置语法也是Ruby的，但是我们没有学过Ruby的人还是可以跟着它的注释知道怎么配置一些基本项的配置。</p>
<ol>
<li><p>box设置</p>
<p>config.vm.box = “base”<br>上面这配置展示了Vagrant要去启用那个box作为系统，也就是上面我们输入vagrant init Box名称时所指定的box，如果沒有输入box名称的話，那么默认就是base，VirtualBox提供了VBoxManage这个命令行工具，可以让我们设定VM，用modifyvm这个命令让我们可以设定VM的名称和内存大小等等，这里说的名称指的是在VirtualBox中显示的名称，我们也可以在Vagrantfile中进行设定，在Vagrantfile中加入如下这行就可以设定了：</p>
<p>config.vm.provider “virtualbox” do |v|<br>v.customize [“modifyvm”, :id, “–name”, “astaxie”, “–memory”, “512”]<br>end<br>这行设置的意思是调用VBoxManage的modifyvm的命令，设置VM的名称为astaxie，内存为512MB。你可以类似的通过定制其它VM属性来定制你自己的VM。</p>
</li>
<li><p>网络设置<br>Vagrant有两种方式来进行网络连接，一种是host-only(主机模式)，意思是主机和虚拟机之间的网络互访，而不是虚拟机访问internet的技术，也就是只有你一個人自High，其他人访问不到你的虚拟机。另一种是Bridge(桥接模式)，该模式下的VM就像是局域网中的一台独立的主机，也就是说需要VM到你的路由器要IP，这样的话局域网里面其他机器就可以访问它了，一般我们设置虚拟机都是自high为主，所以我们的设置一般如下：</p>
<p>config.vm.network :private_network, ip: “11.11.11.11”<br>这里我们虚拟机设置为hostonly，并且指定了一个IP，IP的话建议最好不要用192.168..这个网段，因为很有可能和你局域网里面的其它机器IP冲突，所以最好使用类似11.11..这样的IP地址。</p>
</li>
<li><p>hostname设置<br>hostname的设置非常简单，Vagrantfile中加入下面这行就可以了：</p>
<p>config.vm.hostname = “go-app”<br>设置hostname非常重要，因为当我们有很多台虚拟服务器的时候，都是依靠hostname來做识别的，例如Puppet或是Chef，都是通过hostname來做识别的，既然设置那么简单，所以我们就別偷懒，设置一个。</p>
</li>
<li><p>同步目录<br>我们上面介绍过/vagrant目录默认就是当前的开发目录，这是在虚拟机开启的时候默认挂载同步的。我们还可以通过配置来设置额外的同步目录：<br>config.vm.synced_folder  “/Users/astaxie/data”, “/vagrant_data”<br>上面这个设定，第一个参数是主机的目录，第二个参数是虚拟机挂载的目录</p>
</li>
<li><p>端口转发<br>config.vm.network :forwarded_port, guest: 80, host: 8080<br>上面这句配置可厉害了，这一行的意思是把对host机器上8080端口的访问请求forward到虚拟机的80端口的服务上，例如你在你的虚拟机上使用nginx跑了一个Go应用，那么你在host机器上的浏览器中打开<a href="http://localhost:8080" target="_blank" rel="noopener">http://localhost:8080</a> 时，Vagrant就会把这个请求转发到VM里面跑在80端口的nginx服务上，因此我们可以通过这个设置来帮助我们去设定host和VM之间，或是VM和VM之间的信息交互。<br>修改完Vagrantfile的配置后，记得要用vagrant reload命令来重启VM之后才能使用VM更新后的配置</p>
</li>
</ol>
]]></content>
      <categories>
        <category>技术</category>
        <category>Vagrant</category>
      </categories>
      <tags>
        <tag>Vagrant</tag>
      </tags>
  </entry>
  <entry>
    <title>Vagrant介绍</title>
    <url>/2017/06/26/Vagrant%E4%BB%8B%E7%BB%8D/</url>
    <content><![CDATA[<h2 id="虚拟开发环境"><a href="#虚拟开发环境" class="headerlink" title="虚拟开发环境"></a>虚拟开发环境</h2><p>平常我们经常会遇到这样的问题：在开发机上面开发完毕程序，放到正式环境之后会出现各种奇怪的问题：描述符少了、nginx配置不正确、MySQL编码不对、php缺少模块、glibc版本太低等。</p>
<p>所以我们就需要虚拟开发环境，我们虚拟和正式环境一样的虚拟开发环境，而随着个人开发机硬件的升级，我们可以很容易的在本机跑虚拟机，例如VMware、VirtualBox等。因此使用虚拟化开发环境，在本机可以运行自己喜欢的OS（Windows、Ubuntu、Mac等），开发的程序运行在虚拟机中，这样迁移到生产环境可以避免环境不一致导致的莫名错误。</p>
<a id="more"></a>
<p>虚拟开发环境特别适合团队中开发环境、测试环境、正式环境不同的场合，这样就可以使得整个团队保持一致的环境，我写这一章的初衷就是为了让大家和我的开发环境保持一致，让读者和我们整个大团队保持一致的开发环境。</p>
<h2 id="Vagrant"><a href="#Vagrant" class="headerlink" title="Vagrant"></a>Vagrant</h2><blockquote>
<p>Vagrant是一款用于构建及配置虚拟开发环境的软件，基于Ruby,主要以命令行的方式运行。</p>
</blockquote>
<blockquote>
<p>主要使用Oracle的开源VirtualBox虚拟化系统，与Chef，Salt，Puppet等环境配置管理软件搭配使用， 可以实行快速虚拟开发环境的构建。</p>
</blockquote>
<blockquote>
<p>早期以VirtualBox为对象，1.1以后的版本中开始对应VMware等虚拟化软件，包括Amazon EC2之类服务器环境的对应。</p>
</blockquote>
<blockquote>
<p><a href="https://zh.wikipedia.org/wiki/Vagrant" target="_blank" rel="noopener">https://zh.wikipedia.org/wiki/Vagrant</a></p>
</blockquote>
<p>官方文档：<a href="https://www.vagrantup.com/intro/getting-started/index.html" target="_blank" rel="noopener">https://www.vagrantup.com/intro/getting-started/index.html</a></p>
<p>Vagrant就是为了方便的实现虚拟化环境而设计的，使用Ruby开发，基于VirtualBox等虚拟机管理软件的接口，提供了一个可配置、轻量级的便携式虚拟开发环境。使用Vagrant可以很方便的就建立起来一个虚拟环境，而且可以模拟多台虚拟机，这样我们平时还可以在开发机模拟分布式系统。</p>
<p>Vagrant还会创建一些共享文件夹，用来给你在主机和虚拟机之间共享代码用。这样就使得我们可以在主机上写程序，然后在虚拟机中运行。如此一来团队之间就可以共享相同的开发环境，就不会再出现类似“只有你的环境才会出现的bug”这样的事情。</p>
<p>团队新员工加入，常常会遇到花一天甚至更多时间来从头搭建完整的开发环境，而有了Vagrant，只需要直接将已经打包好的package（里面包括开发工具，代码库，配置好的服务器等）拿过来就可以工作了，这对于提升工作效率非常有帮助。</p>
<p>Vagrant不仅可以用来作为个人的虚拟开发环境工具，而且特别适合团队使用，它使得我们虚拟化环境变得如此的简单，只要一个简单的命令就可以开启虚拟之路。</p>
]]></content>
      <categories>
        <category>技术</category>
        <category>Vagrant</category>
      </categories>
      <tags>
        <tag>Vagrant</tag>
      </tags>
  </entry>
  <entry>
    <title>时间管理</title>
    <url>/2017/05/24/%E6%97%B6%E9%97%B4%E7%AE%A1%E7%90%86/</url>
    <content><![CDATA[<h2 id="什么是时间管理"><a href="#什么是时间管理" class="headerlink" title="什么是时间管理"></a>什么是时间管理</h2><blockquote>
<p><strong>时间管理</strong>（Time Management）就是用技巧、技术和工具帮助人们完成工作，实现目标。时间管理并不是要把所有事情做完，而是更有效的运用时间。时间管理的目的除了要决定你该做些什么事情之外，另一个很重要的目的也是决定什么事情不应该做；时间管理不是完全的掌控，而是降低变动性。时间管理最重要的功能是透过事先的规划，做为一种提醒与指引。</p>
<p><a href="https://zh.wikipedia.org/zh-cn/%E6%97%B6%E9%97%B4%E7%AE%A1%E7%90%86" target="_blank" rel="noopener">https://zh.wikipedia.org/zh-cn/%E6%97%B6%E9%97%B4%E7%AE%A1%E7%90%86</a></p>
</blockquote>
<p>时间的管理最重要的在于能够集中自己的大的整块时间进行某些问题的处理。</p>
<a id="more"></a>
<h2 id="时间流逝"><a href="#时间流逝" class="headerlink" title="时间流逝"></a>时间流逝</h2><p>以下是你必须要知道的真相</p>
<ol>
<li>平均每30分钟会受到一次打扰</li>
<li>平均每次打扰用时大约是五分钟，总共大约两小时。</li>
<li>如果你让自己一天做一件事情，你会花一整天去做；</li>
<li>如果你让自己一天做二十件事情，则会完成七至八件甚至更多。</li>
<li>一年之中，你真正在做有价值的事情的时间不会超过九十天。</li>
<li>三年内，如果你好好的规划一下你的人生和时间，你能够取得是之前的三到五倍。</li>
</ol>
<p>浪费时间的原因有主观和客观两大方面。这里，我们来分析一下浪费时间的主观原因，因为，这是一切的根源。</p>
<h2 id="主观原因"><a href="#主观原因" class="headerlink" title="主观原因"></a>主观原因</h2><h3 id="观念不对"><a href="#观念不对" class="headerlink" title="观念不对"></a>观念不对</h3><ul>
<li><p>进取心不足</p>
</li>
<li><p>缺乏时间意识</p>
</li>
<li>态度消极悲观</li>
</ul>
<h3 id="目标不明"><a href="#目标不明" class="headerlink" title="目标不明"></a>目标不明</h3><ul>
<li>缺乏计划</li>
<li>抓不住重点</li>
</ul>
<h3 id="技巧不够"><a href="#技巧不够" class="headerlink" title="技巧不够"></a>技巧不够</h3><ul>
<li>缺乏优先顺序</li>
<li>做事有头无尾。</li>
<li>没有条理，不简洁，简单的事情复杂化。</li>
<li>事必躬亲，不懂得授权。</li>
<li>不会拒绝别人的请求。</li>
</ul>
<h3 id="习惯不好"><a href="#习惯不好" class="headerlink" title="习惯不好"></a>习惯不好</h3><ul>
<li>5S整顿不足<br>（ps: 5S：整理（SEIRI）、整顿（SEITON）、清扫（SEISO）、清洁（SEIKETSU）、素养（SHITSUKE），又被称为“五常法则”或“五常法”,适用于制造业、服务业<img src="http://wiki.mbalib.com/w/images/0/0d/5S%E7%8E%B0%E5%9C%BA%E7%AE%A1%E7%90%86%E6%B3%95%E5%9B%BE%E7%A4%BA.gif" alt="img"><br><a href="http://wiki.mbalib.com/wiki/5S%E7%8E%B0%E5%9C%BA%E7%AE%A1%E7%90%86%E6%B3%95#.E4.BB.80.E4.B9.88.E6.98.AF5S.E7.8E.B0.E5.9C.BA.E7.AE.A1.E7.90.86.E6.B3.95" target="_blank" rel="noopener">http://wiki.mbalib.com/wiki/5S%E7%8E%B0%E5%9C%BA%E7%AE%A1%E7%90%86%E6%B3%95#.E4.BB.80.E4.B9.88.E6.98.AF5S.E7.8E.B0.E5.9C.BA.E7.AE.A1.E7.90.86.E6.B3.95</a>)</li>
<li>工作作风拖拉。</li>
</ul>
<h3 id="组织不当"><a href="#组织不当" class="headerlink" title="组织不当"></a>组织不当</h3><ul>
<li>工作流程不畅</li>
<li>标准不明确需返工</li>
<li>相互配合衔接不当</li>
</ul>
<p>摘自 <a href="http://baike.baidu.com/item/%E6%97%B6%E9%97%B4%E7%AE%A1%E7%90%86%E6%96%B9%E6%B3%95" target="_blank" rel="noopener">http://baike.baidu.com/item/%E6%97%B6%E9%97%B4%E7%AE%A1%E7%90%86%E6%96%B9%E6%B3%95</a></p>
<p>针对个人的情况有重点的解决主观原因。（感觉自己每个大项都占了。。）</p>
<h2 id="道"><a href="#道" class="headerlink" title="道"></a>道</h2><p>1、取消法：所有的事情，首先分析必要性，能取消的就取消，能回避的就回避（不认同，应该是适当的回避），集中做对你目标最有价值的事情。比如看电视、闲聊、发呆(包括发愁、批评社会)、漫无目的上网、过于广泛的兴趣、过于广泛的人际关系统统取消，只做最有价值的事情，比如学习、休息、工作。<br>2、以人替时法：能让别人代劳的事情，自己就不要做，学会运用别人的时间。因为每个人的精力都是有限的，所谓有所谓有所不为，把自己的精力和时间用在最能体现自己价值的方面。<br>3、改善效率法：学习最新的知识，掌握最新的工具，改进效率，本来花1个小时的工作，想办法变成0.5小时完成，这样可以节省更多时间用于学习。<br>4、以钱购时法：交通方面，能坐飞机，就不要坐火车;如果能打车，就不要等公交;乘坐最快的、最有助于休息、学习的交通工具;学习方面，采用最有效率的学习方法，能面授听课就不看视频;能看视频的，就不买图书;工作方面，用最好的工作设备比如用最好的电脑、用最快的传真机，说服你的老板不要在设备上斤斤计较，要分析好的设备所节省的时间、所带来的价值。时光一去不复返，千金散尽还复来<br>5、见缝插针法：在等人、在乘车、地铁时利用间隙时间听录音、思考。例如对于很多在北京工作的人，每天在路上大概需要2小时，如果每天的2小时利用来听录音，每年可以有720小时在学习，如果坚持10年，就是7200小时，这些时间不管是听管理知识、还是学英语，都可以取得很大的收益。</p>
<p>摘自<a href="http://www.rs66.com/a/2/88/zuiyouxiaode5geshijianguanlifangfa_105397.html" target="_blank" rel="noopener">http://www.rs66.com/a/2/88/zuiyouxiaode5geshijianguanlifangfa_105397.html</a></p>
<h2 id="术"><a href="#术" class="headerlink" title="术"></a>术</h2><p>1.</p>
<blockquote>
<p>“进程切换非常昂贵，避免多任务，保持单进程。”</p>
</blockquote>
<p><img src="http://www.ruanyifeng.com/blogimg/asset/2016/bg2016051302.png" alt="img"></p>
<p>不要同时做多件事，结果可能都没做好，还拖长了工作时间。</p>
<p><img src="http://www.ruanyifeng.com/blogimg/asset/2016/bg2016051303.png" alt="img"></p>
<p>上图是多任务状态和单进程状态的对比，可以看到，多任务状态会花费更多的时间。</p>
<p>2.</p>
<blockquote>
<p>“研究表明，集中注意力、高效工作，每天最多4小时。”</p>
</blockquote>
<p><img src="http://www.ruanyifeng.com/blogimg/asset/2016/bg2016051304.png" alt="img"></p>
<p>一个人能够集中注意力的时间，是有限的。一般来说，高效工作只能持续四个小时，其余时间就都是低效工作了。</p>
<p><img src="http://www.ruanyifeng.com/blogimg/asset/2016/bg2016051305.png" alt="img"></p>
<p>上图左侧是大多数人每天的时间分配，如果你能保证4个小时都高效工作，那么完全可以变成右侧的时间分配。</p>
<p>3.</p>
<blockquote>
<p>“划分任务的优先级，不要把’急切’当作’重要’。”</p>
</blockquote>
<p><img src="http://www.ruanyifeng.com/blogimg/asset/2016/bg2016051306.png" alt="img"></p>
<p>你的时间有限，不可能做所有事。最重要的事，应该首先做。（推荐阅读<a href="http://www.ruanyifeng.com/blog/2009/01/stuff_that_matters.html" target="_blank" rel="noopener">《什么是重要的事情？》</a>）</p>
<p><img src="http://www.ruanyifeng.com/blogimg/asset/2016/bg2016051307.png" alt="img"></p>
<p>一个有用的技巧是，将所有任务按照”重要性”和”紧急性”两个维度，分成四个象限。第一象限优先级最高，第四象限最低。</p>
<p>4.</p>
<blockquote>
<p>“起床后，不要查看邮件和微信。”</p>
</blockquote>
<p><img src="http://www.ruanyifeng.com/blogimg/asset/2016/bg2016051308.png" alt="img"></p>
<p>早晨精力最充沛，消耗在邮件和微信就太可惜了，应该用来做更重要的事。而且，邮件代表对别人优先级高，不等于对你优先级高。你的时间到底属于谁？你自己，还是某个给你写信的人？（推荐阅读<a href="http://www.ruanyifeng.com/blog/2011/01/never_check_email_first_thing_in_the_morning.html" target="_blank" rel="noopener">《为什么起床后不能收邮件？》</a>）</p>
<p>5.</p>
<blockquote>
<p>“避免开会，因为人类已知的最浪费时间的事情，就是开会。”</p>
</blockquote>
<p><img src="http://www.ruanyifeng.com/blogimg/asset/2016/bg2016051309.png" alt="img"></p>
<p>越大的公司，越无法避免开会。但至少不要参加与你无关的会。站着开会，也许是一个缩短会议时间的好办法。</p>
<p>6.</p>
<blockquote>
<p>“早晨4点起床，到了中午，你就完成了一天的任务。”</p>
</blockquote>
<p><img src="http://www.ruanyifeng.com/blogimg/asset/2016/bg2016051310.png" alt="img"></p>
<p>早晨4点起床开始工作，你会发现每天的时间多出了好多。有个日本人写了一本书《四点起床》，就是讲这个观点。</p>
<p>7.</p>
<blockquote>
<p>“你没空时不会做的事情，有空了也不会做。”</p>
</blockquote>
<p><img src="http://www.ruanyifeng.com/blogimg/asset/2016/bg2016051311.png" alt="img"></p>
<p>世上并没有拖延症，只是不想做而已。如果可能，应该尽早放弃你没有意愿去做的那些事。而那些没有时间也会去做的事，才是你应该全力以赴的人生方向。</p>
<p>摘自 <a href="http://www.ruanyifeng.com/blog/2016/05/time-management.html" target="_blank" rel="noopener">http://www.ruanyifeng.com/blog/2016/05/time-management.html</a></p>
<p>\8. 目标明确,明白为什么做这件事。目标要具体、具有可实现性</p>
<p>9.遵循你的生物钟。你办事效率最佳的时间是什么时候？将优先办的事情放在最佳时间里。</p>
<p>10.做好的事情要比把事情做好更重要。做好的事情，是有效果；把事情做好仅仅是有效率。首先考虑效果，然后才考虑效率.</p>
<p>11.学会说”不”。一旦确定了哪些事情是重要的，对那些不重要的事情就应当说”不”。</p>
<h2 id="总结"><a href="#总结" class="headerlink" title="总结"></a>总结</h2><p>1.按照 “重要、紧急”的优先级列好工作内容。</p>
<p>2.将关键工作安排在不被打扰的时间。</p>
<p>3.预估被打扰的时间，这段时间做非关键工作。</p>
<p>4.不重要的事情说不，或分配他人。</p>
<h2 id="参考资料"><a href="#参考资料" class="headerlink" title="参考资料"></a>参考资料</h2><p><a href="https://zh.wikipedia.org/zh-cn/%E6%97%B6%E9%97%B4%E7%AE%A1%E7%90%86" target="_blank" rel="noopener">https://zh.wikipedia.org/zh-cn/%E6%97%B6%E9%97%B4%E7%AE%A1%E7%90%86</a></p>
<p><a href="http://wiki.mbalib.com/wiki/5S%E7%8E%B0%E5%9C%BA%E7%AE%A1%E7%90%86%E6%B3%95#.E4.BB.80.E4.B9.88.E6.98.AF5S.E7.8E.B0.E5.9C.BA.E7.AE.A1.E7.90.86.E6.B3.95" target="_blank" rel="noopener">http://wiki.mbalib.com/wiki/5S%E7%8E%B0%E5%9C%BA%E7%AE%A1%E7%90%86%E6%B3%95#.E4.BB.80.E4.B9.88.E6.98.AF5S.E7.8E.B0.E5.9C.BA.E7.AE.A1.E7.90.86.E6.B3.95</a></p>
<p><a href="http://baike.baidu.com/item/%E6%97%B6%E9%97%B4%E7%AE%A1%E7%90%86%E6%96%B9%E6%B3%95" target="_blank" rel="noopener">http://baike.baidu.com/item/%E6%97%B6%E9%97%B4%E7%AE%A1%E7%90%86%E6%96%B9%E6%B3%95</a></p>
<p><a href="http://www.rs66.com/a/2/88/zuiyouxiaode5geshijianguanlifangfa_105397.html" target="_blank" rel="noopener">http://www.rs66.com/a/2/88/zuiyouxiaode5geshijianguanlifangfa_105397.html</a></p>
<p><a href="http://www.ruanyifeng.com/blog/2016/05/time-management.html" target="_blank" rel="noopener">http://www.ruanyifeng.com/blog/2016/05/time-management.html</a></p>
]]></content>
      <categories>
        <category>通用能力</category>
        <category>时间管理</category>
      </categories>
      <tags>
        <tag>时间管理</tag>
      </tags>
  </entry>
  <entry>
    <title>Zookeeper学习曲线</title>
    <url>/2017/05/13/Zookeeper%E5%AD%A6%E4%B9%A0%E6%9B%B2%E7%BA%BF/</url>
    <content><![CDATA[<h2 id="ZooKeeper-介绍"><a href="#ZooKeeper-介绍" class="headerlink" title="ZooKeeper 介绍"></a>ZooKeeper 介绍</h2><p><a href="http://zookeeper.apache.org/" target="_blank" rel="noopener">http://zookeeper.apache.org/</a><br><a href="https://www.ibm.com/developerworks/cn/opensource/os-cn-zookeeper/" target="_blank" rel="noopener">https://www.ibm.com/developerworks/cn/opensource/os-cn-zookeeper/</a><br><a id="more"></a></p>
<h2 id="命名服务"><a href="#命名服务" class="headerlink" title="命名服务"></a>命名服务</h2><h3 id="zooKeeper-监听事件原理"><a href="#zooKeeper-监听事件原理" class="headerlink" title="zooKeeper 监听事件原理"></a>zooKeeper 监听事件原理</h3><h2 id="配置管理"><a href="#配置管理" class="headerlink" title="配置管理"></a>配置管理</h2><h2 id="集群管理"><a href="#集群管理" class="headerlink" title="集群管理"></a>集群管理</h2><h2 id="共享锁"><a href="#共享锁" class="headerlink" title="共享锁"></a>共享锁</h2><h2 id="队列管理"><a href="#队列管理" class="headerlink" title="队列管理"></a>队列管理</h2><h2 id="ZooKeeper-原理部分"><a href="#ZooKeeper-原理部分" class="headerlink" title="ZooKeeper 原理部分"></a>ZooKeeper 原理部分</h2>]]></content>
      <categories>
        <category>技术</category>
        <category>ZooKeeper</category>
      </categories>
      <tags>
        <tag>zookeeper</tag>
        <tag>distributed</tag>
      </tags>
  </entry>
  <entry>
    <title>akka</title>
    <url>/2017/05/13/akka/</url>
    <content><![CDATA[<p><a href="https://doron.gitbooks.io/akka-doc-zh/content/index.html" target="_blank" rel="noopener">https://doron.gitbooks.io/akka-doc-zh/content/index.html</a><br><a href="http://developer.lightbend.com/guides/akka-quickstart-java/" target="_blank" rel="noopener">http://developer.lightbend.com/guides/akka-quickstart-java/</a><br><a href="http://doc.akka.io/docs/akka/current/java/guide/index.html" target="_blank" rel="noopener">http://doc.akka.io/docs/akka/current/java/guide/index.html</a><br><a href="https://github.com/jasonqu/akka-doc-cn" target="_blank" rel="noopener">https://github.com/jasonqu/akka-doc-cn</a></p>
]]></content>
      <categories>
        <category>技术</category>
        <category>akka</category>
      </categories>
      <tags>
        <tag>distributed</tag>
        <tag>concurrency</tag>
        <tag>JVM</tag>
      </tags>
  </entry>
  <entry>
    <title>Hystrix</title>
    <url>/2017/05/13/Hystrix/</url>
    <content><![CDATA[<p><a href="https://github.com/Netflix/Hystrix/wiki#what" target="_blank" rel="noopener">https://github.com/Netflix/Hystrix/wiki#what</a></p>
]]></content>
      <categories>
        <category>技术</category>
        <category>Hystrix</category>
      </categories>
      <tags>
        <tag>JAVA</tag>
        <tag>Distributed System</tag>
        <tag>latency tolerance</tag>
        <tag>fault tolerance</tag>
      </tags>
  </entry>
  <entry>
    <title>Kafka原理</title>
    <url>/2017/05/06/Kafka%E5%8E%9F%E7%90%86/</url>
    <content><![CDATA[<p>摘自一篇博客，找不到了 </p>
<h2 id="Kafka技术概览"><a href="#Kafka技术概览" class="headerlink" title="Kafka技术概览"></a>Kafka技术概览</h2><h3 id="Kafka的特性"><a href="#Kafka的特性" class="headerlink" title="Kafka的特性"></a>Kafka的特性</h3><p>高吞吐量、低延迟：kafka每秒可以处理几十万条消息，它的延迟最低只有几毫秒</p>
<p>可扩展性：kafka集群支持热扩展</p>
<p>持久性、可靠性：消息被持久化到本地磁盘，并且支持数据备份防止数据丢失</p>
<p>容错性：允许集群中节点失败（若副本数量为n,则允许n-1个节点失败）</p>
<p>高并发：支持数千个客户端同时读写</p>
<h3 id="Kafka一些重要设计思想"><a href="#Kafka一些重要设计思想" class="headerlink" title="Kafka一些重要设计思想"></a>Kafka一些重要设计思想</h3><p>下面介绍先大体介绍一下Kafka的主要设计思想，可以让相关人员在短时间内了解到kafka相关特性，如果想深入研究，后面会对其中每一个特性都做详细介绍。</p>
<a id="more"></a>
<h4 id="Consumer-Group"><a href="#Consumer-Group" class="headerlink" title="Consumer Group"></a>Consumer Group</h4><p>各个consumer可以组成一个组，每个消息只能被组中的一个consumer消费，如果一个消息可以被多个consumer消费的话，那么这些consumer必须在不同的组。</p>
<h4 id="消息状态"><a href="#消息状态" class="headerlink" title="消息状态"></a>消息状态</h4><p>在Kafka中，消息的状态被保存在consumer中，broker不会关心哪个消息被消费了被谁消费了，只记录一个offset值（指向partition中下一个要被消费的消息位置），这就意味着如果consumer处理不好的话，broker上的一个消息可能会被消费多次。</p>
<h4 id="消息持久化"><a href="#消息持久化" class="headerlink" title="消息持久化"></a>消息持久化</h4><p>Kafka中会把消息持久化到本地文件系统中，并且保持极高的效率。</p>
<h4 id="消息有效期"><a href="#消息有效期" class="headerlink" title="消息有效期"></a>消息有效期</h4><p>Kafka会长久保留其中的消息，以便consumer可以多次消费，当然其中很多细节是可配置的。</p>
<h4 id="批量发送"><a href="#批量发送" class="headerlink" title="批量发送"></a>批量发送</h4><p>Kafka支持以消息集合为单位进行批量发送，以提高push效率。</p>
<h4 id="push-and-pull"><a href="#push-and-pull" class="headerlink" title="push-and-pull"></a>push-and-pull</h4><p>Kafka中的Producer和consumer采用的是push-and-pull模式，即Producer只管向broker push消息，consumer只管从broker pull消息，两者对消息的生产和消费是异步的。</p>
<h4 id="负载均衡方面"><a href="#负载均衡方面" class="headerlink" title="负载均衡方面"></a>负载均衡方面</h4><p>Kafka提供了一个 metadata API来管理broker之间的负载（对Kafka0.8.x而言，对于0.7.x主要靠zookeeper来实现负载均衡）。</p>
<h4 id="同步异步"><a href="#同步异步" class="headerlink" title="同步异步"></a>同步异步</h4><p>Producer采用异步push方式，极大提高Kafka系统的吞吐率（可以通过参数控制是采用同步还是异步方式）。</p>
<h4 id="分区机制partition"><a href="#分区机制partition" class="headerlink" title="分区机制partition"></a>分区机制partition</h4><p>Kafka的broker端支持消息分区，Producer可以决定把消息发到哪个分区，在一个分区中消息的顺序就是Producer发送消息的顺序，一个主题中可以有多个分区，具体分区的数量是可配置的。分区的意义很重大，后面的内容会逐渐体现。</p>
<h4 id="离线数据装载"><a href="#离线数据装载" class="headerlink" title="离线数据装载"></a>离线数据装载</h4><p>Kafka由于对可拓展的数据持久化的支持，它也非常适合向Hadoop或者数据仓库中进行数据装载。</p>
<h4 id="插件支持"><a href="#插件支持" class="headerlink" title="插件支持"></a>插件支持</h4><p>现在不少活跃的社区已经开发出不少插件来拓展Kafka的功能，如用来配合Storm、Hadoop、flume相关的插件。</p>
<h3 id="kafka-应用场景"><a href="#kafka-应用场景" class="headerlink" title="kafka 应用场景"></a>kafka 应用场景</h3><h4 id="日志收集"><a href="#日志收集" class="headerlink" title="日志收集"></a>日志收集</h4><p>一个公司可以用Kafka可以收集各种服务的log，通过kafka以统一接口服务的方式开放给各种consumer，例如hadoop、Hbase、Solr等。</p>
<h4 id="消息系统"><a href="#消息系统" class="headerlink" title="消息系统"></a>消息系统</h4><p>解耦和生产者和消费者、缓存消息等。</p>
<h4 id="用户活动跟踪"><a href="#用户活动跟踪" class="headerlink" title="用户活动跟踪"></a>用户活动跟踪</h4><p>Kafka经常被用来记录web用户或者app用户的各种活动，如浏览网页、搜索、点击等活动，这些活动信息被各个服务器发布到kafka的topic中，然后订阅者通过订阅这些topic来做实时的监控分析，或者装载到hadoop、数据仓库中做离线分析和挖掘。</p>
<h4 id="运营指标"><a href="#运营指标" class="headerlink" title="运营指标"></a>运营指标</h4><p>Kafka也经常用来记录运营监控数据。包括收集各种分布式应用的数据，生产各种操作的集中反馈，比如报警和报告。</p>
<h4 id="流式处理"><a href="#流式处理" class="headerlink" title="流式处理"></a>流式处理</h4><p>比如spark streaming和storm</p>
<h4 id="事件源"><a href="#事件源" class="headerlink" title="事件源"></a>事件源</h4><h3 id="Kafka架构组件"><a href="#Kafka架构组件" class="headerlink" title="Kafka架构组件"></a>Kafka架构组件</h3><p>Kafka中发布订阅的对象是topic。我们可以为每类数据创建一个topic，把向topic发布消息的客户端称作producer，从topic订阅消息的客户端称作consumer。Producers和consumers可以同时从多个topic读写数据。一个kafka集群由一个或多个broker服务器组成，它负责持久化和备份具体的kafka消息。</p>
<ul>
<li>topic：消息存放的目录即主题</li>
<li>Producer：生产消息到topic的一方</li>
<li>Consumer：订阅topic消费消息的一方</li>
<li>Broker：Kafka的服务实例就是一个broker</li>
</ul>
<p><img src="/img/15255327943144.jpg" alt></p>
<h3 id="Kafka-Topic-amp-Partition"><a href="#Kafka-Topic-amp-Partition" class="headerlink" title="Kafka Topic &amp; Partition"></a>Kafka Topic &amp; Partition</h3><p>消息发送时都被发送到一个topic，其本质就是一个目录，而topic由是由一些Partition Logs(分区日志)组成,其组织结构如下图所示：<br><img src="/img/15255328151290.jpg" alt></p>
<p>我们可以看到，每个Partition中的消息都是有序的，生产的消息被不断追加到Partition log上，其中的每一个消息都被赋予了一个唯一的offset值。<br>Kafka集群会保存所有的消息，不管消息有没有被消费；我们可以设定消息的过期时间，只有过期的数据才会被自动清除以释放磁盘空间。比如我们设置消息过期时间为2天，那么这2天内的所有消息都会被保存到集群中，数据只有超过了两天才会被清除。<br>Kafka需要维持的元数据只有一个–消费消息在Partition中的offset值，Consumer每消费一个消息，offset就会加1。其实消息的状态完全是由Consumer控制的，Consumer可以跟踪和重设这个offset值，这样的话Consumer就可以读取任意位置的消息。<br>把消息日志以Partition的形式存放有多重考虑，第一，方便在集群中扩展，每个Partition可以通过调整以适应它所在的机器，而一个topic又可以有多个Partition组成，因此整个集群就可以适应任意大小的数据了；第二就是可以提高并发，因为可以以Partition为单位读写了。</p>
<h2 id="Kafka-核心组件"><a href="#Kafka-核心组件" class="headerlink" title="Kafka 核心组件"></a>Kafka 核心组件</h2><h3 id="Replications、Partitions-和Leaders"><a href="#Replications、Partitions-和Leaders" class="headerlink" title="Replications、Partitions 和Leaders"></a>Replications、Partitions 和Leaders</h3><p>通过上面介绍的我们可以知道，kafka中的数据是持久化的并且能够容错的。Kafka允许用户为每个topic设置副本数量，副本数量决定了有几个broker来存放写入的数据。如果你的副本数量设置为3，那么一份数据就会被存放在3台不同的机器上，那么就允许有2个机器失败。一般推荐副本数量至少为2，这样就可以保证增减、重启机器时不会影响到数据消费。如果对数据持久化有更高的要求，可以把副本数量设置为3或者更多。<br>Kafka中的topic是以partition的形式存放的，每一个topic都可以设置它的partition数量，Partition的数量决定了组成topic的log的数量。Producer在生产数据时，会按照一定规则（这个规则是可以自定义的）把消息发布到topic的各个partition中。上面将的副本都是以partition为单位的，不过只有一个partition的副本会被选举成leader作为读写用。<br>关于如何设置partition值需要考虑的因素。一个partition只能被一个消费者消费（一个消费者可以同时消费多个partition），因此，如果设置的partition的数量小于consumer的数量，就会有消费者消费不到数据。所以，推荐partition的数量一定要大于同时运行的consumer的数量。另外一方面，建议partition的数量大于集群broker的数量，这样leader partition就可以均匀的分布在各个broker中，最终使得集群负载均衡。在Cloudera,每个topic都有上百个partition。需要注意的是，kafka需要为每个partition分配一些内存来缓存消息数据，如果partition数量越大，就要为kafka分配更大的heap space。</p>
<h3 id="Producers"><a href="#Producers" class="headerlink" title="Producers"></a>Producers</h3><p>Producers直接发送消息到broker上的leader partition，不需要经过任何中介一系列的路由转发。为了实现这个特性，kafka集群中的每个broker都可以响应producer的请求，并返回topic的一些元信息，这些元信息包括哪些机器是存活的，topic的leader partition都在哪，现阶段哪些leader partition是可以直接被访问的。<br>Producer客户端自己控制着消息被推送到哪些partition。实现的方式可以是随机分配、实现一类随机负载均衡算法，或者指定一些分区算法。Kafka提供了接口供用户实现自定义的分区，用户可以为每个消息指定一个partitionKey，通过这个key来实现一些hash分区算法。比如，把userid作为partitionkey的话，相同userid的消息将会被推送到同一个分区。<br>以Batch的方式推送数据可以极大的提高处理效率，kafka Producer 可以将消息在内存中累计到一定数量后作为一个batch发送请求。Batch的数量大小可以通过Producer的参数控制，参数值可以设置为累计的消息的数量（如500条）、累计的时间间隔（如100ms）或者累计的数据大小(64KB)。通过增加batch的大小，可以减少网络请求和磁盘IO的次数，当然具体参数设置需要在效率和时效性方面做一个权衡。<br>Producers可以异步的并行的向kafka发送消息，但是通常producer在发送完消息之后会得到一个future响应，返回的是offset值或者发送过程中遇到的错误。这其中有个非常重要的参数“acks”,这个参数决定了producer要求leader partition 收到确认的副本个数，如果acks设置数量为0，表示producer不会等待broker的响应，所以，producer无法知道消息是否发送成功，这样有可能会导致数据丢失，但同时，acks值为0会得到最大的系统吞吐量。<br>若acks设置为1，表示producer会在leader partition收到消息时得到broker的一个确认，这样会有更好的可靠性，因为客户端会等待直到broker确认收到消息。若设置为-1，producer会在所有备份的partition收到消息时得到broker的确认，这个设置可以得到最高的可靠性保证。<br>Kafka 消息有一个定长的header和变长的字节数组组成。因为kafka消息支持字节数组，也就使得kafka可以支持任何用户自定义的序列号格式或者其它已有的格式如Apache Avro、protobuf等。Kafka没有限定单个消息的大小，但我们推荐消息大小不要超过1MB,通常一般消息大小都在1~10kB之前。</p>
<h3 id="Consumers"><a href="#Consumers" class="headerlink" title="Consumers"></a>Consumers</h3><p>Kafka提供了两套consumer api，分为high-level api和sample-api。Sample-api 是一个底层的API，它维持了一个和单一broker的连接，并且这个API是完全无状态的，每次请求都需要指定offset值，因此，这套API也是最灵活的。<br>在kafka中，当前读到消息的offset值是由consumer来维护的，因此，consumer可以自己决定如何读取kafka中的数据。比如，consumer可以通过重设offset值来重新消费已消费过的数据。不管有没有被消费，kafka会保存数据一段时间，这个时间周期是可配置的，只有到了过期时间，kafka才会删除这些数据。<br>High-level API封装了对集群中一系列broker的访问，可以透明的消费一个topic。它自己维持了已消费消息的状态，即每次消费的都是下一个消息。<br>High-level API还支持以组的形式消费topic，如果consumers有同一个组名，那么kafka就相当于一个队列消息服务，而各个consumer均衡的消费相应partition中的数据。若consumers有不同的组名，那么此时kafka就相当与一个广播服务，会把topic中的所有消息广播到每个consumer。<br><img src="/img/15255329976928.jpg" alt></p>
<h2 id="Kafka核心特性"><a href="#Kafka核心特性" class="headerlink" title="Kafka核心特性"></a>Kafka核心特性</h2><h3 id="压缩"><a href="#压缩" class="headerlink" title="压缩"></a>压缩</h3><p>我们上面已经知道了Kafka支持以集合（batch）为单位发送消息，在此基础上，Kafka还支持对消息集合进行压缩，Producer端可以通过GZIP或Snappy格式对消息集合进行压缩。Producer端进行压缩之后，在Consumer端需进行解压。压缩的好处就是减少传输的数据量，减轻对网络传输的压力，在对大数据处理上，瓶颈往往体现在网络上而不是CPU（压缩和解压会耗掉部分CPU资源）。<br>那么如何区分消息是压缩的还是未压缩的呢，Kafka在消息头部添加了一个描述压缩属性字节，这个字节的后两位表示消息的压缩采用的编码，如果后两位为0，则表示消息未被压缩。</p>
<h3 id="消息可靠性"><a href="#消息可靠性" class="headerlink" title="消息可靠性"></a>消息可靠性</h3><p>在消息系统中，保证消息在生产和消费过程中的可靠性是十分重要的，在实际消息传递过程中，可能会出现如下三中情况：</p>
<ul>
<li>一个消息发送失败</li>
<li>一个消息被发送多次</li>
<li>最理想的情况：exactly-once ,一个消息发送成功且仅发送了一次</li>
</ul>
<p>有许多系统声称它们实现了exactly-once，但是它们其实忽略了生产者或消费者在生产和消费过程中有可能失败的情况。比如虽然一个Producer成功发送一个消息，但是消息在发送途中丢失，或者成功发送到broker，也被consumer成功取走，但是这个consumer在处理取过来的消息时失败了。<br>从Producer端看：Kafka是这么处理的，当一个消息被发送后，Producer会等待broker成功接收到消息的反馈（可通过参数控制等待时间），如果消息在途中丢失或是其中一个broker挂掉，Producer会重新发送（我们知道Kafka有备份机制，可以通过参数控制是否等待所有备份节点都收到消息）。<br>从Consumer端看：前面讲到过partition，broker端记录了partition中的一个offset值，这个值指向Consumer下一个即将消费message。当Consumer收到了消息，但却在处理过程中挂掉，此时Consumer可以通过这个offset值重新找到上一个消息再进行处理。Consumer还有权限控制这个offset值，对持久化到broker端的消息做任意处理。</p>
<h3 id="备份机制"><a href="#备份机制" class="headerlink" title="备份机制"></a>备份机制</h3><p>备份机制是Kafka0.8版本的新特性，备份机制的出现大大提高了Kafka集群的可靠性、稳定性。有了备份机制后，Kafka允许集群中的节点挂掉后而不影响整个集群工作。一个备份数量为n的集群允许n-1个节点失败。在所有备份节点中，有一个节点作为lead节点，这个节点保存了其它备份节点列表，并维持各个备份间的状体同步。下面这幅图解释了Kafka的备份机制:<br><img src="/img/15255330211208.jpg" alt></p>
<h3 id="Kafka高效性相关设计"><a href="#Kafka高效性相关设计" class="headerlink" title="Kafka高效性相关设计"></a>Kafka高效性相关设计</h3><h4 id="消息的持久化"><a href="#消息的持久化" class="headerlink" title="消息的持久化"></a>消息的持久化</h4><p>Kafka高度依赖文件系统来存储和缓存消息，一般的人认为磁盘是缓慢的，这导致人们对持久化结构具有竞争性持怀疑态度。其实，磁盘远比你想象的要快或者慢，这决定于我们如何使用磁盘。<br>一个和磁盘性能有关的关键事实是：磁盘驱动器的吞吐量跟寻到延迟是相背离的，也就是所，线性写的速度远远大于随机写。比如：在一个6 7200rpm SATA RAID-5 的磁盘阵列上线性写的速度大概是600M/秒，但是随机写的速度只有100K/秒，两者相差将近6000倍。线性读写在大多数应用场景下是可以预测的，因此，操作系统利用read-ahead和write-behind技术来从大的数据块中预取数据，或者将多个逻辑上的写操作组合成一个大写物理写操作中。更多的讨论可以在<a href="http://queue.acm.org/detail.cfm?id=1563874" target="_blank" rel="noopener">ACMQueueArtical</a>中找到，他们发现，对磁盘的线性读在有些情况下可以比内存的随机访问要快一些。<br>为了补偿这个性能上的分歧，现代操作系统都会把空闲的内存用作磁盘缓存，尽管在内存回收的时候会有一点性能上的代价。所有的磁盘读写操作会在这个统一的缓存上进行。<br>此外，如果我们是在JVM的基础上构建的，熟悉Java内存应用管理的人应该清楚以下两件事情：</p>
<ol>
<li>一个对象的内存消耗是非常高的，经常是所存数据的两倍或者更多。</li>
<li>随着堆内数据的增多，Java的垃圾回收会变得非常昂贵。</li>
</ol>
<p>基于这些事实，利用文件系统并且依靠页缓存比维护一个内存缓存或者其他结构要好——我们至少要使得可用的缓存加倍，通过自动访问可用内存，并且通过存储更紧凑的字节结构而不是一个对象，这将有可能再次加倍。这么做的结果就是在一台32GB的机器上，如果不考虑GC惩罚，将最多有28-30GB的缓存。此外，这些缓存将会一直存在即使服务重启，然而进程内缓存需要在内存中重构（10GB缓存需要花费10分钟）或者它需要一个完全冷缓存启动（非常差的初始化性能）。它同时也简化了代码，因为现在所有的维护缓存和文件系统之间内聚的逻辑都在操作系统内部了，这使得这样做比one-off in-process attempts更加高效与准确。如果你的磁盘应用更加倾向于顺序读取，那么read-ahead在每次磁盘读取中实际上获取到这人缓存中的有用数据。<br>以上这些建议了一个简单的设计：不同于维护尽可能多的内存缓存并且在需要的时候刷新到文件系统中，我们换一种思路。所有的数据不需要调用刷新程序，而是立刻将它写到一个持久化的日志中。事实上，这仅仅意味着，数据将被传输到内核页缓存中并稍后被刷新。我们可以增加一个配置项以让系统的用户来控制数据在什么时候被刷新到物理硬盘上。</p>
<h4 id="常数时间性能保证"><a href="#常数时间性能保证" class="headerlink" title="常数时间性能保证"></a>常数时间性能保证</h4><p>消息系统中持久化数据结构的设计通常是维护着一个和消费队列有关的B树或者其它能够随机存取结构的元数据信息。B树是一个很好的结构，可以用在事务型与非事务型的语义中。但是它需要一个很高的花费，尽管B树的操作需要O(logN)。通常情况下，这被认为与常数时间等价，但这对磁盘操作来说是不对的。磁盘寻道一次需要10ms，并且一次只能寻一个，因此并行化是受限的。<br>直觉上来讲，一个持久化的队列可以构建在对一个文件的读和追加上，就像一般情况下的日志解决方案。尽管和B树相比，这种结构不能支持丰富的语义，但是它有一个优点，所有的操作都是常数时间，并且读写之间不会相互阻塞。这种设计具有极大的性能优势：最终系统性能和数据大小完全无关，服务器可以充分利用廉价的硬盘来提供高效的消息服务。<br>事实上还有一点，磁盘空间的无限增大而不影响性能这点，意味着我们可以提供一般消息系统无法提供的特性。比如说，消息被消费后不是立马被删除，我们可以将这些消息保留一段相对比较长的时间（比如一个星期）。</p>
<h4 id="进一步提高效率"><a href="#进一步提高效率" class="headerlink" title="进一步提高效率"></a>进一步提高效率</h4><p>我们已经为效率做了非常多的努力。但是有一种非常主要的应用场景是：处理Web活动数据，它的特点是数据量非常大，每一次的网页浏览都会产生大量的写操作。更进一步，我们假设每一个被发布的消息都会被至少一个consumer消费，因此我们更要怒路让消费变得更廉价。<br>通过上面的介绍，我们已经解决了磁盘方面的效率问题，除此之外，在此类系统中还有两类比较低效的场景：</p>
<ul>
<li>太多小的I/O操作</li>
<li>过多的字节拷贝</li>
</ul>
<p>为了减少大量小I/O操作的问题，kafka的协议是围绕消息集合构建的。Producer一次网络请求可以发送一个消息集合，而不是每一次只发一条消息。在server端是以消息块的形式追加消息到log中的，consumer在查询的时候也是一次查询大量的线性数据块。消息集合即MessageSet，实现本身是一个非常简单的API，它将一个字节数组或者文件进行打包。所以对消息的处理，这里没有分开的序列化和反序列化的上步骤，消息的字段可以按需反序列化（如果没有需要，可以不用反序列化）。<br>另一个影响效率的问题就是字节拷贝。为了解决字节拷贝的问题，kafka设计了一种“标准字节消息”，Producer、Broker、Consumer共享这一种消息格式。Kakfa的message log在broker端就是一些目录文件，这些日志文件都是MessageSet按照这种“标准字节消息”格式写入到磁盘的。<br>维持这种通用的格式对这些操作的优化尤为重要：持久化log 块的网络传输。流行的unix操作系统提供了一种非常高效的途径来实现页面缓存和socket之间的数据传递。在Linux操作系统中，这种方式被称作：sendfile system call（Java提供了访问这个系统调用的方法：FileChannel.transferTo api）。</p>
<p>为了理解sendfile的影响，需要理解一般的将数据从文件传到socket的路径：</p>
<ol>
<li>操作系统将数据从磁盘读到内核空间的页缓存中</li>
<li>应用将数据从内核空间读到用户空间的缓存中</li>
<li>应用将数据写回内核空间的socket缓存中</li>
<li>操作系统将数据从socket缓存写到网卡缓存中，以便将数据经网络发出</li>
</ol>
<p>这种操作方式明显是非常低效的，这里有四次拷贝，两次系统调用。如果使用sendfile，就可以避免两次拷贝：操作系统将数据直接从页缓存发送到网络上。所以在这个优化的路径中，只有最后一步将数据拷贝到网卡缓存中是需要的。<br>我们期望一个主题上有多个消费者是一种常见的应用场景。利用上述的zero-copy，数据只被拷贝到页缓存一次，然后就可以在每次消费时被重得利用，而不需要将数据存在内存中，然后在每次读的时候拷贝到内核空间中。这使得消息消费速度可以达到网络连接的速度。这样以来，通过页面缓存和sendfile的结合使用，整个kafka集群几乎都已以缓存的方式提供服务，而且即使下游的consumer很多，也不会对整个集群服务造成压力。<br>关于sendfile和zero-copy，请参考：<a href="https://www.ibm.com/developerworks/linux/library/j-zerocopy/" target="_blank" rel="noopener">zero-copy</a></p>
<h2 id="推荐阅读"><a href="#推荐阅读" class="headerlink" title="推荐阅读"></a>推荐阅读</h2><ol>
<li><a href="https://blog.csdn.net/lizhitao/article/details/39499283" target="_blank" rel="noopener">https://blog.csdn.net/lizhitao/article/details/39499283</a></li>
</ol>
]]></content>
      <categories>
        <category>技术</category>
        <category>消息队列</category>
        <category>Kafka</category>
      </categories>
      <tags>
        <tag>Kafka</tag>
      </tags>
  </entry>
  <entry>
    <title>ElasticSearch</title>
    <url>/2017/05/06/ElasticSearch/</url>
    <content><![CDATA[]]></content>
      <categories>
        <category>技术</category>
        <category>搜索</category>
      </categories>
      <tags>
        <tag>ElasticSearch</tag>
      </tags>
  </entry>
  <entry>
    <title>Disruptor</title>
    <url>/2017/05/06/Disruptor/</url>
    <content><![CDATA[]]></content>
      <categories>
        <category>技术</category>
        <category>JAVA</category>
      </categories>
      <tags>
        <tag>JAVA</tag>
        <tag>Disruptor</tag>
      </tags>
  </entry>
  <entry>
    <title>SimHash</title>
    <url>/2017/05/06/SimHash/</url>
    <content><![CDATA[<p>本篇主要是对网上资源的整理，缺乏原创。</p>
<h2 id="什么是SimHash"><a href="#什么是SimHash" class="headerlink" title="什么是SimHash"></a>什么是SimHash</h2><p>SimHash是一种局部敏感hash(即Locality Sensitive Hashing，感兴趣可以自行学习下)，是google用来处理海量文本去重的算法。</p>
<h2 id="与普通Hash区别"><a href="#与普通Hash区别" class="headerlink" title="与普通Hash区别"></a>与普通Hash区别</h2><p>传统的加密式hash，比如md5，其设计的目的是为了让整个分布尽可能地均匀，输入内容哪怕只有轻微变化，hash就会发生很大地变化。<br>我们理想当中的哈希函数，需要对几乎相同的输入内容，产生相同或者相近的hashcode，换句话说，hashcode的相似程度要能直接反映输入内容的相似程度。很明显，前面所说的md5等传统hash无法满足我们的需求。  </p>
<a id="more"></a>
<p>假设有以下三段文本：</p>
<ul>
<li>the cat sat on the mat</li>
<li>the cat sat on a mat</li>
<li>we all scream for ice cream</li>
</ul>
<p>使用传统hash可能会产生如下的结果： </p>
<ol>
<li>the cat sat on the mat -&gt; 415542861</li>
<li>the cat sat on a mat -&gt; 668720516</li>
<li>we all scream for ice cream -&gt; 767429688</li>
</ol>
<p>使用simhash会应该产生类似如下的结果： </p>
<ol>
<li>the cat sat on the mat -&gt; 851459198 -&gt; 00110010110000000011110001111110 </li>
<li>the cat sat on a mat -&gt; 847263864 -&gt; 00110010100000000011100001111000 </li>
<li>we all scream for ice crea -&gt; 984968088 -&gt; 00111010101101010110101110011000</li>
</ol>
<p>可以看到SimHash比传统hash算出来更接近些。 </p>
<h2 id="算法原理"><a href="#算法原理" class="headerlink" title="算法原理"></a>算法原理</h2><p>simHash值生成过程：<br><img src="/img/15270623656302.jpg" alt><br>算法过程大概如下：</p>
<ol>
<li>分词，把需要判断文本分词形成这个文章的特征单词。最后形成去掉噪音词的单词序列并为每个词加上权重，我们假设权重分为5个级别（1~5）。比如：“ 美国“51区”雇员称内部有9架飞碟，曾看见灰色外星人 ” ==&gt; 分词后为 “ 美国（4） 51区（5） 雇员（3） 称（1） 内部（2） 有（1） 9架（3） 飞碟（5） 曾（1） 看见（3） 灰色（4） 外星人（5）”，括号里是代表单词在整个句子里重要程度，数字越大越重要。</li>
<li>hash，通过hash算法把每个词变成hash值，比如“美国”通过hash算法计算为 100101,“51区”通过hash算法计算为 101011。这样我们的字符串就变成了一串串数字，还记得文章开头说过的吗，要把文章变为数字计算才能提高相似度计算性能，现在是降维过程进行时。</li>
<li>加权，通过 2步骤的hash生成结果，需要按照单词的权重形成加权数字串，比如“美国”的hash值为“100101”，通过加权计算为“4 -4 -4 4 -4 4”；“51区”的hash值为“101011”，通过加权计算为 “ 5 -5 5 -5 5 5”。</li>
<li>合并，把上面各个单词算出来的序列值累加，变成只有一个序列串。比如 “美国”的 “4 -4 -4 4 -4 4”，“51区”的 “ 5 -5 5 -5 5 5”， 把每一位进行累加， “4+5 -4+-5 -4+5 4+-5 -4+5 4+5” ==》 “9 -9 1 -1 1 9”。这里作为示例只算了两个单词的，真实计算需要把所有单词的序列串累加。</li>
<li>降维，把4步算出来的 “9 -9 1 -1 1 9” 变成 0 1 串，形成我们最终的simhash签名。 如果每一位大于0 记为 1，小于0 记为 0。最后算出结果为：“1 0 1 0 1 1”。</li>
</ol>
<p>整个过程的流程图为：<br><img src="/img/15270624852812.jpg" alt></p>
<p>到此，如何从一个doc到一个simhash值的过程已经讲明白了。 但是还有一个重要的部分没讲：海明距离计算。</p>
<h2 id="simhash值的海明距离计算"><a href="#simhash值的海明距离计算" class="headerlink" title="simhash值的海明距离计算"></a>simhash值的海明距离计算</h2><p>二进制串A 和 二进制串B 的海明距离 就是 A xor B 后二进制中1的个数。</p>
<p>如：<br><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">A = 100111;</span><br><span class="line">B = 101010;</span><br><span class="line">hamming_distance(A, B) = count_1(A xor B) = count_1(001101) = 3;</span><br></pre></td></tr></table></figure></p>
<p>当我们算出所有doc的simhash值之后，需要计算doc A和doc B之间是否相似的条件是：<br>A和B的海明距离是否小于等于n，这个n值根据经验一般取值为3。</p>
<h2 id="海量数据计算海明距离"><a href="#海量数据计算海明距离" class="headerlink" title="海量数据计算海明距离"></a>海量数据计算海明距离</h2><p>计算文本相似度问题就转变为-&gt; 有10亿个不重复的64位的01字符串，任意给出一个64位的01字符串f，如何快速从中找出与f汉明距离小于3的字符串？</p>
<p>方法1：前0位上精确匹配，那就要在后面，也就是比较所有<br>方法2：前61位上精确匹配，后面就不需要比较了</p>
<p>那么折中的想法是 前d bits相同，留下3 bit在(64-d)bit小范围搜索，可行否?</p>
<p><strong>d bits的表示范围有2^d，总量N个指纹，平均每个范围只有N/(2^d)个指纹。<br>快速定位到前缀是d的位置以后，直接比较范围内N/(2^d)个指纹即可。</strong></p>
<p>假设我们要寻找海明距离3以内的数值，根据鸽巢原理，只要我们将整个64位的二进制串划分为4块，无论如何，匹配的两个simhash code之间至少有一块区域是完全相同的，如下图所示：<br><img src="/img/15270632191445.jpg" alt></p>
<p>由于我们无法事先得知完全相同的是哪一块区域，因此我们必须采用存储多份table的方式。在本例的情况下，我们需要存储4份table，并将64位的simhash code等分成4份；对于每一个输入的code，我们通过精确匹配的方式，查找前16位相同的记录作为候选记录，如下图所示： </p>
<p><img src="/img/15270632542779.jpg" alt></p>
<p>算法过程为：</p>
<ol>
<li>将64位的二进制串等分成四块 </li>
<li>调整上述64位二进制，将任意一块作为前16位，总共有四种组合，即每个指纹生成4个指纹。 </li>
<li>采用精确匹配的方式查找前16位 </li>
<li>如果样本库中存有2^30（差不多10亿）的哈希指纹，每个指纹存四份即 2^30 * 2^2 = 2^32个哈希指纹。共有2^16种类型，每种类型有 2^32 / 2^16 = 65536 个候选结果，大大减少了海明距离的计算成本。</li>
</ol>
<h2 id="与其他算法对比"><a href="#与其他算法对比" class="headerlink" title="与其他算法对比"></a>与其他算法对比</h2><ol>
<li>百度的去重算法<br>百度的去重算法最简单，就是直接找出此文章的最长的n句话，做一遍hash签名。n一般取3。 工程实现巨简单，据说准确率和召回率都能到达80%以上。</li>
<li>shingle算法<br>shingle原理略复杂，对于工程实现不够友好，速度太慢，基本上无法处理海量数据。</li>
</ol>
<h2 id="参考文档"><a href="#参考文档" class="headerlink" title="参考文档"></a>参考文档</h2><ol>
<li><a href="https://blog.csdn.net/lgnlgn/article/details/6008498" target="_blank" rel="noopener">https://blog.csdn.net/lgnlgn/article/details/6008498</a></li>
<li><a href="http://www.cnblogs.com/maybe2030/p/5203186.html" target="_blank" rel="noopener">http://www.cnblogs.com/maybe2030/p/5203186.html</a></li>
<li><a href="https://yanyiwu.com/work/2014/01/30/simhash-shi-xian-xiang-jie.html" target="_blank" rel="noopener">https://yanyiwu.com/work/2014/01/30/simhash-shi-xian-xiang-jie.html</a></li>
<li><a href="http://grunt1223.iteye.com/blog/964564" target="_blank" rel="noopener">http://grunt1223.iteye.com/blog/964564</a></li>
</ol>
]]></content>
      <categories>
        <category>算法</category>
      </categories>
      <tags>
        <tag>算法</tag>
        <tag>SimHash</tag>
      </tags>
  </entry>
  <entry>
    <title>Double-Array Trie</title>
    <url>/2017/05/06/Double-Array-Trie/</url>
    <content><![CDATA[]]></content>
      <categories>
        <category>算法</category>
      </categories>
      <tags>
        <tag>Double-Array Trie</tag>
        <tag>算法</tag>
      </tags>
  </entry>
  <entry>
    <title>ZooKeeper watch机制</title>
    <url>/2017/04/24/zookeeper%E4%B9%8B%E7%9B%91%E5%90%AC%E4%BA%8B%E4%BB%B6/</url>
    <content><![CDATA[<h2 id="zookeeper-watch机制"><a href="#zookeeper-watch机制" class="headerlink" title="zookeeper watch机制"></a>zookeeper watch机制</h2><p>一个zk的节点可以被监控，包括这个目录中存储的数据的修改，子节点目录的变化，一旦变化可以通知设置监控的客户端，这个功能是zookeeper对于应用最重要的特性，通过这个特性可以实现的功能包括配置的集中管理，集群管理，分布式锁等等。<br><a id="more"></a></p>
<p><strong>getData(), getChildren(), and exists()</strong>可以设置对某个节点进行监听。<br><strong> New ZooKeeper时注册的watcher叫default watcher，它不是一次性的，只对client的连接状态变化作出反应。</strong></p>
<h2 id="zookeeper-watch机制特点"><a href="#zookeeper-watch机制特点" class="headerlink" title="zookeeper watch机制特点"></a>zookeeper watch机制特点</h2><h3 id="One-time-trigger"><a href="#One-time-trigger" class="headerlink" title="One-time trigger"></a>One-time trigger</h3><p>当数据改变的时候，那么一个Watch事件会产生并且被发送到客户端中。但是客户端只会收到一次这样的通知，如果以后这个数据再次发生改变的时候，之前设置Watch的客户端将不会再次收到改变的通知，因为Watch机制规定了它是一个一次性的触发器。           </p>
<p>当设置监视的数据发生改变时，该监视事件会被发送到客户端，例如，如果客户端调用了 getData(“/znode1”, true) 并且稍后 /znode1 节点上的数据发生了改变或者被删除了，客户端将会获取到 /znode1 发生变化的监视事件，而如果 /znode1 再一次发生了变化，除非客户端再次对 /znode1 设置监视，否则客户端不会收到事件通知。</p>
<figure class="highlight java"><table><tr><td class="code"><pre><span class="line"><span class="keyword">package</span> com.ytf.zk.nameservice;</span><br><span class="line"></span><br><span class="line"><span class="keyword">import</span> com.ytf.zk.constant.ClientBase;</span><br><span class="line"><span class="keyword">import</span> org.apache.zookeeper.CreateMode;</span><br><span class="line"><span class="keyword">import</span> org.apache.zookeeper.KeeperException;</span><br><span class="line"><span class="keyword">import</span> org.apache.zookeeper.ZooDefs;</span><br><span class="line"><span class="keyword">import</span> org.apache.zookeeper.ZooKeeper;</span><br><span class="line"></span><br><span class="line"><span class="keyword">import</span> java.io.IOException;</span><br><span class="line"></span><br><span class="line"><span class="comment">/**</span></span><br><span class="line"><span class="comment"> * Created by</span></span><br><span class="line"><span class="comment"> * DATE: 17/4/23星期日.</span></span><br><span class="line"><span class="comment"> */</span></span><br><span class="line"><span class="keyword">public</span> <span class="class"><span class="keyword">class</span> <span class="title">Naming</span> </span>&#123;</span><br><span class="line">    <span class="keyword">private</span> <span class="keyword">static</span> <span class="keyword">final</span> <span class="keyword">int</span> CLIENT_PORT = <span class="number">2181</span>;</span><br><span class="line">    <span class="keyword">private</span> <span class="keyword">static</span> <span class="keyword">final</span> String ROOT_PATH = <span class="string">"/root"</span>;</span><br><span class="line">    <span class="keyword">private</span> <span class="keyword">static</span> <span class="keyword">final</span> String CHILD_PATH = <span class="string">"/root/childPath"</span>;</span><br><span class="line">    <span class="keyword">private</span> <span class="keyword">static</span> <span class="keyword">final</span> String CHILD_PATH_2 = <span class="string">"/root/childPath2"</span>;</span><br><span class="line">    <span class="keyword">static</span> ZooKeeper zk = <span class="keyword">null</span>;</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">public</span> <span class="keyword">static</span> <span class="keyword">void</span> <span class="title">main</span><span class="params">(String[] args)</span> <span class="keyword">throws</span> Exception </span>&#123;</span><br><span class="line">        <span class="keyword">try</span> &#123;</span><br><span class="line">            zk = <span class="keyword">new</span> ZooKeeper(<span class="string">"localhost:"</span> + CLIENT_PORT, ClientBase.CONNECTION_TIMEOUT, (watchedEvent) -&gt; &#123;</span><br><span class="line">                System.out.println(watchedEvent.getPath() + <span class="string">"触发了"</span> + watchedEvent.getType() + <span class="string">"事件!"</span> + <span class="string">"data:"</span> + Naming.getData(watchedEvent.getPath()));</span><br><span class="line">            &#125;</span><br><span class="line">            );</span><br><span class="line"></span><br><span class="line">            <span class="comment">// 创建根目录</span></span><br><span class="line">            zk.create(ROOT_PATH, ROOT_PATH.getBytes(), ZooDefs.Ids.OPEN_ACL_UNSAFE, CreateMode.PERSISTENT);</span><br><span class="line">            System.out.println(zk.getChildren(ROOT_PATH, <span class="keyword">true</span>));</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">            <span class="comment">// 创建子目录</span></span><br><span class="line">            zk.create(CHILD_PATH, <span class="string">"childPath"</span>.getBytes(), ZooDefs.Ids.OPEN_ACL_UNSAFE, CreateMode.PERSISTENT);</span><br><span class="line">            <span class="comment">// 取出子目录数据</span></span><br><span class="line">            System.out.println(CHILD_PATH + <span class="string">"数据: "</span> + <span class="keyword">new</span> String(zk.getData(CHILD_PATH, <span class="keyword">true</span>, <span class="keyword">null</span>)));</span><br><span class="line"></span><br><span class="line">            <span class="comment">// 修改子目录节点数据</span></span><br><span class="line">            zk.setData(CHILD_PATH, <span class="string">"modification"</span>.getBytes(), -<span class="number">1</span>);</span><br><span class="line">            System.out.println(<span class="keyword">new</span> String(zk.getData(CHILD_PATH, <span class="keyword">true</span>, <span class="keyword">null</span>)));</span><br><span class="line"></span><br><span class="line">            zk.setData(CHILD_PATH, <span class="string">"modification2"</span>.getBytes(), -<span class="number">1</span>);</span><br><span class="line"></span><br><span class="line">            zk.delete(CHILD_PATH, -<span class="number">1</span>);</span><br><span class="line">            <span class="comment">// 删除父目录节点</span></span><br><span class="line">            zk.delete(ROOT_PATH, -<span class="number">1</span>);</span><br><span class="line">            <span class="comment">// 关闭连接</span></span><br><span class="line">            zk.close();</span><br><span class="line">        &#125; <span class="keyword">catch</span> (KeeperException e) &#123;</span><br><span class="line">            e.printStackTrace();</span><br><span class="line">        &#125; <span class="keyword">catch</span> (InterruptedException e) &#123;</span><br><span class="line">            e.printStackTrace();</span><br><span class="line">        &#125; <span class="keyword">catch</span> (IOException e) &#123;</span><br><span class="line">            e.printStackTrace();</span><br><span class="line">        &#125;</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">public</span> <span class="keyword">static</span> String <span class="title">getData</span><span class="params">(String path)</span> </span>&#123;</span><br><span class="line">        <span class="keyword">if</span> (path == <span class="keyword">null</span>) &#123;</span><br><span class="line">            <span class="keyword">return</span> <span class="keyword">null</span>;</span><br><span class="line">        &#125;</span><br><span class="line">        <span class="keyword">try</span> &#123;</span><br><span class="line">            <span class="keyword">return</span> <span class="keyword">new</span> String(zk.getData(path, <span class="keyword">false</span>, <span class="keyword">null</span>));</span><br><span class="line">        &#125; <span class="keyword">catch</span> (KeeperException e) &#123;</span><br><span class="line">            e.printStackTrace();</span><br><span class="line">        &#125; <span class="keyword">catch</span> (InterruptedException e) &#123;</span><br><span class="line">            e.printStackTrace();</span><br><span class="line">        &#125;</span><br><span class="line">        <span class="keyword">return</span> <span class="keyword">null</span>;</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<p>输出:</p>
<blockquote>
<p>null触发了None事件!data:null<br>[]<br>/root/childPath数据: childPath<br>/root触发了NodeChildrenChanged事件!data:/root<br>/root/childPath触发了NodeDataChanged事件!data:modification<br>modification<br>/root/childPath触发了NodeDataChanged事件!data:modification2</p>
</blockquote>
<p>注意将第41行的参数true改为false后的执行结果：<br><figure class="highlight java"><table><tr><td class="code"><pre><span class="line"><span class="keyword">package</span> com.ytf.zk.nameservice;</span><br><span class="line"></span><br><span class="line"><span class="keyword">import</span> com.ytf.zk.constant.ClientBase;</span><br><span class="line"><span class="keyword">import</span> org.apache.zookeeper.CreateMode;</span><br><span class="line"><span class="keyword">import</span> org.apache.zookeeper.KeeperException;</span><br><span class="line"><span class="keyword">import</span> org.apache.zookeeper.ZooDefs;</span><br><span class="line"><span class="keyword">import</span> org.apache.zookeeper.ZooKeeper;</span><br><span class="line"></span><br><span class="line"><span class="keyword">import</span> java.io.IOException;</span><br><span class="line"></span><br><span class="line"><span class="comment">/**</span></span><br><span class="line"><span class="comment"> * Created by</span></span><br><span class="line"><span class="comment"> * DATE: 17/4/23星期日.</span></span><br><span class="line"><span class="comment"> */</span></span><br><span class="line"><span class="keyword">public</span> <span class="class"><span class="keyword">class</span> <span class="title">Naming</span> </span>&#123;</span><br><span class="line">    <span class="keyword">private</span> <span class="keyword">static</span> <span class="keyword">final</span> <span class="keyword">int</span> CLIENT_PORT = <span class="number">2181</span>;</span><br><span class="line">    <span class="keyword">private</span> <span class="keyword">static</span> <span class="keyword">final</span> String ROOT_PATH = <span class="string">"/root"</span>;</span><br><span class="line">    <span class="keyword">private</span> <span class="keyword">static</span> <span class="keyword">final</span> String CHILD_PATH = <span class="string">"/root/childPath"</span>;</span><br><span class="line">    <span class="keyword">private</span> <span class="keyword">static</span> <span class="keyword">final</span> String CHILD_PATH_2 = <span class="string">"/root/childPath2"</span>;</span><br><span class="line">    <span class="keyword">static</span> ZooKeeper zk = <span class="keyword">null</span>;</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">public</span> <span class="keyword">static</span> <span class="keyword">void</span> <span class="title">main</span><span class="params">(String[] args)</span> <span class="keyword">throws</span> Exception </span>&#123;</span><br><span class="line">        <span class="keyword">try</span> &#123;</span><br><span class="line">            zk = <span class="keyword">new</span> ZooKeeper(<span class="string">"localhost:"</span> + CLIENT_PORT, ClientBase.CONNECTION_TIMEOUT, (watchedEvent) -&gt; &#123;</span><br><span class="line">                System.out.println(watchedEvent.getPath() + <span class="string">"触发了"</span> + watchedEvent.getType() + <span class="string">"事件!"</span> + <span class="string">"data:"</span> + Naming.getData(watchedEvent.getPath()));</span><br><span class="line">            &#125;</span><br><span class="line">            );</span><br><span class="line"></span><br><span class="line">            <span class="comment">// 创建根目录</span></span><br><span class="line">            zk.create(ROOT_PATH, ROOT_PATH.getBytes(), ZooDefs.Ids.OPEN_ACL_UNSAFE, CreateMode.PERSISTENT);</span><br><span class="line">            System.out.println(zk.getChildren(ROOT_PATH, <span class="keyword">true</span>));</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">            <span class="comment">// 创建子目录</span></span><br><span class="line">            zk.create(CHILD_PATH, <span class="string">"childPath"</span>.getBytes(), ZooDefs.Ids.OPEN_ACL_UNSAFE, CreateMode.PERSISTENT);</span><br><span class="line">            <span class="comment">// 取出子目录数据</span></span><br><span class="line">            System.out.println(CHILD_PATH + <span class="string">"数据: "</span> + <span class="keyword">new</span> String(zk.getData(CHILD_PATH, <span class="keyword">true</span>, <span class="keyword">null</span>)));</span><br><span class="line"></span><br><span class="line">            <span class="comment">// 修改子目录节点数据</span></span><br><span class="line">            zk.setData(CHILD_PATH, <span class="string">"modification"</span>.getBytes(), -<span class="number">1</span>);</span><br><span class="line">            System.out.println(<span class="keyword">new</span> String(zk.getData(CHILD_PATH, <span class="keyword">false</span>, <span class="keyword">null</span>)));</span><br><span class="line"></span><br><span class="line">            zk.setData(CHILD_PATH, <span class="string">"modification2"</span>.getBytes(), -<span class="number">1</span>);</span><br><span class="line"></span><br><span class="line">            zk.delete(CHILD_PATH, -<span class="number">1</span>);</span><br><span class="line">            <span class="comment">// 删除父目录节点</span></span><br><span class="line">            zk.delete(ROOT_PATH, -<span class="number">1</span>);</span><br><span class="line">            <span class="comment">// 关闭连接</span></span><br><span class="line">            zk.close();</span><br><span class="line">        &#125; <span class="keyword">catch</span> (KeeperException e) &#123;</span><br><span class="line">            e.printStackTrace();</span><br><span class="line">        &#125; <span class="keyword">catch</span> (InterruptedException e) &#123;</span><br><span class="line">            e.printStackTrace();</span><br><span class="line">        &#125; <span class="keyword">catch</span> (IOException e) &#123;</span><br><span class="line">            e.printStackTrace();</span><br><span class="line">        &#125;</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">public</span> <span class="keyword">static</span> String <span class="title">getData</span><span class="params">(String path)</span> </span>&#123;</span><br><span class="line">        <span class="keyword">if</span> (path == <span class="keyword">null</span>) &#123;</span><br><span class="line">            <span class="keyword">return</span> <span class="keyword">null</span>;</span><br><span class="line">        &#125;</span><br><span class="line">        <span class="keyword">try</span> &#123;</span><br><span class="line">            <span class="keyword">return</span> <span class="keyword">new</span> String(zk.getData(path, <span class="keyword">false</span>, <span class="keyword">null</span>));</span><br><span class="line">        &#125; <span class="keyword">catch</span> (KeeperException e) &#123;</span><br><span class="line">            e.printStackTrace();</span><br><span class="line">        &#125; <span class="keyword">catch</span> (InterruptedException e) &#123;</span><br><span class="line">            e.printStackTrace();</span><br><span class="line">        &#125;</span><br><span class="line">        <span class="keyword">return</span> <span class="keyword">null</span>;</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure></p>
<p>输出:</p>
<blockquote>
<p>null触发了None事件!data:null<br>[]<br>/root触发了NodeChildrenChanged事件!data:/root<br>/root/childPath数据: childPath<br>/root/childPath触发了NodeDataChanged事件!data:modification<br>modification</p>
</blockquote>
<p>看到对于路径/root/childPath的数据修改并没有监听到</p>
<h3 id="Sent-to-the-client"><a href="#Sent-to-the-client" class="headerlink" title="Sent to the client"></a>Sent to the client</h3><p>Watch的通知事件是从服务器异步发送给客户端，不同的客户端收到的Watch的时间可能不同。但是ZooKeeper有保证：当一个客户端在收到Watch事件之前是不会看到结点数据的变化的。例如：A=3，此时在上面设置了一次Watch，如果A突然变成4了，那么客户端会先收到Watch事件的通知，然后才会看到A=4。</p>
<p>Zookeeper 客户端和服务端是通过 Socket 进行通信的，由于网络存在故障，所以监听事件很有可能不会成功地到达客户端，监听事件是异步发送至监视者的，Zookeeper 可以保障顺序性(ordering guarantee)：即客户端只有首先收到监听事件后，才会感知到它所监听的 znode 发生了变化.</p>
<blockquote>
<p>a client will never see a change for which it has set a watch until it first sees the watch event). </p>
</blockquote>
<p>网络延迟或者其他因素可能导致不同的客户端在不同的时刻感知某一监视事件，但是不同的客户端所看到都是一致的顺序。</p>
<blockquote>
<p>The key point is that everything seen by the different clients will have a consistent order.</p>
</blockquote>
<h3 id="The-data-for-which-the-watch-was-set"><a href="#The-data-for-which-the-watch-was-set" class="headerlink" title="The data for which the watch was set"></a>The data for which the watch was set</h3><p><strong>这部分是重点</strong></p>
<blockquote>
<p>This refers to the different ways a node can change. It helps to think of ZooKeeper as maintaining two lists of watches: data watches and child watches. getData() and exists() set data watches. getChildren() sets child watches. Alternatively, it may help to think of watches being set according to the kind of data returned. getData() and exists() return information about the data of the node, whereas getChildren() returns a list of children. Thus, setData() will trigger data watches for the znode being set (assuming the set is successful). A successful create() will trigger a data watch for the znode being created and a child watch for the parent znode. A successful delete() will trigger both a data watch and a child watch (since there can be no more children) for a znode being deleted as well as a child watch for the parent znode.</p>
</blockquote>
<p>这意味着 znode 节点本身具有不同的改变方式。你也可以想象 Zookeeper 维护了两条监听链表：</p>
<p>数据监听和子节点监听(data watches and child watches) </p>
<p><strong>getData() and exists() 设置数据监听,getChildren() 设置子节点监听.</strong>也可以理解成设置为哪种监听是由返回的数据类型决定的。getData() 和 exists() 返回节点数据相关信息，getChildren()返回一个子节点列表。因此，setData()会触发数据监听，create()会触发数据监听及父节点的child watch; delete() 操作将会触发当前节点的数据监视和子节点监视事件，同时也会触发该节点父节点的child watch。</p>
<p>实验一下：<br><figure class="highlight java"><table><tr><td class="code"><pre><span class="line"><span class="keyword">package</span> com.ytf.zk.nameservice;</span><br><span class="line"></span><br><span class="line"><span class="keyword">import</span> com.ytf.zk.constant.ClientBase;</span><br><span class="line"><span class="keyword">import</span> org.apache.zookeeper.CreateMode;</span><br><span class="line"><span class="keyword">import</span> org.apache.zookeeper.KeeperException;</span><br><span class="line"><span class="keyword">import</span> org.apache.zookeeper.ZooDefs;</span><br><span class="line"><span class="keyword">import</span> org.apache.zookeeper.ZooKeeper;</span><br><span class="line"></span><br><span class="line"><span class="keyword">import</span> java.io.IOException;</span><br><span class="line"></span><br><span class="line"><span class="comment">/**</span></span><br><span class="line"><span class="comment"> * Created by</span></span><br><span class="line"><span class="comment"> * DATE: 17/4/23星期日.</span></span><br><span class="line"><span class="comment"> */</span></span><br><span class="line"><span class="keyword">public</span> <span class="class"><span class="keyword">class</span> <span class="title">Naming</span> </span>&#123;</span><br><span class="line">    <span class="keyword">private</span> <span class="keyword">static</span> <span class="keyword">final</span> <span class="keyword">int</span> CLIENT_PORT = <span class="number">2181</span>;</span><br><span class="line">    <span class="keyword">private</span> <span class="keyword">static</span> <span class="keyword">final</span> String ROOT_PATH = <span class="string">"/root"</span>;</span><br><span class="line">    <span class="keyword">private</span> <span class="keyword">static</span> <span class="keyword">final</span> String CHILD_PATH = <span class="string">"/root/childPath"</span>;</span><br><span class="line">    <span class="keyword">private</span> <span class="keyword">static</span> <span class="keyword">final</span> String CHILD_PATH_2 = <span class="string">"/root/childPath2"</span>;</span><br><span class="line">    <span class="keyword">static</span> ZooKeeper zk = <span class="keyword">null</span>;</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">public</span> <span class="keyword">static</span> <span class="keyword">void</span> <span class="title">main</span><span class="params">(String[] args)</span> <span class="keyword">throws</span> Exception </span>&#123;</span><br><span class="line">        <span class="keyword">try</span> &#123;</span><br><span class="line">            zk = <span class="keyword">new</span> ZooKeeper(<span class="string">"localhost:"</span> + CLIENT_PORT, ClientBase.CONNECTION_TIMEOUT, (watchedEvent) -&gt; &#123;</span><br><span class="line">                System.out.println(watchedEvent.getPath() + <span class="string">"触发了"</span> + watchedEvent.getType() + <span class="string">"事件!"</span> + <span class="string">"data:"</span> + Naming.getData(watchedEvent.getPath()));</span><br><span class="line">            &#125;</span><br><span class="line">            );</span><br><span class="line"></span><br><span class="line">            <span class="comment">// 创建根目录</span></span><br><span class="line">            zk.create(ROOT_PATH, ROOT_PATH.getBytes(), ZooDefs.Ids.OPEN_ACL_UNSAFE, CreateMode.PERSISTENT);</span><br><span class="line">            <span class="comment">// 创建子目录</span></span><br><span class="line">            zk.create(CHILD_PATH, <span class="string">"childPath"</span>.getBytes(), ZooDefs.Ids.OPEN_ACL_UNSAFE, CreateMode.PERSISTENT);</span><br><span class="line"></span><br><span class="line">            <span class="comment">// 创建对子目录的监听</span></span><br><span class="line">            System.out.println(zk.getChildren(CHILD_PATH, <span class="keyword">true</span>));</span><br><span class="line"></span><br><span class="line">            <span class="comment">// 修改子目录节点数据,观察根节点是否监听到</span></span><br><span class="line">            zk.setData(CHILD_PATH, <span class="string">"modification"</span>.getBytes(), -<span class="number">1</span>);</span><br><span class="line"></span><br><span class="line">            zk.delete(CHILD_PATH, -<span class="number">1</span>);</span><br><span class="line"></span><br><span class="line">            <span class="comment">// 删除父目录节点</span></span><br><span class="line">            zk.delete(ROOT_PATH, -<span class="number">1</span>);</span><br><span class="line">            <span class="comment">// 关闭连接</span></span><br><span class="line">            zk.close();</span><br><span class="line">        &#125; <span class="keyword">catch</span> (KeeperException e) &#123;</span><br><span class="line">            e.printStackTrace();</span><br><span class="line">        &#125; <span class="keyword">catch</span> (InterruptedException e) &#123;</span><br><span class="line">            e.printStackTrace();</span><br><span class="line">        &#125; <span class="keyword">catch</span> (IOException e) &#123;</span><br><span class="line">            e.printStackTrace();</span><br><span class="line">        &#125;</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">public</span> <span class="keyword">static</span> String <span class="title">getData</span><span class="params">(String path)</span> </span>&#123;</span><br><span class="line">        <span class="keyword">if</span> (path == <span class="keyword">null</span>) &#123;</span><br><span class="line">            <span class="keyword">return</span> <span class="keyword">null</span>;</span><br><span class="line">        &#125;</span><br><span class="line">        <span class="keyword">try</span> &#123;</span><br><span class="line">            <span class="keyword">return</span> <span class="keyword">new</span> String(zk.getData(path, <span class="keyword">false</span>, <span class="keyword">null</span>));</span><br><span class="line">        &#125; <span class="keyword">catch</span> (KeeperException e) &#123;</span><br><span class="line">            e.printStackTrace();</span><br><span class="line">        &#125; <span class="keyword">catch</span> (InterruptedException e) &#123;</span><br><span class="line">            e.printStackTrace();</span><br><span class="line">        &#125;</span><br><span class="line">        <span class="keyword">return</span> <span class="keyword">null</span>;</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure></p>
<p>输出：</p>
<blockquote>
<p>null触发了None事件!data:null<br>[]</p>
</blockquote>
<p>修改代码：<br><figure class="highlight java"><table><tr><td class="code"><pre><span class="line"><span class="keyword">package</span> com.ytf.zk.nameservice;</span><br><span class="line"></span><br><span class="line"><span class="keyword">import</span> com.ytf.zk.constant.ClientBase;</span><br><span class="line"><span class="keyword">import</span> org.apache.zookeeper.CreateMode;</span><br><span class="line"><span class="keyword">import</span> org.apache.zookeeper.KeeperException;</span><br><span class="line"><span class="keyword">import</span> org.apache.zookeeper.ZooDefs;</span><br><span class="line"><span class="keyword">import</span> org.apache.zookeeper.ZooKeeper;</span><br><span class="line"></span><br><span class="line"><span class="keyword">import</span> java.io.IOException;</span><br><span class="line"></span><br><span class="line"><span class="comment">/**</span></span><br><span class="line"><span class="comment"> * Created by</span></span><br><span class="line"><span class="comment"> * DATE: 17/4/23星期日.</span></span><br><span class="line"><span class="comment"> */</span></span><br><span class="line"><span class="keyword">public</span> <span class="class"><span class="keyword">class</span> <span class="title">Naming</span> </span>&#123;</span><br><span class="line">    <span class="keyword">private</span> <span class="keyword">static</span> <span class="keyword">final</span> <span class="keyword">int</span> CLIENT_PORT = <span class="number">2181</span>;</span><br><span class="line">    <span class="keyword">private</span> <span class="keyword">static</span> <span class="keyword">final</span> String ROOT_PATH = <span class="string">"/root"</span>;</span><br><span class="line">    <span class="keyword">private</span> <span class="keyword">static</span> <span class="keyword">final</span> String CHILD_PATH = <span class="string">"/root/childPath"</span>;</span><br><span class="line">    <span class="keyword">private</span> <span class="keyword">static</span> <span class="keyword">final</span> String CHILD_PATH_2 = <span class="string">"/root/childPath2"</span>;</span><br><span class="line">    <span class="keyword">static</span> ZooKeeper zk = <span class="keyword">null</span>;</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">public</span> <span class="keyword">static</span> <span class="keyword">void</span> <span class="title">main</span><span class="params">(String[] args)</span> <span class="keyword">throws</span> Exception </span>&#123;</span><br><span class="line">        <span class="keyword">try</span> &#123;</span><br><span class="line">            zk = <span class="keyword">new</span> ZooKeeper(<span class="string">"localhost:"</span> + CLIENT_PORT, ClientBase.CONNECTION_TIMEOUT, (watchedEvent) -&gt; &#123;</span><br><span class="line">                System.out.println(watchedEvent.getPath() + <span class="string">"触发了"</span> + watchedEvent.getType() + <span class="string">"事件!"</span> + <span class="string">"data:"</span> + Naming.getData(watchedEvent.getPath()));</span><br><span class="line">            &#125;</span><br><span class="line">            );</span><br><span class="line"></span><br><span class="line">            <span class="comment">// 创建根目录</span></span><br><span class="line">            zk.create(ROOT_PATH, ROOT_PATH.getBytes(), ZooDefs.Ids.OPEN_ACL_UNSAFE, CreateMode.PERSISTENT);</span><br><span class="line">            <span class="comment">// 创建子目录</span></span><br><span class="line">            zk.create(CHILD_PATH, <span class="string">"childPath"</span>.getBytes(), ZooDefs.Ids.OPEN_ACL_UNSAFE, CreateMode.PERSISTENT);</span><br><span class="line"></span><br><span class="line">            <span class="comment">// 创建对子目录的数据监听</span></span><br><span class="line">            System.out.println(<span class="keyword">new</span> String(zk.getData(CHILD_PATH, <span class="keyword">true</span>, <span class="keyword">null</span>)));</span><br><span class="line"></span><br><span class="line">            <span class="comment">// 修改子目录节点数据,观察根节点是否监听到</span></span><br><span class="line">            zk.setData(CHILD_PATH, <span class="string">"modification"</span>.getBytes(), -<span class="number">1</span>);</span><br><span class="line"></span><br><span class="line">            zk.delete(CHILD_PATH, -<span class="number">1</span>);</span><br><span class="line"></span><br><span class="line">            <span class="comment">// 删除父目录节点</span></span><br><span class="line">            zk.delete(ROOT_PATH, -<span class="number">1</span>);</span><br><span class="line">            <span class="comment">// 关闭连接</span></span><br><span class="line">            zk.close();</span><br><span class="line">        &#125; <span class="keyword">catch</span> (KeeperException e) &#123;</span><br><span class="line">            e.printStackTrace();</span><br><span class="line">        &#125; <span class="keyword">catch</span> (InterruptedException e) &#123;</span><br><span class="line">            e.printStackTrace();</span><br><span class="line">        &#125; <span class="keyword">catch</span> (IOException e) &#123;</span><br><span class="line">            e.printStackTrace();</span><br><span class="line">        &#125;</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">public</span> <span class="keyword">static</span> String <span class="title">getData</span><span class="params">(String path)</span> </span>&#123;</span><br><span class="line">        <span class="keyword">if</span> (path == <span class="keyword">null</span>) &#123;</span><br><span class="line">            <span class="keyword">return</span> <span class="keyword">null</span>;</span><br><span class="line">        &#125;</span><br><span class="line">        <span class="keyword">try</span> &#123;</span><br><span class="line">            <span class="keyword">return</span> <span class="keyword">new</span> String(zk.getData(path, <span class="keyword">false</span>, <span class="keyword">null</span>));</span><br><span class="line">        &#125; <span class="keyword">catch</span> (KeeperException e) &#123;</span><br><span class="line">            e.printStackTrace();</span><br><span class="line">        &#125; <span class="keyword">catch</span> (InterruptedException e) &#123;</span><br><span class="line">            e.printStackTrace();</span><br><span class="line">        &#125;</span><br><span class="line">        <span class="keyword">return</span> <span class="keyword">null</span>;</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure></p>
<p>输出:</p>
<blockquote>
<p>null触发了None事件!data:null<br>childPath<br><strong>/root/childPath触发了NodeDataChanged事件!data:modification</strong></p>
</blockquote>
<p>对比一下可以看出不同的操作触发不同的监听事件。</p>
<h2 id="各种watch触发的情况总结"><a href="#各种watch触发的情况总结" class="headerlink" title="各种watch触发的情况总结"></a>各种watch触发的情况总结</h2><p>可以注册watcher的方法：getData、exists、getChildren。      可以触发watcher的方法：create、delete、setData。连接断开的情况下触发的watcher会丢失。<br>一个Watcher实例是一个回调函数，被回调一次后就被移除了。如果还需要关注数据的变化，需要再次注册watcher。<br>New ZooKeeper时注册的watcher叫default watcher，它不是一次性的，只对client的连接状态变化作出反应。</p>
<h3 id="写操作与ZK内部产生的事件的对应关系"><a href="#写操作与ZK内部产生的事件的对应关系" class="headerlink" title="写操作与ZK内部产生的事件的对应关系"></a>写操作与ZK内部产生的事件的对应关系</h3><table>
<thead>
<tr>
<th></th>
<th>event For “/path”</th>
<th>event For “/path/child”</th>
</tr>
</thead>
<tbody>
<tr>
<td>create(“/path”)</td>
<td>EventType.NodeCreated</td>
<td>无</td>
</tr>
<tr>
<td>delete(“/path”)</td>
<td>EventType.NodeDeleted</td>
<td>无</td>
</tr>
<tr>
<td>setData(“/path”)</td>
<td>EventType.NodeDataChanged</td>
<td>无</td>
</tr>
<tr>
<td>create(“/path/child”)</td>
<td>EventType.NodeChildrenChanged</td>
<td>EventType.NodeCreated</td>
</tr>
<tr>
<td>delete(“/path/child”)</td>
<td>EventType.NodeChildrenChanged</td>
<td>EventType.NodeDeleted</td>
</tr>
<tr>
<td>setData(“/path/child”)</td>
<td>无</td>
<td>EventType.NodeDataChanged</td>
</tr>
</tbody>
</table>
<h3 id="事件类型与watcher的对应关系"><a href="#事件类型与watcher的对应关系" class="headerlink" title="事件类型与watcher的对应关系"></a>事件类型与watcher的对应关系</h3><table>
<thead>
<tr>
<th>event For “/path”</th>
<th>defaultWatcher</th>
<th>exists(“/path”)</th>
<th>getData(“/path”)</th>
<th>getChildren(“/path”)</th>
</tr>
</thead>
<tbody>
<tr>
<td>EventType.None</td>
<td>√</td>
<td>√</td>
<td>√</td>
<td>√</td>
</tr>
<tr>
<td>EventType.NodeCreated</td>
<td></td>
<td>√</td>
<td>√</td>
<td></td>
</tr>
<tr>
<td>EventType.NodeDeleted</td>
<td></td>
<td>√</td>
<td>√</td>
<td></td>
</tr>
<tr>
<td>EventType.NodeDataChanged</td>
<td></td>
<td>√</td>
<td>√</td>
<td></td>
</tr>
<tr>
<td>EventType.NodeChildrenChanged</td>
<td></td>
<td></td>
<td></td>
<td>√</td>
</tr>
</tbody>
</table>
<h3 id="写操作与watcher的对应关系"><a href="#写操作与watcher的对应关系" class="headerlink" title="写操作与watcher的对应关系"></a>写操作与watcher的对应关系</h3><table>
<thead>
<tr>
<th></th>
<th>“/path”</th>
<th></th>
<th></th>
<th></th>
<th>“/path/child”</th>
<th></th>
</tr>
</thead>
<tbody>
<tr>
<td></td>
<td>exists</td>
<td>getData</td>
<td>getChildren</td>
<td>exists</td>
<td>getData</td>
<td>getChildren</td>
</tr>
<tr>
<td>create(“/path”)</td>
<td>√</td>
<td>√</td>
<td></td>
<td></td>
<td></td>
<td></td>
</tr>
<tr>
<td>delete(“/path”)</td>
<td>√</td>
<td>√</td>
<td>√</td>
<td></td>
<td></td>
<td></td>
</tr>
<tr>
<td>setData(“/path”)</td>
<td>√</td>
<td>√</td>
<td></td>
<td></td>
<td></td>
<td></td>
</tr>
<tr>
<td>create(“/path/child”)</td>
<td></td>
<td></td>
<td>√</td>
<td>√</td>
<td>√</td>
<td></td>
</tr>
<tr>
<td>delete(“/path/child”)</td>
<td></td>
<td></td>
<td>√</td>
<td>√</td>
<td>√</td>
<td>√</td>
</tr>
<tr>
<td>setData(“/path/child”)</td>
<td></td>
<td></td>
<td></td>
<td>√</td>
<td>√</td>
</tr>
</tbody>
</table>
<p><strong>值得注意的是：getChildren(“/path”)监视/path的子节点，如果（/path）自己删了，也会触发NodeDeleted事件。</strong></p>
<h3 id="永久监听"><a href="#永久监听" class="headerlink" title="永久监听"></a>永久监听</h3><h2 id="参考文档"><a href="#参考文档" class="headerlink" title="参考文档"></a>参考文档</h2><p><a href="https://zookeeper.apache.org/doc/trunk/zookeeperProgrammers.html" target="_blank" rel="noopener">https://zookeeper.apache.org/doc/trunk/zookeeperProgrammers.html</a><br><a href="http://lixuguang.iteye.com/blog/2342721" target="_blank" rel="noopener">http://lixuguang.iteye.com/blog/2342721</a><br><a href="https://www.ibm.com/developerworks/cn/opensource/os-cn-zookeeper/" target="_blank" rel="noopener">https://www.ibm.com/developerworks/cn/opensource/os-cn-zookeeper/</a></p>
]]></content>
      <categories>
        <category>技术</category>
        <category>ZooKeeper</category>
      </categories>
      <tags>
        <tag>zookeeper</tag>
      </tags>
  </entry>
  <entry>
    <title>Kafka官方文档翻译--设计</title>
    <url>/2017/04/22/Kafka%E5%AE%98%E6%96%B9%E6%96%87%E6%A1%A3%E7%BF%BB%E8%AF%91%E2%80%94%E2%80%94%E8%AE%BE%E8%AE%A1/</url>
    <content><![CDATA[<h2 id="Design"><a href="#Design" class="headerlink" title="Design"></a>Design</h2><h3 id="Motivation"><a href="#Motivation" class="headerlink" title="Motivation"></a>Motivation</h3><p>我们设计Kafka用来作为统一的平台来处理大公司可能拥有的所有实时数据源。为了做到这点，我们必须思考大量的使用场景。</p>
<p>它必须有高吞吐去支持大数据流，例如实时日志聚合。</p>
<p>它必须优雅的处理数据积压，以支持定期从离线系统加载数据。</p>
<p>这也以为这系统必须支持低延迟的分发来处理传统消息系统的场景。</p>
<p>我们想支持分区的、分布式的、实时的处理数据源并创建新的数据源，这推动了我们的分区和消费模型。</p>
<p>最后，将流反馈到其他系统进行服务的情况下，我们知道系统必须能够保证容错性，在部分机器故障的时候提供服务。</p>
<p>支持这些使用推动我们做了一些列特殊的元素设计，比起传统的消息系统更像是数据库日志。我们将在以下章节介绍一些设计要素。</p>
<a id="more"></a>
<h3 id="Persistence"><a href="#Persistence" class="headerlink" title="Persistence"></a>Persistence</h3><h4 id="Don’t-fear-the-filesystem"><a href="#Don’t-fear-the-filesystem" class="headerlink" title="Don’t fear the filesystem!"></a>Don’t fear the filesystem!</h4><p>Kafka强依赖文件系统来存储和缓存消息。“磁盘是缓慢的”是一个通常的认知，这是人们怀疑持久化的结构能否提供强大的性能。事实上，磁盘比人们想象的更慢也更快，这基于如何去使用它们；一个合适的设计可以使磁盘和网络一样的快速。</p>
<p>影响磁盘性能的核心因素是磁盘驱动的吞吐和过去十年磁盘的查找方式不同了。使用六个7200rpm的SATA RAID-5阵列的JBOD配置线性写入能力为600MB/sec，而随机写的性能仅仅是100k/sec，相差了6000倍。线性写入和读取是最可预测的，并且被操作系统大量的优化。现代操作系统提供read-ahead和write-behind技术，他们大块预读数据，并将较小的罗机械合并成较大的物理写入。在ACM Queue的文章中可以找到此问题相关的进一步讨论；他们实际上发现顺序访问磁盘在某些情况下比随机访问内存还快。</p>
<p>为了弥补性能的差异，现代操作系统在使用主内存来做磁盘缓存时变的越来越激进。当内存被回收时，现代操作系统将乐意将所有可用内存转移到磁盘缓存，而且性能会降低很多。所有的磁盘读写都需要通过这层缓存。这个功能不会被轻易关闭，除非使用Direct IO，因此尽管在进程内缓存了数据，这些数据也有可能在操作系统的pagecache中缓存，从而被缓存了两次。</p>
<p>此外，我们建立在JVM之上，任何在Java内存上花费过时间的人都知道两件事情：</p>
<p>对象的内存开销非常大，通常将存储的数据大小翻倍（或更多）。</p>
<p>Java的内存回收随着堆内数据的增多变的越来越缓慢。</p>
<p>由于这些因素，使用文件系统并依赖于pagecache要优于维护内存中缓存或其他结构——我们至少可以通过直接访问内存来是可用内存增加一倍，并通过存储字节码而不是对象的方式来节约更多的内存。这样做将可以在32G的机器上使用28-30GB的内存，而不需要承受GC的问题。此外，及时重启服务，内存会保持有效，而进程内缓存将需要重建（对于10G的数据可能需要10分钟），否则需要从冷数据加载（可怕的初始化性能）。这也大大简化了代码，因为保持缓存和文件之间的一致性是由操作系统负责的，这比进程中操作更不容易出错。</p>
<p>这是一个简单的设计：在进程内尽量缓冲数据，空间不足时将所有数据刷写到磁盘，我们采用了相反的方式。数据并尽快写入一个持久化的日志而不需要立即刷到磁盘。实际上这只是意味着数据被转移到了内核的pagecache。</p>
<p>（以pagecache为中心的设计风格）</p>
<h4 id="Constant-Time-Suffices"><a href="#Constant-Time-Suffices" class="headerlink" title="Constant Time Suffices"></a>Constant Time Suffices</h4><p>在消息系统中使用持久化数据通常是具有关联的BTree或其他随机访问的数据结构，以维护消息的元数据。BTree是最通用的数据结构，可以在消息系统中支持各种各样的语义。BTree的操作时间复杂度是O(log N)。通常O(log N)被认为是固定时间的，但是在磁盘操作中却不是。每个磁盘一次只能执行一个seek，所以并行度受到限制。因此即使少量的磁盘搜索也会导致非常高的开销。由于操作系统将快速的缓存操作和非常慢的磁盘操作相结合，所以观察到树结构的操作通常是超线性的，因为数据随固定缓存增加。</p>
<p>直观的，持久化队列可以像日志的解决方案一样，简单的读取和追加数据到文件的结尾。这个结构的优势是所有的操作都是O(1)的，并且读取是可以并行不会阻塞的。这具有明显的性能优势，因为性能与数据大小完全分离，可以使用低速的TB级SATA驱动器。虽然这些驱动器的搜索性能不佳，但是对于大量读写而言，他们的性能是可以接受的，并且价格是三分之一容量是原来的三倍。</p>
<p>无需任何的性能代价就可以访问几乎无限的磁盘空间，这意味着我们可以提供一些在消息系统中非寻常的功能。例如，在Kafka中，我们可以将消息保留较长的时间（如一周），而不是在消费后就尽快删除。这位消费者带来了很大的灵活性。</p>
<h3 id="Efficiency"><a href="#Efficiency" class="headerlink" title="Efficiency"></a>Efficiency</h3><p>我们在效率上付出了很大的努力。主要的用例是处理web的数据，这个数据量非常大：每个页面可能会生成十几个写入。此外我们假设每个发布的消息至少被一个Consumer消费，因此我们尽可能使消费的开销小一些。</p>
<p>从构建和运行一些类似的系统的经验发现，效率是多租户操作的关键。如果下游基础服务成为瓶颈，那么应用程序的抖动将会引起问题。我们确保应用程序不会引起基础服务的Load问题，这个非常重要的，当一个集群服务上百个应用程序的时候，因为应用的使用模式的变化时非常频繁的。</p>
<p>我们在之前的章节中讨论过磁盘的效率。一旦不良的磁盘访问模式被消除，这种类型的系统有两个低效的原因：太多太小的IO操作和过多的数据拷贝。</p>
<p>太小的IO操作问题存在于客户端和服务端之间，也存在于服务端自身的持久化当中。</p>
<p>为了避免这个问题，我们的协议围绕“message set”抽象，通常是将消息聚合到一起。这允许网络请求将消息聚合到一起，并分摊网络往返的开销，而不是一次发送单个消息。服务端依次将大块消息追加到日志中，消费者一次线性获取一批数据。</p>
<p>这种简单的优化产生了一个数量级的加速。分批带来了更大的网络包，连续的磁盘操作，连续的内存块等等，这些都使得Kafka将随机消息写入转化为线性的写入并流向Consumer。</p>
<p>其他低效的地方是字符复制。在消息少时不是问题，但是对负载的影响是显而易见的。为了避免这种情况，我们采用被producer、broker、Consumer共享的标准的二进制消息格式（所以数据可以在传输时不需要进行修改）。</p>
<p>由Broker维护的消息日志本身只是一批文件，每个文件由一系列以相同格式写入的消息构成。保持相同的格式保证了最重要的优化：网络传输和持久化日志块。现在UNIX操作系统提供了高度优化的代码路径用于将pagecache的数据传输到网络；在Linux中，这有sendfile实现。<br><a href="http://man7.org/linux/man-pages/man2/sendfile.2.html" target="_blank" rel="noopener">sendfile system call</a></p>
<p>要理解sendfile的影响，了解从文件到网络传输数据的data path非常重要：</p>
<ol>
<li>操作系统从磁盘读取文件数据到pagecache，在内核空间</li>
<li>用户从内核空间将数据读到用户空间的buffer</li>
<li>操作系统重新将用户buffer数据读取到内核空间写入到socket中</li>
<li>操作系统拷贝socket buffer数据到NIC buffer并发送到网络<br>这显然是低效的，有四个副本和两个系统调用。使用sendfile，允许操作系统直接将数据从pagecache写入到网络，而避免不必要的拷贝。在这个过程中，只有最终将数据拷贝到NIC buffer是必要的。</li>
</ol>
<p>我们期望一个共同的场景是多个Consumer消费一个Topic数据，使用zero-copy优化，数据被拷贝到pagecache并且被多次使用，而不是每次读取的时候拷贝到内存。这允许以接近网络连接的速度消费消息。</p>
<p>pagecache和sendfile的组合意味着在消费者追上写入的情况下，将看不到磁盘上的任何读取活动，因为他们都将从缓存读取数据。</p>
<p>sendfile和更多的zero-copy背景知识见zero-copy</p>
<p>End-to-end Batch Compression</p>
<p>在一些场景下，CPU核磁盘并不是性能瓶颈，而是网络带宽。在数据中心和广域网上传输数据尤其如此。当然，用户可以压缩它的消息而不需要Kafka的支持，但是这可能导致非常差的压缩比，因为冗余的大部分是由于相同类型的消息之间的重复（例如JSON的字段名）。多个消息进行压缩比单独压缩每条消息效率更高。</p>
<p>Kafka通过允许递归消息来支持这一点。一批消息可以一起压缩并以此方式发送到服务端。这批消息将以压缩的形式被写入日志，只能在消费端解压缩。</p>
<p>Kafka支持GZIP，Snappy和LZ4压缩协议。更多的压缩相关的细节在这里。</p>
<h3 id="The-Producer"><a href="#The-Producer" class="headerlink" title="The Producer"></a>The Producer</h3><h4 id="Load-balancing"><a href="#Load-balancing" class="headerlink" title="Load balancing"></a>Load balancing</h4><p>Producer直接向Leader Partition所在的Broker发送数据而不需要经过任何路由的干预。为了支持Producer直接向Leader Partition写数据，所有的Kafka服务节点都支持Topic Metadata的请求，返回哪些Server节点存活的、Partition的Leader节点的分布情况。</p>
<p>由客户端控制将数据写到哪个Partition。这可以通过随机或者一些负载均衡的策略来实现（即客户端去实现Partition的选择策略）。Kafka暴露了一个接口用于用户去指定一个Key，通过Key hash到一个具体的Partition。例如，如果Key是User id，那么同一个User的数据将被发送到同一个分区。这样就允许消费者在消费时能够对消费的数据做一些特定的处理。这样的设计被用于处理“局部敏感”的数据（结合上面的场景，Partition内的数据是可以保持顺序消费的，那么同一个用户的数据在一个分区，那么就可以保证对任何一个用户的处理都是顺序的）。</p>
<h4 id="Asynchronous-send"><a href="#Asynchronous-send" class="headerlink" title="Asynchronous send"></a>Asynchronous send</h4><p>批处理是提升效率的主要方式一致，为了支持批处理，Kafka允许Producer在内存聚合数据并在一个请求中发出。批处理的大小可以是通过消息数量指定的，也可以是通过等待的时间决定的（例如64K或者10ms）。这样允许聚合更多的数据后发送，减少了IO操作。缓冲的数据大小是可以配置了，这样能适当增加延迟来提升吞吐。</p>
<p>更多的细节可以在Producer的配合和API文档中找到。</p>
<h3 id="The-Consumer"><a href="#The-Consumer" class="headerlink" title="The Consumer"></a>The Consumer</h3><p>Kafka Consumer通过给Leader Partition所在的Broker发送“fetch”请求来进行消费。Consumer在请求中指定Offset，并获取从指定的Offset开始的一段数据。因此Consumer对消费的位置有绝对的控制权，通过重新设置Offset就可以重新消费数据。</p>
<h4 id="Push-vs-Pull"><a href="#Push-vs-Pull" class="headerlink" title="Push vs Pull"></a>Push vs Pull</h4><p>我们考虑的一个初步问题是Consumer应该从Broker拉取数据还是Broker将数据推送给Consumer。在这方面，Kafka和大多数消息系统一样，采用传统的设计方式，由Producer想Broker推送数据，Consumer从Broker上拉取数据。一些日志中心系统，如<a href="https://github.com/facebookarchive/scribe" target="_blank" rel="noopener">Scribe</a>和<a href="http://flume.apache.org/" target="_blank" rel="noopener">Apache Flume</a>，遵循数据向下游推送的方式。两种方式各有利弊。基于推送的方式，由于是由Broker控制速率，不能很好对不同的Consumer做处理。Consumer的目标通常是以最大的速率消费消息，不幸的是，在一个基于推送的系统中，当Consumer消费速度跟不上生产速度 时，推送的方式将使Consumer“过载”。基于拉取的系统在这方面做的更好，Consumer只是消费落后并在允许时可以追上进度。消费者通过某种协议来缓解这种情况，消费者可以通过这种方式来表明它的负载，这让消费者获得充分的利用但不会“过载”。以上原因最终使我们使用更为传统的Pull的方式。</p>
<p>Pull模型的另一个优势是可以聚合数据批量发送给Consumer。Push模型必须考虑是立即推送数据给Consumer还是等待聚合一批数据之后发送。如果调整为低延迟，这将导致每次只发送一条消息（增加了网络交互）。基于Pull的模式，Consumer每次都会尽可能多的获取消息（受限于可消费的消息数和配置的每一批数据最大的消息数），所以可以优化批处理而不增加不必要的延迟。</p>
<p>基于Pull模式的一个缺陷是如果Broker没有数据，Consumer可能需要busy-waiting的轮训方式来保证高效的数据获取（在数据到达后快速的响应）。为了避免这种情况，我们在Pull请求中可以通过参数配置“long poll”的等待时间，可以在服务端等待数据的到达（可选的等待数据量的大小以保证每次传输的数据量，减少网络交互）。</p>
<p>你可以想象其他一些从端到端，采用Pull的可能的设计。Producer把数据写到本地日志，Broker拉取这些Consumer需要的数据。一个相似的被称为“store-and-forward”的Producer经常被提及。这是有趣的，但是我们觉得不太适合我们可能会有成千上万个Producer的目标场景。我们维护持久化数据系统的经验告诉我们，在系统中使多应用涉及到上千块磁盘将会使事情变得不可靠并且会使操作它们变成噩梦。最后再实践中，我们发现可以大规模的运行强大的SLAs通道，而不需要生产者持久化。</p>
<h4 id="Consumer-Position"><a href="#Consumer-Position" class="headerlink" title="Consumer Position"></a>Consumer Position</h4><p>记录哪些消息被消费过是消息系统的关键性能点。</p>
<p>大多数消息系统在Broker上保存哪些消息已经被消费的元数据。也就是说，Broker可以在消费传递给Consumer后立即记录或等待消费者确认之后记录。这是一个直观的选择，并且对于单个服务器而言并没有更好的方式可以存储这个状态。大多数消息系统中的存储设备并不能很好的伸缩，所以这也是务实的选择——当Broker确认消息被消费后就立即删除，以保证存储较少的数据。</p>
<p>让Broker和Consumer关于那些消息已经被消费了达成一致并不是一个简单的问题。如果Broker在将消息写到网络之后就立即认为消息已经被消费，那么如果Consumer消费失败（Consumer在消费消息之前Crash或者网络问题等）消息将丢失。为了解决这个问题，一些消息系统增加了ACK机制，消息被标记为只是发送出去而不是已经被消费，Broker需要等待Consumer发送的ACK请求之后标记具体哪些消息已经被消费了。这个策略修复了消息丢失的问题，但是引起了新的问题。第一，如果Consumer处理了消息，但是在发送ACK给Broker之前出现问题，那么消息会被重复消息。第二，Broker需要维护每一条消息的多个状态（是否被发送、是否被消费）。棘手的问题是要处理被发送出去但是没有被ACK的消息。</p>
<p>Kafka采用不同的方式处理。Topic被划分为多个内部有序的分区，每个分区任何时刻只会被一个group内的一个Consumer消费。这意味着一个Partition的Position信息只是一个数字，标识下一条要消费的消息的偏移量。这使得哪些消息已经被消费的状态变成了一个简单的数据。这个位置可以定期做CheckPoint。这使得消息的ACK的代价非常小。</p>
<p>这个方案还有其他的好处。消费者可以优雅的指定一个旧的偏移量并重新消费这些数据。这和通常的消息系统的观念相违背，但对很多消费者来说是一个很重要的特性。比如，如果Consumer程序存在BUG，在发现并修复后，可以通过重新消费来保证数据都正确的处理。</p>
<h4 id="Offline-Data-Load"><a href="#Offline-Data-Load" class="headerlink" title="Offline Data Load"></a>Offline Data Load</h4><p>可扩展的持久化存储的能力，是消费者可以定期的将数据导入到像Hadoop这样的离线系统或关系型数据仓库中。</p>
<p>在Hadoop的场景中，我们通过把数据分发到独立的任务中进行并行处理，按照node/topic/partition组合，充分使用另行能力加载数据。Hadoop提供任务管理，失败的任务可以重新启动，而不需要担心重复数据的危险——任务会从原始位置重新启动。</p>
<h3 id="Message-Delivery-Semantics"><a href="#Message-Delivery-Semantics" class="headerlink" title="Message Delivery Semantics"></a>Message Delivery Semantics</h3><p>现在我们对Producer和Consumer已经有了一定的了解，接着我们来讨论Kafka在Producer和Consumer上提供的语义。显然的，在分发消息时是可以有多种语义的：</p>
<ul>
<li>At most once：消息可能丢失，但不会重复投递</li>
<li>At least once：消息不会丢失，但可能会重复投递</li>
<li>Exactly once：消息不丢失、不重复，会且只会被分发一次（真正想要的）<br>值得注意的是这分为两个问题：发布消息的可用性和消费消息的可用性。</li>
</ul>
<p>许多系统都声称提供“exactly once”语义，仔细阅读会发现，这些声明是误导的（他们没有考虑Producer和Consumer可能Crash的场景，或是数据写入磁盘后丢失的情况）。</p>
<p>Kafka提供的语义是直接了当的。发送消息的时候我们有一个消息被Commit到Log的概念。一旦消息已经被Commit，它将不会丢失，只要还有一个复制了消息所在Partition的Broker存活着。“存活”的定义以及我们覆盖的失败的情况将在下一节描述。现在假设一个完美的Broker，并且不会丢失，来理解对Producer和Consumer提供的语义保证。如果Producer发送一条消息，并且发生了网络错误，我们是不能确认错误发生在消息Commit之前还是消息Commit之后的。类似于使用自增主键插入数据库，是不能确认写入之后的主键值的。</p>
<p>Producer没有使用的强制可能的语义。我们无法确认网络是否会发生异常，可以使Producer创建有序的主键使重试发送成为幂等的行为。这个特性对一个复制系统来说不是无价值的，因为服务器在发生故障的情况下依旧需要提供服务。使用这个功能，Producer可以重试，直到收到消息成功commit的响应，在这个点上保证消息发送的exactly once。我们希望把这个特性加到后续的Kafka版本中。</p>
<p>不是所有的场景都需要这样的保证。对应延迟敏感的场景，我们允许Producer指定其期望的可用性级别。如果Producer期望等待消息Commit，那么这可能消耗10ms。Producer也可以指定以异步的方式发送消息或只等Leader节点写入消息（不能Follower）。</p>
<p>接着我们从消费者的视角来描述语义。所有的副本都拥有偏移量相同的日志。Consumer控制它在日志中的偏移量。如果Consumer一直正常运行，它可以只把偏移量存储在内存中，但是如果Consumer crash且我们期望另一个新的Consumer接管消费，那么需要选择一个位置来开始消费。假设Consumer读取了一些消息——它有集中处理消息和位置的方式。</p>
<ol>
<li><p>它可以读取消息，然后保存位置信息，然后处理消息。在这个场景中，Consumer可能在保存位置信息后消费消息失败，那么下一次消费可能从保存的位点开始，尽管之前部分消息被处理失败。这是消费处理过程中失败的at-most-once（只被处理了一次，但是可能处理失败）。</p>
</li>
<li><p>它可以读取消息，之后处理消息，最后保存位置信息。这个场景中，Consumer可能在处理完消息，但是保存位点之前Crash，那么下一次会重新消费这些消息，尽管已经被消费过。这是Consumer Crash引起的at-least-once（消息可能会被处理多次）。在很多场景中，消息可以有一个主键，这样可以保证处理的幂等性（多次处理不会有影响）。</p>
</li>
</ol>
<p>那么什么是exactly once语义？这里的限制实际上不是消息系统的特性，而是消息处理和位置信息的保存。经典的解决方案是采用两阶段提交的方式来处理。但是这也可以用一个更简单的方式来处理：通过将消息处理结果和位置信息保存在同一位置上。这是更好的，因为很多Consumer期望写入的系统并不支持两阶段提交。例如, 我们的hadoop ETL工具从保存数据到hdfs上的同时也把位移位置也保存到hdfs中了, 这样可以保证数据和位移位置同时被更新或者都没更新.我们在很多系统上使用类似的模式, 用于解决那些需要这种强语义但是却没有主键用于区分重复的储存系统中.</p>
<p>默认Kafka提供at-least-once语义的消息分发(<a href="https://kafka.apache.org/documentation/streams/" target="_blank" rel="noopener">kafka stream</a>)，允许用户通过在处理消息之前保存位置信息的方式来提供at-most-once语义。exactly-once语义需要和输出系统像结合，Kafka提供的offset可以使这个实现变的“直接了当的”（变得比较简单）。</p>
<h3 id="Replication"><a href="#Replication" class="headerlink" title="Replication"></a>Replication</h3><p>Kafka为Topic的每个Partition日志进行备份，备份数量可以由用户进行配置。这保证了系统的自动容错，如果有服务器宕机，消息可以从剩余的服务器中读取。</p>
<p>其他消息系统提供了备份相关的功能，但在我们看来，这是一个附加的功能，不能被大量使用，并且伴随着大量的缺点：Slave是不活跃的（这里应该是指Slave只提供了备份，并不可以被消费等等）、吞吐受到很大的影响、需要手动配置等等。在Kafka中，我们默认就提供备份，实际上我们认为没有备份的Topic是一种特殊的备份，只是备份数为1。</p>
<p>备份的单位是Topic的分区。在没有发生异常的情况下，Kafka中每个分区都会有一个Leader和0或多个Follower。备份包含Leader在内（也就是说如果备份数为3，那么有一个Leader Partition和两个Follower Partition）。所有的读写请求都落在Leader Partition上。通常情况下分区要比Broker多，Leader分区分布在Broker上。Follower上的日志和Leader上的日志相同，拥有相同的偏移量和消息顺序（当然，在特定时间内，Leader上日志会有一部分数据还没复制到Follower上）。</p>
<p>Follower作为普通的Consumer消费Leader上的日志，并应用到自己的日志中。Leader允许Follower自然的，成批的从服务端获取日志并应用到自己的日志中。</p>
<p>大部分分布式系统都需要自动处理故障，需要对节点“alive”进行精确的定义。例如在Kafka中，节点存活需要满足两个条件：</p>
<p>节点需要保持它和ZooKeeper之间的Session（通过ZK的心跳机制）<br>如果是Follower，需要复制Leader上的写事件，并且复制进度没有“落后太多”<br>我们称满足这两个条件的节点为“同步的”来避免使用“alive”或“failed”这样模糊的概念。Leader节点保存同步中的Follower节点。如果一个Follower宕机或复制落后太多，Leader将从同步的Follower List中将其移除。通过replica.lag.time.max.ms配置来定义“落后太多”。</p>
<p>在分布式系统的术语中，我们只尝试处理“失败/恢复”模型——节点突然停止工作之后恢复的情况。Kafka不处理“拜占庭”问题。</p>
<p>一条消息在被应用到所有的备份上之后被认为是“已经提交的”。只有提交了的消息会被Consumer消费。这意味着Consumer不需要担心Leader节点宕机后消息会丢失。另一方面，Producer可以配置是否等待消息被提交，这取决于他们在延迟和可用性上的权衡。这个可以通过Producer的配置项中设置。</p>
<p>Kafka提供了一条消息被提交之后，只要还有一个备份可用，消息就不会丢失的保证。</p>
<p>Kafka保证在节点故障后依旧可用，但是无法再网络分区的情况下保持可用。</p>
<p>Replicated Logs: Quorums, ISRs, and State Machines (Oh my!)</p>
<p>Kafka分区机制的核心是日志复制。日志复制是分布式系统中最基础的东西，有很多方式可以实现。日志复制可以作为基于状态机的分布式系统的基础设置。</p>
<p>日志复制模型用于处理连续、有序的输入（例如给log entry添加0、1、2这样的编号）。有很多方式实现日志复制，最简单的方式是Leader选择和提供这个顺序之。只要Leader节点存活，Follower只需要按照Leader选择的值和顺序来复制即可。</p>
<p>当然，如果Leader不会宕机，那我们也不需要Follower了！在Leader宕机之后，我们需要在Follower中选择一个节点成为新的Leader。Follower可能会宕机或者日志落后较多，所以我们必须确保选择一个“及时同步”（复制进度和Leader最近的节点）成为新的Leader。复制算法必须提供这样的保证：如果Client收到一条消息已经被Commit了，如果Leader宕机，新Leader必须包含这条已经被Commit的消息。这是一个权衡：Leader在确认消息Commit之前需要等待更多的Follower来确认复制了消息来保证在Leader宕机后有更多可以成为Leader的Follower节点。</p>
<p>如果你选择了所需要的ACK的数量以及选择Leader时需要比较的日志数以确保能重合，这个叫做Quorum。</p>
<p>一个通用的来权衡的方式是提交日志和选择Leader时都采用大多数投票的原则。这不是Kafka使用的方式，但是无所谓，让我们去理解这种方式来了解实现原理。假设一共有2f+1个备份，那么f+1的副本必须在Leader提交commit之前接收到消息，这样就可以从f+1个节点中选择出新节点作为Leader。因为任何f+1个节点，必然有一个节点包含最全的日志。还有很多关于这个算法的细节需要处理（如何定义日志更全、在Leader节点宕机时保持日志一致性等）在这里先忽略。</p>
<p>大多数选票的方法有非常好的特性：延迟取决于同步最快的Server节点。这说明，如果备份数为3，那么延迟取决于两个备份节点中较快的节点。</p>
<p>有很多类似的算法变体，例如ZooKeeper的Zab，Raft,Viewstamped Replication等。和Kafka最相似的学术刊物是微软的PacificA。</p>
<p>大多数选票方式的取消是它不能容忍很多的故障，导致你没有可以被选为新Leader的节点。为了容忍一个节点故障，需要3分数据备份，容忍两个节点故障则需要5个节点。在我们的经验中，只有足够的冗余才能容忍单一的故障在实际系统中是不够的，每次写5次副本，使用5倍的存储空间，和1/5的带宽，在大体量的数据存储上不是很可行。这就是为什么quorum算法多多应用在像ZK这样存储配置的集群中，而不是数据存储系统中。例如HDFS的namenode的高可用建立在大多数选票的机制上，但是数据存储缺不是。</p>
<p>Kafka使用一个明显不同的方式来选择quorum集合。代替大多数选票，Kafka动态的维护一个“同步的备份（in-sync replicas ISR）”的集合。只有这个集合中的成员能被选举为Leader。一个写入请求需要同步到所有的同步中的备份才能认为是提交的。ISR集合在变更时会被持久化到ZK。因此，任何ISR中的备份都可以被选举为新的Leader。这对于Kafka这种拥有多分区并且需要保证这节点负载均衡的模型来说非常重要。使用ISR模型和f+1个副本，Kafka可以容忍f个备份不可用的情况。</p>
<p>对于大多数的场景，我们认为这样的妥协是合理的。在实践中，为了容忍f个节点故障，大多数选票原则和ISR方式都需要等待相同的备份在提交消息前进行确认（如需要容忍一个节点故障，大多数选票的选择需要3个节点，并且提交消息需要至少一个备份的确认；ISR只需要两个节点，需要确认的副本数一样是一个）。相对于大多数选票的原则，ISR方式不需要等待最慢的服务器确认消息是一个优势。尽管如此，我们进行改善，让客户端决定是否等待消息提交，使用较小的副本数，这样带来的吞吐和更小的磁盘空间要求是有价值的。</p>
<p>另一个重要的设计是Kafka不需要故障的节点恢复所有的数据。这是不常见的，复制算法依赖于存储介质在任何故障的情况下都不丢失数据并且不违反一致性原则。这个假设有两个主要的问题。第一，磁盘故障是持久化数据系统中最常见的问题，并且它通常导致数据不完整。第二，即使这不是一个问题，我们也不希望在每一次写入之后都使用fsync来保证一致性，这会使性能下降两三个数量级。我们的协议中允许一个副本重新加入到ISR集合中，在重新加入之前，它需要从新同步在故障时丢失的数据。</p>
<p>Unclean leader election: What if they all die?</p>
<p>Kafka保证的数据不丢失，在至少有一个备份保持同步的情况下。如果一个分区所有的备份的节点都故障，那么就不能提供这个保障了。</p>
<p>但是实践系统中需要一些合理的事情，在所有备份故障时。如果不巧遇上这个问题，去考虑哪些情况会发生是非常重要的。有两种方式去做：</p>
<p>等待一个ISR中的副本恢复并将其选举为新的Leader（期望它拥有所有的数据）。<br>选择第一个副本（无需在ISR中）作为Leader。<br>这是在可用性和一致性之间的权衡。如果我们等待ISR中的备份恢复，那么会在这个期间一直不可用。如果这样的副本被损坏，那么我们将永久性的失效。另一方便，如果使用不在ISR中的备份成为Leader，尽管它可能不包含所有的日志。默认情况下，Kafka使用第二种策略，当所有ISR中的备份不可用时，倾向于选择可能不一致的备份。这个方式可以通过unclean.leader.election.enable配置禁用，在哪些停机时间优于不一致的场景。</p>
<p>这种困境不是kafka特有的, 这存在于任何基于quorum方式的结构中. 例如, 多数投票算法, 如果大多数的服务器都永久性失效了, 你必须选择丢失全部的数据或者接受某一台可能数据不一致的服务器上的数据.</p>
<p>Availability and Durability Guarantees</p>
<p>在向Kafka写入数据时，Producer可以选择是否等待0，1或（-1）个备份响应。注意，这里说的“被所有备份响应”不是说被所有分配的备份响应，默认情况下只的时所有ISR集合中的备份响应。例如，如果一个Topic配置成只需要两个备份，并且一个备份故障了，那么写入一个备份即认为收到了所有响应。但是，如果这个备份也故障了，那么数据会丢失。这样保证了分区的最大可用，但是可能不是那些相对于可用性更需要可靠性的用户的需求。因此，我们提供两种Topic级别的配置，相对于可用性，优先保证可靠性：</p>
<p>禁用unclean leader election；如果所有备份不可用，那么分区保持不可用，直到最近的Leader重新恢复可用。这可能导致不可用，但是不会丢失数据。</p>
<p>配置一个最小的ISR大小；分区只会在满足最小ISR的情况下接受请求，这样可以避免数据只写入一个备份，而这个备份后续故障导致数据丢失。这个配置只在Producer使用acks=all的配置时有效。这个配置在一致性和可用性上做了权衡。更大的ISR提供了更好的一致性，但是降低了可用性，如果同步备份数小于最小ISR配置时将不可用。</p>
<p>Replica Management</p>
<p>以上的讨论都是基于一个日志，即一个Topic的分区考虑的。但是Kafka集群拥有成百上千这样的分区。我们尝试使用轮训的方式来平衡分区，避免高数量的Topic的分区集中在一部分少量的节点上。同样我们要平衡所有Leader分区，这样每个节点上承载的主分区都有一定的比例。</p>
<p>优化Leader的选举过程也是非常重要的，因为这是系统不可用的窗口期。一个直观的实现是，如果一个节点故障了，为这个节点上所有的分区都独立的执行一次选举。代替这种方式，我们选择一个Broker作为Controller，Controller负责一个故障节点影响的所有分区的Leader变更。这样的好处是我们可以批量处理，减少独立选举时大量的通知，这使得大量分区需要选举时变得更快，代价更小。如果Controller故障了，剩余的Broker中会有一个节点成为新的Controller。</p>
<h3 id="Log-Compaction"><a href="#Log-Compaction" class="headerlink" title="Log Compaction"></a>Log Compaction</h3><p>日志压缩确保Kafka会为一个Topic分区数据日志中保留至少message key的最后一个值。它解决了应用crash或系统故障或应用在操作期间重启来重新加载缓存的场景。让我们深入到细节中解释日志压缩是如何工作的。</p>
<p>到屋面位置，我们只说明了在一断时间或达到特定大小的时候丢弃就日志的简单方法。这适用于想日志这样每一条数据都是独立数据的情况。但是重要类别的数据是根据key处理的数据（例如DB中表的变更数据）。</p>
<p>让我们来讨论这样一个具体的流的例子。一个Topic包含了用户email address信息；每一次用户变更邮箱地址，我们都像这个topic发送一条消息，使用用户ID作为primay key。现在我们已经为用户ID为123的用户发送了一些消息，每条消息包含了email address的变更：</p>
<blockquote>
</blockquote>
<p>123 =&gt; <a href="mailto:bill@microsoft.com" target="_blank" rel="noopener">bill@microsoft.com</a><br>123 =&gt; <a href="mailto:bill@gatesfoundation.org" target="_blank" rel="noopener">bill@gatesfoundation.org</a><br>123 =&gt; <a href="mailto:bill@gmail.com" target="_blank" rel="noopener">bill@gmail.com</a></p>
<p>日志压缩为我们提供了更精细的保留机制，至少保存每个key最后一个变更（如123 =&gt; <a href="mailto:bill@gmail.com" target="_blank" rel="noopener">bill@gmail.com</a>）。这样做我们确保了这个日志包含了所有key最后一个值的快照。这样Consumer可以重建状态而不需要保留完成的变更日志。</p>
<p>让我们列一些日志压缩有用的场景，然后看他是如果被使用的。</p>
<ol>
<li><p>DB变更订阅。这是很常见的，一个数据在多个数据系统中，而且其中一个系统是数据库类型的（如RDBMS或KV系统）。例如可能有一个数据库，一个户缓存系统，一个搜索集群，一个Hadoop集群。DB的任何一个变更需要反映到缓存、搜索集群，最终保存到Hadoop中。在这个场景中，你只需要实时系统最新的更新日志。但是如果需要重新加载缓存或恢复宕机的检索节点，就需要完整的数据。</p>
</li>
<li><p>事件源。这是一种应用设计风格，它将查询处理和应用程序设计结合到一起，并使用日志作为程序的主要存储。</p>
</li>
<li><p>高可用日志。一个本地集成程序可以通过变更日志来做到容错，这样另一个程序能够在当前程序故障时继续处理。例如, 像流数据查询例子, 如计数, 汇总或其他的分组操作. 实时系统框架如Samza, 就是为了达到这个目的使用这个特性的。</p>
</li>
</ol>
<p>在这些场景中，主要处理实时的变更，但有时需要重新加载或重新处理时，需要加载所有数据。日志压缩允许使用相同的Topic来支持这些场景，这种日志使用风格在后续的内容中会更详细的描述。</p>
<p>想法很简单，我们有有无限的日志，以上每种情况记录变更日志，我们从一开始就捕获每一次变更。使用这个完整的日志，我们可以通过回放日志来恢复到任何一个时间点的状态。这种假设的情况下，完整的日志是不实际的，对于那些每一行记录会变更多次的系统，即使数据集很小，日志也会无限的增长下去。丢弃旧日志的简单操作可以限制空间的增长，但是无法重建状态——因为旧的日志被丢弃，可能一部分记录的状态会无法重建（这写记录所有的状态变更都在就日志中）。</p>
<p>日志压缩机制是更细粒度的，每个记录都保留的机制，而不是基于时间的粗粒度。这个想法是选择性的删除哪些有更新的变更的记录的日志。这样最终日志至少包含每个key的记录的最后一个状态。</p>
<p>这个策略可以为每个Topic设置，这样一个集群中，可以一部分Topic通过时间和大小保留日志，另外一些可以通过压缩保留。</p>
<p>这个功能的灵感来自于LinkedIn的最古老且最成功的基础设置——一个称为Databus的数据库变更日志缓存系统。不想大多数的日志存储系统，Kafka为了订阅而量身打造，用于线性的快速读写。和Databus不同，Kafka作为真实的存储，压缩日志是非常有用的，在上有数据源不能重放的情况下。</p>
<h4 id="Log-Compaction-Basics"><a href="#Log-Compaction-Basics" class="headerlink" title="Log Compaction Basics"></a>Log Compaction Basics</h4><p>这里是一个展示Kafka日志的逻辑结构的图（每条消息包含了一个offset）：<br><img src="/img/15042400214438.jpg" alt></p>
<p>Log head中包含传统的Kafka日志。它包含了连续的连续的offset和所有的消息。日志压缩增加了处理tail Log的选项。上图展示了日志压缩的的Log tail的情况。tail中的消息保存了初次写入时的offset。即使该offset的消息被压缩，所有offset仍然在日志中是有效的。在这个场景中，无法区分和下一个出现的更高offset的位置。如上面的例子中，36、37、38是属于相同位置的，从他们开始读取日志都将从38开始。</p>
<p>压缩允许删除。一条消息伴随着空的值被认为从日志中删除。这个删除标记将会引起所有之前拥有相同key的消息被移除（包括拥有key相同的新消息），但是删除标记比较特殊，它将在一定周期后被从日志中删除来示范空间。这个时间点被称为“delete retention point”。</p>
<p>压缩操作通过在后台周期性的拷贝日志段来完成。清除操作不会阻塞读取，并且可以被配置不超过一定IO吞吐来避免影响Producer和Consumer。实际的日志段压缩过程有点像如下：<br><img src="/img/15042400375238.jpg" alt></p>
<h4 id="What-guarantees-does-log-compaction-provide"><a href="#What-guarantees-does-log-compaction-provide" class="headerlink" title="What guarantees does log compaction provide?"></a>What guarantees does log compaction provide?</h4><p>日志压缩提供了如下的保证：</p>
<ol>
<li><p>所有跟上消费的Consumer能消费到所有写入的消息；这些消息有连续的序列号。Topic的min.compaction.lag.ms可以用于保证消息写入多久后才会被压缩。这限制了一条消息在Log Head中的最短存在时间。</p>
</li>
<li><p>消息的顺序会被保留。压缩不会重排序消息，只是移除其中一部分。</p>
</li>
<li><p>消息的Offset不会变更。这是消息在日志中的永久标志。</p>
</li>
<li><p>任何从头开始处理日志的Consumer至少会拿到每个key的最终状态。另外，只要Consumer在小于Topic的delete.retention.ms设置（默认24小时）的时间段内到达Log head，将会看到所有删除记录的所有删除标记。换句话说，因为移除删除标记和读取是同事发生的，Consumer可能会因为落后超过delete.retention.ms而导致错过删除标记。</p>
</li>
</ol>
<h4 id="Log-Compaction-Details"><a href="#Log-Compaction-Details" class="headerlink" title="Log Compaction Details"></a>Log Compaction Details</h4><p>日志压缩由Log Cleaner执行，后台线程池重新拷贝日志段，移除那些key存在于Log Head中的记录。每个压缩线程如下工作：</p>
<ol>
<li>选择Log Head相对于Log Head在日志中占更高比例的日志</li>
<li>创建Log Head中每个Key最后一个offset的摘要</li>
<li>从头到尾的拷贝日志，并删除之后日志终于到相同key的记录。新的、干净的日志将会立即被交到到日志中，所以只需要一个额外的日志段空间</li>
<li>Log Head的摘要实际上是一个空间紧凑的哈希表。每个条目使用24个字节。所以如果有8G的整理缓冲区, 则能迭代处理大约366G的日志头部(假设消息大小为1k)。<h4 id="Configuring-The-Log-Cleaner"><a href="#Configuring-The-Log-Cleaner" class="headerlink" title="Configuring The Log Cleaner"></a>Configuring The Log Cleaner</h4></li>
</ol>
<p>Log Cleaner默认启用。这会启动清理的线程池。如果要开始特定Topic的清理功能，可以开启特定的属性：</p>
<blockquote>
</blockquote>
<p>log.cleanup.policy=compact</p>
<p>这个可以通过创建Topic时配置或者之后使用Topic命令实现。</p>
<p>Log Cleaner可以配置保留最小的不压缩的日志头。可以通过配置压缩的延迟时间：</p>
<blockquote>
</blockquote>
<p>log.cleaner.min.compaction.lag.ms</p>
<p>这可以用于保证消息比在被压缩的消息大一段时间。如果没有设置，除了最后一个日志外，所有的日志都会被压缩。当前写入的自如端不会被压缩，即使所有的消息都落后于比配置的最小压缩时间。</p>
<p>更多的配置在<a href="http://kafka.apache.org/documentation.html#brokerconfigs" target="_blank" rel="noopener">这里</a></p>
<h3 id="Quotas"><a href="#Quotas" class="headerlink" title="Quotas"></a>Quotas</h3><p>从0.9版本开始，Kafka可以对生产和消费请求进行限额配置。基于字节速率来限制，每个group中所有的客户端共享一个限额。</p>
<h4 id="Why-are-quotas-necessary"><a href="#Why-are-quotas-necessary" class="headerlink" title="Why are quotas necessary?"></a>Why are quotas necessary?</h4><p>Producer和Consumer可能生产或消费大量的数据而耗尽Broker的资源，导致网络饱和。进行限额可以避免这些问题，特别是在多租户的集群中，一小部分低质量的客户端会降低整个集群的体验。实际上，当运行Kafka作为服务时，这还可以对API的使用进行限制。</p>
<h4 id="Client-groups"><a href="#Client-groups" class="headerlink" title="Client groups"></a>Client groups</h4><p>Kafka客户端的身份代表了用于鉴权。 在无鉴权机制的集群中, 用户身份是由服务器使用可配置的PrincipalBuilder进行选择的, Client-id作为客户端逻辑分组, 是由客户端应用选择的一个有意义的名称. 标量(user, client-id)定义共享这个用户身份和客户端ID的逻辑客户端分组.</p>
<p>配额可以用于(user, client-id)组合, 或user, client-id分组。</p>
<p>对一个给定的连接, 最符合这个连接的配额被使用到, 一个限额组的所有连接共享这个限额配置, 例如: 如果(user=”test-user”, client-id=”test-client”) 10MB/s的配额, 这个配置会被所有的具有”test-user”用户和客户端ID是 “test-client”的所有生产者所共享.</p>
<h4 id="Quota-Configuration"><a href="#Quota-Configuration" class="headerlink" title="Quota Configuration"></a>Quota Configuration</h4><p>配额可以按照(user, client-id)或者, user或client-id进行分组, 如果需要更高或更低的配额, 可以覆盖默配额, 这个机制类似于对日志主题配置的覆盖, user 或者 (user, client-id)配额可以覆盖写入到zookeeper下的 /config/users ,client-id配置, 可以写入到 /config/clients。这些覆盖写入会被服务器很快的读取到, 这让我们修改配置不需要重新启动服务器. 每个分组的默认配置也可以同样的方式动态修改。</p>
<p>限额的配置顺序如下:</p>
<ol>
<li>/config/users//clients/</li>
<li>/config/users//clients/</li>
<li>/config/users/</li>
<li>/config/users//clients/</li>
<li>/config/users//clients/</li>
<li>/config/users/</li>
<li>/config/clients/</li>
<li>/config/clients/<br>Broker的quota.producer.default，quota.consumer.default也可以用来配置默认的client-id分组的默认值。这可属性已经不鼓励使用，后续将会删除。默认client-id限额配置可以和其它默认配置一样, 在Zookeeper直接设置。</li>
</ol>
<h4 id="Enforcement"><a href="#Enforcement" class="headerlink" title="Enforcement"></a>Enforcement</h4><p>默认情况下，每个唯一的客户端group会收到一个集群配置的固定的限额。这个限额是基于每个Broker的。每个客户端能发布或获取在每台服务器都的最大速率, 我们按服务器定义配置, 而不是按整个集群定义,是因为如果是集群范围的需要额外的机制来共享配额的使用情况, 这会导致配额机制的实现比较难。</p>
<p>Broker检测到限额违规时时如何处理的？在我们的解决方案中，Broker不会返回错误给客户端，而是降低客户端的速率。Broker计算使客户端回到合理限额的需要的响应延迟。这种方法的处理对客户端是透明，使他们不必执行任何棘手的，特殊的操作。实际上，错误的客户端还可能加剧正在解决的限额问题。</p>
<p>客户端字节率在多个小窗口（例如每个1秒的30个窗口）上进行测量，以便快速检测和纠正配额违规。 通常，具有大的测量窗口（例如，每个30秒的10个窗口）导致大量的流量脉冲，随后是长时间的延迟，这在用户体验方面不是很好。</p>
<blockquote>
</blockquote>
<p>文章摘自：<a href="http://www.cnblogs.com/hzmark/p/kafka_design.html" target="_blank" rel="noopener">http://www.cnblogs.com/hzmark/p/kafka_design.html</a></p>
<h3 id="参考资料"><a href="#参考资料" class="headerlink" title="参考资料"></a>参考资料</h3><p><a href="http://www.cnblogs.com/hzmark/p/kafka_design.html" target="_blank" rel="noopener">http://www.cnblogs.com/hzmark/p/kafka_design.html</a><br><a href="https://kafka.apache.org/documentation/" target="_blank" rel="noopener">https://kafka.apache.org/documentation/</a></p>
]]></content>
      <categories>
        <category>技术</category>
        <category>消息队列</category>
        <category>Kafka</category>
      </categories>
      <tags>
        <tag>Kafka</tag>
      </tags>
  </entry>
  <entry>
    <title>Kafka官方文档翻译--简介</title>
    <url>/2017/04/21/Kafka%E5%AE%98%E6%96%B9%E6%96%87%E6%A1%A3%E7%BF%BB%E8%AF%91--%E7%AE%80%E4%BB%8B/</url>
    <content><![CDATA[<p>Kafka擅长于做什么？</p>
<p>它被用于两大类应用：</p>
<ol>
<li>在应用间构建实时的数据流通道</li>
<li>构建传输或处理数据流的实时流式应用<a id="more"></a>
</li>
</ol>
<p>几个概念：</p>
<p>Kafka以集群模式运行在1或多台服务器上<br>Kafka以topics的形式存储数据流<br>每一个记录包含一个key、一个value和一个timestamp.</p>
<p>Kafka有4个核心API：</p>
<p>Producer API：用于应用程序将数据流发送到一个或多个Kafka topics<br>Consumer API：用于应用程序订阅一个或多个topics并处理被发送到这些topics中的数据<br>Streams API：允许应用程序作为流处理器，处理来自一个或多个topics的数据并将处理结果发送到一个或多个topics中，有效的将输入流转化为输出流<br>Connector API：用于构建和运行将Kafka topics和现有应用或数据系统连接的可重用的produers和consumers。例如，如链接到关系数据库的连接器可能会捕获某个表所有的变更<br><img src="/img/15042372711680.jpg" alt><br>Kafka客户端和服务端之间的通信是建立在简单的、高效的、语言无关的TCP协议上的。此协议带有版本且向后兼容。我们为Kafka提供了Java客户端，但是客户端可以使用多种语言。</p>
<h2 id="Topics-and-Logs"><a href="#Topics-and-Logs" class="headerlink" title="Topics and Logs"></a>Topics and Logs</h2><p>Topic是发布记录的类别。Kafka中的Topics一般是多订阅者的，也就是一个Topic可以有0个或多个Consumer订阅它的数据。</p>
<p>对于每个主题，Kafka会会维护一个如下所示的分区日志：<br><img src="/img/15042374175690.jpg" alt></p>
<p>每个分区是一个有序的，以不可变的记录顺序追加的Commit Log。分区中的每个记录都有一个连续的ID，称为Offset，唯一标识分区内的记录。</p>
<p>Kafka集群使用记录保存时间的配置来保存所有已发布的记录（无论他们是否被消费）。例如，配置策略为两天，那么在一条记录发布两天内，这条记录是可以被消费的，之后将被丢弃以腾出空间。Kafka的性能和数据量无关，所以存储长时间的数据并不会成为问题。<br><img src="/img/15042374457050.jpg" alt></p>
<p>实际上唯一需要保存的元数据是消费者的消费进度，即消费日志的偏移量（Offset）。这个Offset是由Consumer控制的：通常消费者会在读取记录时以线性方式提升Offset，但是事实上，由于Offset由Consumer控制，因此它可以以任何顺序消费记录。例如一个Consumer可以通过重置Offset来处理过去的数据或者跳过部分数据。</p>
<p>这个特征意味着Kafka的Consumer可以消费“过去”和“将来”的数据而不对集群和其他Consumer不造成太大的影响。例如，可以使用命令行工具tail来获取Topic尾部的内容而不对已经在消费Consumer造成影响。</p>
<p>分区日志有几个目的。第一，使服务器能承载日志的大小，每个分区的日志必须可以被保存在单个服务器上，但是一个Topic可以拥有多个分区，那么它可以处理任意大小的数据量。第二，它们作为并行度的单位（更多的是这点的考虑）。</p>
<h2 id="Distribution"><a href="#Distribution" class="headerlink" title="Distribution"></a>Distribution</h2><p>分区日志分布在集群中服务器中，每个服务器处理一部分分区的数据和请求。每个分区可以配置分布的服务器，以实现容错。</p>
<p>每个分区拥有一个Leader节点，和零或多个Follower。Leader处理该分区所有的读写请求，Follower复制Leader数据。如果Leader节点宕机，将会有一个Follower节点自动的转化为Leader。每个节点成为其部分分区的Leader，并成为剩余分区的Follower，这样整个集群的负载将比较均衡。</p>
<h2 id="Producers"><a href="#Producers" class="headerlink" title="Producers"></a>Producers</h2><p>Producer发送数据到它选择的Topic。Producer负责决定将数据发送到Topic的那个分区上。这可以通过简单的循环方式来平衡负载，或则可以根据某些语义来决定分区（例如基于数据中一些关键字）。</p>
<h2 id="Consumers"><a href="#Consumers" class="headerlink" title="Consumers"></a>Consumers</h2><p>Consumer使用一个group name来标识自己的身份，每条被发送到一个Topic的消息都将被分发到属于同一个group的Consumer的一个实例中（group name相同的Consumer属于一个组，一个Topic的一条消息会被这个组中的一个Consumer实例消费）。Consumer实例可以在单独的进程中或者单独的机器上。</p>
<p>如果所有的Consumer实例都是属于一个group的，那么所有的消息将被均衡的分发给每个实例。</p>
<p>如果所有的Consumer都属于不同的group，那么每条消息将被广播给所有的Consumer。<br><img src="/img/15042374736944.jpg" alt></p>
<p>（上图）一个包含两个Server的Kafka集群，拥有四个分区（P0-P3），有两个Consumer group：Group A和Group B。Group有C1、C2两个Consumer，GroupB有C3、C4、C5、C6四个Consumer。</p>
<p>更常见的是，Topic有少量的Consumer group，每一个都是“一个逻辑上的订阅者”。每个group包含多个Consumer实例，为了可伸缩性和容错性。这就是一个发布-订阅模式，只是订阅方是一个集群。</p>
<p>Kafka中消费的实现方式是“公平”的将分区分配给Consumer，每一个时刻分区都拥有它唯一的消费者。Consumer成员关系有Kafka程度动态维护。如果新的Consumer加入了分区，那么它会从这个分区其他的Consumer中分配走一部分分区；如果部分Consumer实例宕机，它的分区会被其他Consumer实例接管。</p>
<p>Kafka只保证同一个分区内记录的顺序，而不是同一个Topic的不同分区间数据的顺序。每个分区顺序结合按Key分配分区的能力，能满足大多数程序的需求。如果需要全局的顺序，可以使用只有一个分区的Topic，这意味着每个group只能有一个Consumer实例（因为一个分区同一时刻只能被一份Consumer消费——多加的Consumer只能用于容错）。</p>
<h2 id="Guarantees"><a href="#Guarantees" class="headerlink" title="Guarantees"></a>Guarantees</h2><p>Kafka高级API中提供一些能力：</p>
<p>被一个Producer发送到特定Topic分区的消息将按照他们的发送顺序被添加到日志中。这意味着，如果M1、M2是被同一个Producer发送出来的，且M1先发送，那么M1拥有更小的Offset，在日志中的位置更靠前。</p>
<p>Consumer按照消息的存储顺序在日志文件中查找消息。</p>
<p>对于复制配置参数为N的Topic，我们能容忍N-1的服务器故障，而不会丢失已经Commit的数据。有关这些保证更详细的信息，参见文档的设计部分。</p>
<h2 id="Kafka-as-a-Messaging-System"><a href="#Kafka-as-a-Messaging-System" class="headerlink" title="Kafka as a Messaging System"></a>Kafka as a Messaging System</h2><p>Kafka的流模式和传统的消息系统有什么区别？</p>
<p>消息传统上有两种模式：队列和发布-订阅。在队列中，一群Consumer从一个Server读取数据，每条消息被其中一个Consumer读取。在发布-订阅中，消息被广播给所有的Consumer。这两种模式有各自的优缺点。队列模式的优点是你可以在多个消费者实例上分配数据处理，从而允许你对程序进行“伸缩”。确定是队列不是多用户的，一旦消息被一个Consumer读取就不会再给其他Consumer。发布订阅模式允许广播数据到多个Consumer，那么就没办法对单个Consumer进行伸缩。</p>
<p>Kafka的Consumer group包含两个概念。与队列一样，消费组允许通过一些进程来划分处理（每个进程处理一部分）。与发布订阅一样，Kafka允许广播消息到不同的Consumer group。</p>
<p>Kafka模式的优势是每个Topic都拥有队列和发布-订阅两种模式。</p>
<p>Kafka比传统的消息系统有更强的顺序保证。</p>
<p>传统的消息系统在服务器上按顺序保存消息，如果多个Consumer从队列中消费消息，服务器按照存储的顺序输出消息。然后服务器虽然按照顺序输出消息，但是消息将被异步的传递给Consumer，所以他们将以不确定的顺序到达Consumer。这意味着在并行消费中将丢失消息顺序。传统消息系统通常采用“唯一消费者”的概念只让一个Consumer进行消费，但这就丢失了并行处理的能力。</p>
<p>Kafka做的更好一些。通过提供分区的概念，Kafka能提供消费集群顺序和负载的平衡。这是通过将分区分配个一个Consumer group中唯一的一个Consumer而实现的，一个分区只会被一个分组中的一个Consumer进行消费。通过这么实现，能让一个Consumer消费一个分区并按照顺序处理消息。因为存在多个分区，所有可以在多个Consumer实例上实现负载均衡。注意，一个分组内的Consumer实例数不能超过分区数。</p>
<h2 id="Kafka-as-a-Storage-System"><a href="#Kafka-as-a-Storage-System" class="headerlink" title="Kafka as a Storage System"></a>Kafka as a Storage System</h2><p>任何将发送消息和消费结构的消息队列都有效的用作一个消息的存储系统。不同的是Kafka是一个更好的存储系统。</p>
<p>被写入到Kafka的数据将被写入磁盘并复制以保证容错。Kafka允许Producer等待确定，以保证Producer可以确认消息被成功持久化并复制完成。</p>
<p>Kafka使用的存储结构，使其提供相同的能力，无论是存储50KB或者50TB持久化数据。</p>
<p>因为允许客户端控制读取的位置，可以将Kafka视为高性能，低延迟的日志存储、复制、传播的分布式系统。</p>
<h2 id="Kafka-for-Stream-Processing"><a href="#Kafka-for-Stream-Processing" class="headerlink" title="Kafka for Stream Processing"></a>Kafka for Stream Processing</h2><p>仅仅是读写和存储流数据是不够的，Kafka的目标是对流失数据的实时处理。</p>
<p>在Kafka中，Stream Producer从输入的Topic中读取数据，执行一些操作，生成输出流到输出的Topic中。</p>
<p>例如，零售的应用程序将收到销售和出货的输入流，并输出根据该数据计算的重排序和价格调整后的数据流。</p>
<p>可以使用Producer和Consumer实现简单的处理。对于更复杂的转换，Kafka提供的完成的Stream API，允许构建将流中数据聚合或将流连接到一起的应用。</p>
<p>这用于解决以下的一些困难：处理无需的数据，执行有状态的计算等。</p>
<p>Stream API基于Kafka的核心函数构建：使用Producer和Consumer API用于输入，使用Kafka作为有状态的存储，使用group机制来实现Stream处理器的容错。</p>
<h2 id="Putting-the-Pieces-Together"><a href="#Putting-the-Pieces-Together" class="headerlink" title="Putting the Pieces Together"></a>Putting the Pieces Together</h2><p>消息、存储和流处理这种组合看是不寻常，但是Kafka作为流式平台这是必须的。</p>
<p>类似HDFS的分布式文件系统存储静态的文件用于批处理。这种的系统允许存储和处理历史数据。</p>
<p>传统的企业消息系统允许处理在你订阅之后的未来的数据。以这种方式构建的应用程序在未来数据到达时进行处理。</p>
<p>Kafka组合这些能力，并且组合这些对Kafka作为流应用平台和流数据通道至关重要。</p>
<p>通过组合存储和低延迟的订阅，流应用程序能以相同的方式处理过去和未来的数据。一个单一的程序可以处理过去的历史数据，并且不会在达到一个位置时停止，而是能继续处理将来到达的数据。这是一个广泛的流处理的概念，其中包含批处理和消息驱动的应用程序。</p>
<p>同样，对于数据流通道，组合订阅机制和实时事件使Kafka成为非常低延迟的管道；数据的存储能力使其能和可能会进行停机维护的周期性处理数据的离线系统集成，或用于必须保证数据被确认交付的场景。流处理程序可以在数据到达后进行处理。</p>
<p>其他关闭Kafka提供的API、功能，参阅其他文档。</p>
<blockquote>
<p>出处：<a href="http://www.cnblogs.com/hzmark/p/kafka_introduction.html" target="_blank" rel="noopener">http://www.cnblogs.com/hzmark/p/kafka_introduction.html</a></p>
</blockquote>
]]></content>
      <categories>
        <category>技术</category>
        <category>消息队列</category>
        <category>Kafka</category>
      </categories>
      <tags>
        <tag>Kafka</tag>
      </tags>
  </entry>
  <entry>
    <title>ZSH 安装</title>
    <url>/2017/03/29/ZSH-%E5%AE%89%E8%A3%85/</url>
    <content><![CDATA[<p>介绍下比较好用的zsh安装以及相关的配置</p>
<a id="more"></a>
<h2 id="安装iTerm2"><a href="#安装iTerm2" class="headerlink" title="安装iTerm2"></a>安装iTerm2</h2><p>iTerm2官方下载地址 <a href="http://www.iterm2.com/downloads.html" target="_blank" rel="noopener">http://www.iterm2.com/downloads.html</a></p>
<h2 id="安装Oh-My-Bash"><a href="#安装Oh-My-Bash" class="headerlink" title="安装Oh My Bash"></a>安装Oh My Bash</h2><ol>
<li>通过cat /etc/shells命令可以查看当前系统可以使用哪些shell；<ul>
<li>/bin/bash</li>
<li>/bin/csh</li>
<li>/bin/ksh</li>
<li>/bin/sh</li>
<li>/bin/tcsh</li>
<li>/bin/zsh</li>
</ul>
</li>
<li><p>通过echo $SHELL命令可以查看我们当前正在使用的shell；</p>
<ul>
<li>Mac系统中默认的shell为bash shell</li>
<li>/bin/bash</li>
</ul>
</li>
<li><p>如果当前的shell不是zsh，我们可以通过chsh -s /bin/zsh命令可以将shell切换为shell之zsh，终端重启之后即可生效。</p>
</li>
<li><p>将shell切换为zsh之后，我们就可以安装Oh My ZSH了<br>官方推荐的安装方法为：</p>
</li>
</ol>
<p>sh -c “$(curl -fsSL <a href="https://raw.github.com/robbyrussell/oh-my-zsh/master/tools/install.sh)&quot;" target="_blank" rel="noopener">https://raw.github.com/robbyrussell/oh-my-zsh/master/tools/install.sh)&quot;</a></p>
<p>记住，爱翻墙的童鞋记得先关闭代理哦，不然没法下载成功的<br>出线以下提示，便是安装成功了^_^<br><img src="/img/15301540285993.jpg" alt></p>
<h2 id="配置agnoster主题"><a href="#配置agnoster主题" class="headerlink" title="配置agnoster主题"></a>配置agnoster主题</h2><p>Oh My Zsh提供的所有主题在线预览：<br><a href="https://github.com/robbyrussell/oh-my-zsh/wiki/Themes" target="_blank" rel="noopener">https://github.com/robbyrussell/oh-my-zsh/wiki/Themes</a></p>
<p>安装成功之后，我们可以通过vi ~/.zshrc，设置ZSH_THEME=”agnoster”对主题进行修改。</p>
<p>注意，agnoster主题能否设置成功，还依赖于以下东西：</p>
<ol>
<li><p>Solarized Dark配色方案<br>下载完成之后解压，在iTerm2的Preferences——Profiles——colors——Load Presets——Solarized Dark即可设置终端配色</p>
</li>
<li><p>特殊字体安装<br>下载完成之后解压，执行其中的install.sh文件，在iTerm2的Preferences——Profiles——Text中同时将Regular Font和Non—ASCII Font设置为Meslo LG M DZ Regular for Powerline即可</p>
</li>
</ol>
<h2 id="主题列表"><a href="#主题列表" class="headerlink" title="主题列表"></a>主题列表</h2><p><a href="https://github.com/robbyrussell/oh-my-zsh/wiki/themes" target="_blank" rel="noopener">https://github.com/robbyrussell/oh-my-zsh/wiki/themes</a></p>
]]></content>
      <categories>
        <category>工具</category>
      </categories>
      <tags>
        <tag>ZSH</tag>
        <tag>工具</tag>
      </tags>
  </entry>
  <entry>
    <title>RabbitMQ概述</title>
    <url>/2017/02/05/RabbitMQ%E6%A6%82%E8%BF%B0/</url>
    <content><![CDATA[<h2 id="安装"><a href="#安装" class="headerlink" title="安装"></a>安装</h2><p>mac上安装rabbitmq比较简单，参考官网教程 <a href="http://www.rabbitmq.com/install-standalone-mac.html" target="_blank" rel="noopener">http://www.rabbitmq.com/install-standalone-mac.html</a> 即可。遇到了下载很慢问题，找了其他网站上下。</p>
<p>其他系统安装方式在官网也有详细描述，不再累述。</p>
<a id="more"></a>
<h2 id="配置"><a href="#配置" class="headerlink" title="配置"></a>配置</h2><ol>
<li>查找默认配置位置：find / -name “rabbitmq.config.example”，我这边搜索结果是：/usr/share/doc/rabbitmq-server-3.6.1/rabbitmq.config.example</li>
<li>复制默认配置：cp /usr/share/doc/rabbitmq-server-3.6.1/rabbitmq.config.example /etc/rabbitmq/</li>
<li>修改配置文件名：cd /etc/rabbitmq ; mv rabbitmq.config.example rabbitmq.config</li>
<li>开启 Web 界面管理：rabbitmq-plugins enable rabbitmq_management</li>
<li>重启 RabbitMQ 服务：service rabbitmq-server restart</li>
<li>开放防火墙端口：<ul>
<li>sudo iptables -I INPUT -p tcp -m tcp –dport 15672 -j ACCEPT</li>
<li>sudo iptables -I INPUT -p tcp -m tcp –dport 5672 -j ACCEPT</li>
<li>sudo service iptables save</li>
<li>sudo service iptables restart</li>
</ul>
</li>
<li>浏览器访问：<a href="http://localhost:15672" target="_blank" rel="noopener">http://localhost:15672</a> 默认管理员账号：guest 默认管理员密码：guest</li>
</ol>
<p>参考<a href="https://github.com/judasn/Linux-Tutorial/blob/master/RabbitMQ-Install-And-Settings.md" target="_blank" rel="noopener">https://github.com/judasn/Linux-Tutorial/blob/master/RabbitMQ-Install-And-Settings.md</a></p>
<h2 id="核心概念"><a href="#核心概念" class="headerlink" title="核心概念"></a>核心概念</h2><h3 id="Broker"><a href="#Broker" class="headerlink" title="Broker"></a>Broker</h3><p>简单来说就是消息队列服务器</p>
<h3 id="Exchange"><a href="#Exchange" class="headerlink" title="Exchange"></a>Exchange</h3><p>消息交换机，服务器中的实体，用来接收生产者发送的消息并将这些消息路由给服务器中的队列</p>
<h3 id="Queue"><a href="#Queue" class="headerlink" title="Queue"></a>Queue</h3><p>消息队列载体，用来保存消息直到发送给消费者，每个消息都会被投入到一个或多个队列</p>
<h3 id="Binding"><a href="#Binding" class="headerlink" title="Binding"></a>Binding</h3><p>绑定器，它的作用就是把exchange和queue按照路由规则绑定起来</p>
<h3 id="Binding-Key"><a href="#Binding-Key" class="headerlink" title="Binding Key"></a>Binding Key</h3><p>绑定关键字，Exchange视自身类型来决定Binding的路由行为</p>
<h3 id="Routing-Key"><a href="#Routing-Key" class="headerlink" title="Routing Key"></a>Routing Key</h3><p>消息的路由关键字，Exchange根据这个关键字决定如何路由某条消息</p>
<h3 id="vhost"><a href="#vhost" class="headerlink" title="vhost"></a>vhost</h3><p>虚拟主机，一批交换器、消息队列和相关对象，虚拟主机是共享相同的身份认证和加密环境的独立服务器域，一个broker里可以开设多个vhost，用作不同用户的权限分离</p>
<h3 id="Channel"><a href="#Channel" class="headerlink" title="Channel"></a>Channel</h3><p>多路复用连接中的一条独立的双向数据流通道，为会话提供物理传输介质，在客户端的每个连接里，可建立多个channel</p>
<h3 id="Consumer"><a href="#Consumer" class="headerlink" title="Consumer"></a>Consumer</h3><p>消费者，一个从消息队列中请求消息的客户端应用程序</p>
<h3 id="Producer"><a href="#Producer" class="headerlink" title="Producer"></a>Producer</h3><p>生产者，一个向交换器发布消息的客户端应用程序</p>
<h2 id="工作流程"><a href="#工作流程" class="headerlink" title="工作流程"></a>工作流程</h2><p><img src="/img/15255306886088.jpg" alt></p>
<ol>
<li>消息生产者将消息发布(Public)到 Exchange 中.</li>
<li>Exchange 根据队列的绑定关系将消息分发到不同的 Queue 中.</li>
<li>AMQP broker 根据订阅规则将消息发送给消费者 或 消费者自行根据需要从消息队列中获取消息.</li>
</ol>
<p>Message是当前模型中所操纵的基本单位，它由Producer产生，经过Broker被Consumer所消费。它的基本结构有两部分: Header和Body。Header是由Producer添加上的各种属性的集合，这些属性有控制Message是否可被缓存，接收的queue是哪个，优先级是多少等。Body是真正需要传送的数据，它是对Broker不可见的二进制数据流，在传输过程中不应该受到影响。</p>
<h2 id="Exchange-和-Exchange-类型"><a href="#Exchange-和-Exchange-类型" class="headerlink" title="Exchange 和 Exchange 类型"></a>Exchange 和 Exchange 类型</h2><table>
<thead>
<tr>
<th>类型</th>
<th>默认预定义的名字</th>
</tr>
</thead>
<tbody>
<tr>
<td>Direct Exchange</td>
<td>空字符串和 amq.direct</td>
</tr>
<tr>
<td>Fanout Exchange</td>
<td>amq.fanout</td>
</tr>
<tr>
<td>Topic Exchange</td>
<td>amq.topic</td>
</tr>
<tr>
<td>Headers Exchange</td>
<td>amq.match(在 RabbitMQ 中, 额外提供amq.headers)</td>
</tr>
</tbody>
</table>
<h3 id="关于默认-Exchange"><a href="#关于默认-Exchange" class="headerlink" title="关于默认 Exchange"></a>关于默认 Exchange</h3><p>默认的 exchange 是一个由 broker 预创建的匿名的(即名字是空字符串) direct exchagne. 对于简单的程序来说, 默认的 exchange 有一个实用的属性: 如果没有显示地绑定 Exchnge, 那么创建的每个 queue 都会自动绑定到这个默认的 exchagne 中, 并且此时这个 queue 的 route key 就是这个queue 的名字.</p>
<p>例如当我们声明了一个名为 “search-indexing-online” 的 queue, 那么 AMQP broker 会以 “search-indexing-online” 作为 route key 将此 queue 绑定到默认的 exchange 中. 因此当一个消息以 route key 为 “search-indexing-online” 投递到默认的 exchange 中时, 此消息就会被路由到这个 queue 中去. 换句话说, 由于有默认的 exchagne 的存在, 我们就好像可以直接将消息投递到指定的 queue 中去而不需要经过 exchange 一样.</p>
<h2 id="RabbitMQ应用场景"><a href="#RabbitMQ应用场景" class="headerlink" title="RabbitMQ应用场景"></a>RabbitMQ应用场景</h2><p>官网中有很详细的样例，各个语言都有，<a href="http://www.rabbitmq.com/getstarted.html" target="_blank" rel="noopener">http://www.rabbitmq.com/getstarted.html</a> 此处不再说明。</p>
<h2 id="持久化"><a href="#持久化" class="headerlink" title="持久化"></a>持久化</h2><p>服务重启时, 是否能恢复队列中的数据.</p>
<p>考虑这样的场景, 当消息被暂存到队列后, 在没有被提取的情况下, RabbitMQ 服务停掉了怎么办.</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="comment"># -*- coding: utf-8 -*-</span></span><br><span class="line"><span class="keyword">import</span> pika</span><br><span class="line"></span><br><span class="line">connection = pika.BlockingConnection(pika.ConnectionParameters(<span class="string">'localhost'</span>))</span><br><span class="line">channel = connection.channel()</span><br><span class="line">channel.exchange_declare(exchange=<span class="string">'first'</span>, type=<span class="string">'fanout'</span>)</span><br><span class="line">channel.queue_declare(queue=<span class="string">'hello'</span>)</span><br><span class="line">channel.queue_bind(exchange=<span class="string">'first'</span>, queue=<span class="string">'hello'</span>)</span><br><span class="line">channel.basic_publish(exchange=<span class="string">'first'</span>, routing_key=<span class="string">''</span>, body=<span class="string">'Hello World!'</span>)</span><br></pre></td></tr></table></figure>
<p>上面的代码, 我们创建了一条内容为 Hello World! 的消息, 通过命令行工具:</p>
<figure class="highlight shell"><table><tr><td class="code"><pre><span class="line"><span class="meta">$</span>  ./rabbitmqctl list_queues</span><br><span class="line">Listing queues ...</span><br><span class="line">hello    1</span><br><span class="line">...done.</span><br><span class="line"></span><br><span class="line"><span class="meta">$</span> ./rabbitmqctl list_exchanges</span><br><span class="line">Listing exchanges ...</span><br><span class="line">    direct</span><br><span class="line">amq.direct    direct</span><br><span class="line">amq.fanout    fanout</span><br><span class="line">amq.headers    headers</span><br><span class="line">amq.match    headers</span><br><span class="line">amq.rabbitmq.log    topic</span><br><span class="line">amq.rabbitmq.trace    topic</span><br><span class="line">amq.topic    topic</span><br><span class="line">first    fanout</span><br><span class="line">...done.</span><br></pre></td></tr></table></figure>
<p>可以查到, 在名为 hello 的队列中, 有 1 条消息. 有一个类型为 fanout , 名为 first 的交换器.</p>
<p>此时通过 Ctrl-C 或 ./rabbitmqctl stop 把 RabbitMQ 服务停掉, 再重启. 交换器, 队列, 消息都是不会恢复的.</p>
<p>所以, 默认情况下, <strong>消息</strong>, <strong>队列</strong>, <strong>交换器</strong> 都不具有持久化的性质. 如果我们需要持久化功能, 那么在声明的时候就需要配置好.</p>
<p>交换器和队列的持久化性质, 在声明时通过一个 durable 参数即可实现:</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line">channel.exchange_declare(exchange=<span class="string">'first'</span>, type=<span class="string">'fanout'</span>, durable=<span class="literal">True</span>)</span><br><span class="line">channel.queue_declare(queue=<span class="string">'hello'</span>, durable=<span class="literal">True</span>)</span><br></pre></td></tr></table></figure>
<p>这样, 在服务重启之后, first 和 hello 都会恢复. 但是 hello 中的消息不会, 还需要额外配置. 这是 <strong>消息</strong> 的属性的相关内容:</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line">channel.basic_publish(exchange=<span class="string">'first'</span>,</span><br><span class="line">                      routing_key=<span class="string">''</span>,</span><br><span class="line">                      body=<span class="string">'Hello World!'</span>,</span><br><span class="line">                      properties=pika.BasicProperties(</span><br><span class="line">                         delivery_mode = <span class="number">2</span>,<span class="comment"># make message persistent</span></span><br><span class="line">                      ))</span><br></pre></td></tr></table></figure>
<p>这里注意一下, 消息的持久化并不是一个很强的约束, 涉及数据落地的时机, 及系统层面的 <strong>fsync</strong> 等问题, 不要认为消息完全不会丢. 如果要尽可能高地提高消息的持久化的有效性, 还需要配置其它的一些机制, 比如后面会谈到的 <strong>状态反馈</strong> 中的 <strong>confirm mode</strong>.</p>
<p><strong>交换器 , 队列, 消息</strong> 这三者的持久化问题都介绍过了. 前两者是一经声明, 则其性质无法再被更改, 即你不能先声明一个非持久化的队列, 再声明一个持久化的同名队列, 企图修改它, 这是不行的. 你重复声明时, 相关参数需要一致. 当然, 你可以删除它们再重新声明:</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line">channel.queue_delete(queue=<span class="string">'hello'</span>)</span><br><span class="line">channel.exchange_delete(exchange=<span class="string">'first'</span>)</span><br></pre></td></tr></table></figure>
<h2 id="调度策略"><a href="#调度策略" class="headerlink" title="调度策略"></a>调度策略</h2><p>交换器如何把消息给到哪些队列, 是每个队列给一条, 或者把一条消息给多个队列.</p>
<p>我们考虑交换器 Exchange 和队列 Queue 的关系. Exchange 在得到消息后会依据规则把消息投到一个或多个队列当中.</p>
<p>在调度策略方面, 有两个需要了解的地方, 一是交换器的类型(前面我们用的是 fanout), 二是交换器和队列的绑定关系. 在绑定了的前提下, 我们再谈不同类型的交换器的规则. 绑定动作本身也会影响交换器的行为.</p>
<p>交换器的类型, 内置的有四种, 分别是:</p>
<ul>
<li>fanout</li>
<li>direct</li>
<li>topic</li>
<li>headers</li>
</ul>
<p>下面一一介绍.</p>
<h3 id="fanout"><a href="#fanout" class="headerlink" title="fanout"></a>fanout</h3><p>故名思义, fanout 类型的交换器, 其行为是把消息转发给所有绑定的队列上, 就是一个”广播”行为.</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line"># -*- coding: utf-8 -*-</span><br><span class="line"></span><br><span class="line">import pika</span><br><span class="line"></span><br><span class="line">connection = pika.BlockingConnection(pika.ConnectionParameters(&apos;localhost&apos;))</span><br><span class="line">channel = connection.channel()</span><br><span class="line"></span><br><span class="line">channel.exchange_declare(exchange=&apos;first&apos;, type=&apos;fanout&apos;)</span><br><span class="line">channel.queue_declare(queue=&apos;A&apos;)</span><br><span class="line">channel.queue_declare(queue=&apos;B&apos;)</span><br><span class="line">channel.queue_declare(queue=&apos;C&apos;)</span><br><span class="line"></span><br><span class="line">channel.queue_bind(exchange=&apos;first&apos;, queue=&apos;A&apos;)</span><br><span class="line">channel.queue_bind(exchange=&apos;first&apos;, queue=&apos;B&apos;)</span><br><span class="line"></span><br><span class="line">channel.basic_publish(exchange=&apos;first&apos;,</span><br><span class="line">                      routing_key=&apos;&apos;,</span><br><span class="line">                      body=&apos;Hello World!&apos;)</span><br></pre></td></tr></table></figure>
<p>运行 N 次, 通过 rabbitmqctl 可以看到 A 和 B 中就有 N 条消息, 而 C 中没有消息. 因为只有 A 和 B 是绑定到了 first 上的.</p>
<h3 id="direct"><a href="#direct" class="headerlink" title="direct"></a>direct</h3><p>direct 类型的行为是”先匹配, 再投送”. 即在绑定时设定一个 routing_key , 消息的 routing_key 匹配时, 才会被交换器投送到绑定的队列中去</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="comment"># -*- coding: utf-8 -*-</span></span><br><span class="line"></span><br><span class="line"><span class="keyword">import</span> pika</span><br><span class="line"></span><br><span class="line">connection = pika.BlockingConnection(pika.ConnectionParameters(<span class="string">'localhost'</span>))</span><br><span class="line">channel = connection.channel()</span><br><span class="line"></span><br><span class="line">channel.exchange_declare(exchange=<span class="string">'first'</span>, type=<span class="string">'direct'</span>)</span><br><span class="line">channel.queue_declare(queue=<span class="string">'A'</span>)</span><br><span class="line">channel.queue_declare(queue=<span class="string">'B'</span>)</span><br><span class="line"></span><br><span class="line">channel.queue_bind(exchange=<span class="string">'first'</span>, queue=<span class="string">'A'</span>, routing_key=<span class="string">'a'</span>)</span><br><span class="line">channel.queue_bind(exchange=<span class="string">'first'</span>, queue=<span class="string">'B'</span>, routing_key=<span class="string">'b'</span>)</span><br><span class="line"></span><br><span class="line">channel.basic_publish(exchange=<span class="string">'first'</span>,</span><br><span class="line">                      routing_key=<span class="string">'a'</span>,</span><br><span class="line">                      body=<span class="string">'Hello World!'</span>)</span><br></pre></td></tr></table></figure>
<p>A 和 B 虽然都绑定在了类型为 direct 的 first 上, 但是绑定时的 routing_key 不同.</p>
<p>当一个 routing_key 为 a 的消息出来时, 只会被 first 投送到 A 里.</p>
<h3 id="topic"><a href="#topic" class="headerlink" title="topic"></a>topic</h3><p>topic 和 direct 类似, 只是匹配上支持了”模式”, 在”点分”的 routing_key 形式中, 可以使用两个通配符:</p>
<ul>
<li>* 表示一个词.</li>
<li># 表示零个或多个词.</li>
</ul>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="comment"># -*- coding: utf-8 -*-</span></span><br><span class="line"></span><br><span class="line"><span class="keyword">import</span> pika</span><br><span class="line"></span><br><span class="line">connection = pika.BlockingConnection(pika.ConnectionParameters(<span class="string">'localhost'</span>))</span><br><span class="line">channel = connection.channel()</span><br><span class="line"></span><br><span class="line">channel.exchange_declare(exchange=<span class="string">'first'</span>, type=<span class="string">'topic'</span>)</span><br><span class="line">channel.queue_declare(queue=<span class="string">'A'</span>)</span><br><span class="line">channel.queue_declare(queue=<span class="string">'B'</span>)</span><br><span class="line"></span><br><span class="line">channel.queue_bind(exchange=<span class="string">'first'</span>, queue=<span class="string">'A'</span>, routing_key=<span class="string">'a.*.*'</span>)</span><br><span class="line">channel.queue_bind(exchange=<span class="string">'first'</span>, queue=<span class="string">'B'</span>, routing_key=<span class="string">'a.#'</span>)</span><br><span class="line"></span><br><span class="line">channel.basic_publish(exchange=<span class="string">'first'</span>,</span><br><span class="line">                      routing_key=<span class="string">'a'</span>,</span><br><span class="line">                      body=<span class="string">'Hello World!'</span>)</span><br><span class="line"></span><br><span class="line">channel.basic_publish(exchange=<span class="string">'first'</span>,</span><br><span class="line">                      routing_key=<span class="string">'a.b.c'</span>,</span><br><span class="line">                      body=<span class="string">'Hello World!'</span>)</span><br></pre></td></tr></table></figure>
<p>在发出的两条消息当中, a 只会被 a.# 匹配到. 而 a.b.c 会被两个都匹配到.</p>
<p>所以, 最终的结果会是 A 中有一条消息, B 中有两条消息.</p>
<h3 id="headers"><a href="#headers" class="headerlink" title="headers"></a>headers</h3><p>headers 也是根据规则匹配, 相较于 direct 和 topic 固定地使用 routing_key , headers 则是一个自定义匹配规则的类型.</p>
<p>在队列与交换器绑定时, 会设定一组键值对规则, 消息中也包括一组键值对( headers 属性), 当这些键值对有一对, 或全部匹配时, 消息被投送到对应队列.</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="comment"># -*- coding: utf-8 -*-</span></span><br><span class="line"></span><br><span class="line"><span class="keyword">import</span> pika</span><br><span class="line"></span><br><span class="line">connection = pika.BlockingConnection(pika.ConnectionParameters(<span class="string">'localhost'</span>))</span><br><span class="line">channel = connection.channel()</span><br><span class="line"></span><br><span class="line">channel.exchange_declare(exchange=<span class="string">'first'</span>, type=<span class="string">'headers'</span>)</span><br><span class="line">channel.queue_declare(queue=<span class="string">'A'</span>)</span><br><span class="line">channel.queue_declare(queue=<span class="string">'B'</span>)</span><br><span class="line"></span><br><span class="line">channel.queue_bind(exchange=<span class="string">'first'</span>, queue=<span class="string">'A'</span>, arguments=&#123;<span class="string">'a'</span>: <span class="string">'1'</span>&#125;)</span><br><span class="line">channel.queue_bind(exchange=<span class="string">'first'</span>, queue=<span class="string">'B'</span>, arguments=&#123;<span class="string">'b'</span>: <span class="string">'2'</span>, <span class="string">'c'</span>: <span class="number">3</span>, <span class="string">'x-match'</span>: <span class="string">'all'</span>&#125;)</span><br><span class="line"></span><br><span class="line">channel.basic_publish(exchange=<span class="string">'first'</span>,</span><br><span class="line">                      routing_key=<span class="string">''</span>,</span><br><span class="line">                      properties=pika.BasicProperties(</span><br><span class="line">                          headers = &#123;<span class="string">'a'</span>: <span class="string">'2'</span>&#125;,</span><br><span class="line">                      ),</span><br><span class="line">                      body=<span class="string">'Hello World!'</span>)</span><br><span class="line"></span><br><span class="line">channel.basic_publish(exchange=<span class="string">'first'</span>,</span><br><span class="line">                      routing_key=<span class="string">''</span>,</span><br><span class="line">                      properties=pika.BasicProperties(</span><br><span class="line">                          headers = &#123;<span class="string">'a'</span>: <span class="string">'1'</span>, <span class="string">'b'</span>: <span class="string">'2'</span>&#125;,</span><br><span class="line">                      ),</span><br><span class="line">                      body=<span class="string">'Hello World!'</span>)</span><br></pre></td></tr></table></figure>
<p>绑定时, 通过 arguments 参数设定匹配规则, x-match 是一个特殊的规则, 表示需要全部匹配上, 还是只匹配一条:</p>
<ul>
<li>all , 全部匹配.</li>
<li>any , 只匹配一个.</li>
</ul>
<p>消息的 headers 属性会用于规则的匹配.</p>
<p>上面的代码中, 第一条消息不会匹配任何规则. 第二条消息, 匹配到 A , 但是不会匹配到 B (虽然有一条 b:2 ).</p>
<p>最终的结果是, A 中有一条消息, B 中没有消息.</p>
<h2 id="分配策略"><a href="#分配策略" class="headerlink" title="分配策略"></a>分配策略</h2><p>队列面对消费者时, 如何把消息吐出去, 来一个消费者就把消息全给它, 还是只给一条.</p>
<p>调度策略是影响 Exchange 是不是要把消息给 Queue , 而分配策略影响队列如何把消息给 Consuming .</p>
<p>考虑这样的场景: 队列中有多条消息, 每一个消费者取出消息后, 都要花 10 秒来处理它, 处理完一条消息之后才可能再取出一条继续处理. 刚开始只有一个消费者, 过了 2 秒后来了第二个消费者, 此时, 这两个消费者获取消息的行为是一个什么状态?</p>
<p>我们的需求可能是, 当一个消费者来时, 只给它一条消息, 等它再”请求”时, 再给. 或者也可能是, 当有消费者时, 就把目前有的消息全给它(因为不知道是否还有其它的消费者, 所以既然来了一个就让它尽量多处理一些消息).</p>
<p>先产生一些等待处理的消息:</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="comment"># -*- coding: utf-8 -*-</span></span><br><span class="line"></span><br><span class="line"><span class="keyword">import</span> pika</span><br><span class="line"></span><br><span class="line">connection = pika.BlockingConnection(pika.ConnectionParameters(<span class="string">'localhost'</span>))</span><br><span class="line">channel = connection.channel()</span><br><span class="line"></span><br><span class="line">channel.exchange_declare(exchange=<span class="string">'first'</span>, type=<span class="string">'fanout'</span>)</span><br><span class="line">channel.queue_declare(queue=<span class="string">'A'</span>)</span><br><span class="line"></span><br><span class="line">channel.queue_bind(exchange=<span class="string">'first'</span>, queue=<span class="string">'A'</span>)</span><br><span class="line"></span><br><span class="line"><span class="keyword">for</span> i <span class="keyword">in</span> range(<span class="number">10</span>):</span><br><span class="line">    channel.basic_publish(exchange=<span class="string">'first'</span>,</span><br><span class="line">                          routing_key=<span class="string">''</span>,</span><br><span class="line">                          body=str(i))</span><br><span class="line">``` </span><br><span class="line"></span><br><span class="line">然后是消费者的实现:</span><br><span class="line"></span><br><span class="line">```python</span><br><span class="line"><span class="comment"># -*- coding: utf-8 -*-</span></span><br><span class="line"></span><br><span class="line"><span class="keyword">import</span> pika</span><br><span class="line"></span><br><span class="line">connection = pika.BlockingConnection(pika.ConnectionParameters(<span class="string">'localhost'</span>))</span><br><span class="line">channel = connection.channel()</span><br><span class="line">channel.queue_declare(queue=<span class="string">'A'</span>)</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">callback</span><span class="params">(ch, method, properties, body)</span>:</span></span><br><span class="line">    <span class="keyword">import</span> time</span><br><span class="line">    time.sleep(<span class="number">10</span>)</span><br><span class="line">    <span class="keyword">print</span> body</span><br><span class="line"></span><br><span class="line">channel.basic_consume(callback, queue=<span class="string">'A'</span>, no_ack=<span class="literal">True</span>)</span><br><span class="line">channel.start_consuming()</span><br><span class="line">``` </span><br><span class="line"></span><br><span class="line">上面的代码, 是假设处理一条消息需要 <span class="number">10</span> 秒的时间. 但是事实上, 你只要一执行代码, 马上再使用 rabbitmqctl 查看队列状态时, 会发现队列已经空了. 因为在关闭 ack 的情况下, Queue 的行为是, 一旦有消费者请求, 那么当前队列中的消息它都会一次性吐很多出去.</span><br><span class="line"></span><br><span class="line">ack 机制在后面 状态反馈 会介绍到, 简单来说是一种确认消息被正确处理的机制.</span><br><span class="line"></span><br><span class="line">如果我们想一次只吐一条消息, 当其它消费者连上来时, 还可以并行处理, 简单地把 ack 打开就可以了(默认就是打开的).</span><br><span class="line"></span><br><span class="line">再考虑一下细节. 当有多个消费者连上时, 它是从队列一次取一条消息, 还是一次取多条消息(这样至少可以改善性能). 这可以通过配置 channel 的 qos 相关参数实现:</span><br><span class="line"></span><br><span class="line">```python</span><br><span class="line"><span class="comment"># -*- coding: utf-8 -*-importpika</span></span><br><span class="line"></span><br><span class="line">connection = pika.BlockingConnection(pika.ConnectionParameters(<span class="string">'localhost'</span>))</span><br><span class="line">channel = connection.channel()</span><br><span class="line">channel.queue_declare(queue=<span class="string">'A'</span>)</span><br><span class="line">channel.basic_qos(prefetch_count=<span class="number">2</span>)</span><br><span class="line"></span><br><span class="line">defcallback(ch, method, properties, body):</span><br><span class="line">    importtime</span><br><span class="line">    time.sleep(<span class="number">10</span>)</span><br><span class="line">    <span class="keyword">print</span> body</span><br><span class="line">    ch.basic_ack(delivery_tag = method.delivery_tag)</span><br><span class="line"></span><br><span class="line">channel.basic_consume(callback, queue=<span class="string">'A'</span>, no_ack=<span class="literal">False</span>)</span><br><span class="line">channel.start_consuming()</span><br></pre></td></tr></table></figure>
<p>通过配置 prefetch_count 参数, 来设置一次从队列中取多少条消息. 要看到效果, 至少需要启 2 个消费者.</p>
<p>之前是 10 个数字按顺序入了队列, channel 的配置是一次取 2 个, 那么启 2 个消费者的话, 过 10 秒, 在两个消费者的输出中分别能看到 0 , 2 . 这时把两个消费者都 Ctrl-C , 通过 rabbitmqctl 能看到 A 队列中还有 8 条消息.</p>
<h2 id="状态反馈"><a href="#状态反馈" class="headerlink" title="状态反馈"></a>状态反馈</h2><p>当消息从某一个队列中被提出后, 这个消息的生命周期就此结束, 还是说需要一个具体的信号以明确标识消息已被正确处理.</p>
<p>状态反馈 的功能目的是为了确认行为的结果. 比如, 当你向 Exchange 提交一个消息时, 这个消息是否提交成功, 是否送达到了队列中. 当你从队列中提取消息之后, RabbitMQ 的 Server 如何处理, 因为在提取消息之后, Consuming 可能判断消息有问题, 可能在处理的过程中出现了异常.</p>
<p>在一些关键的节点上, 要保证消息的正确处理, 安全处理, 是需要很多细节上的控制的. AMQP 协议本身也为此作了相关设计, 甚至是事务机制. 事实上在 AMQP 中要确保消息的业务可靠性只能使用事务, 不过在 RabbitMQ 中有一些相应的简便的扩展机制来达到同样目的.</p>
<h3 id="信息发布的确认"><a href="#信息发布的确认" class="headerlink" title="信息发布的确认"></a>信息发布的确认</h3><p>回看一下之前的一段代码:</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line">channel.basic_publish(exchange=<span class="string">'first'</span>, routing_key=<span class="string">''</span>, body=<span class="string">'Hello World!'</span>)</span><br></pre></td></tr></table></figure>
<p>这段代码要做的事, 是把一条消息发给名为 first 的交换器. 这个过程中可能出现意外:</p>
<ul>
<li>exchange 的名字写错了.</li>
<li>exchange 得到消息后, 发现没有对应的 queue 可以投送.</li>
<li>投送到 queue 后当前没有消费者来提取它.</li>
</ul>
<p>上面的三种情况, 第一种, 会直接引发一个调用错误. 第三种, 通常不是问题, 反正消息会在 queue 中暂存. 但是第二种情况很多时候是需要避免的, 否则消息就丢失了, 更严重的是 Producing 对此浑然不知.</p>
<p>在这个地方, 我们就需要确认消息发出之后, 是否成功地被投送到 queue 中去了(或者知道它不能被投送到任何 queue 中去).</p>
<p>要确认这些状态信息, 首先需要把 channel 设置到 confirm mode , 也称之为 Publisher Acknowledgements 机制 (和消息的 ack 机制区分开). 它的目的就是为了确认 Producing 发出的信息的状态.</p>
<p>打开 confirm mode 的方法是:</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line">channel.confirm_delivery()</span><br></pre></td></tr></table></figure>
<p>之后的 publish 行为就可以收到服务器的反馈. 比如在 basic_publish 函数中, 通过 mandatory=True 参数来确认发出的消息是否有 queue 接收, 并且所有 queue 都成功接收.</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">import</span> pika</span><br><span class="line"></span><br><span class="line">connection = pika.BlockingConnection(pika.ConnectionParameters(<span class="string">'localhost'</span>))</span><br><span class="line">channel = connection.channel()</span><br><span class="line"></span><br><span class="line">channel.exchange_declare(exchange=<span class="string">'first'</span>, type=<span class="string">'fanout'</span>)</span><br><span class="line">channel.queue_declare(queue=<span class="string">'A'</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment">#channel.queue_bind(exchange='first', queue='A')</span></span><br><span class="line"></span><br><span class="line">channel.confirm_delivery()</span><br><span class="line"></span><br><span class="line">r = channel.basic_publish(exchange=<span class="string">'first'</span>,</span><br><span class="line">                          routing_key=<span class="string">''</span>,</span><br><span class="line">                          body=<span class="string">'Hello'</span>,</span><br><span class="line">                          mandatory=<span class="literal">True</span>,</span><br><span class="line">                         )</span><br><span class="line"><span class="keyword">print</span> r</span><br></pre></td></tr></table></figure>
<p>上面的代码中, 因为名为 first 的 Exchange 没有绑定任何的 queue , 在 mandatory 参数的作用下, basic_publish 会返回 False .</p>
<p>对于持久化性质, confirm mode 的确认结果是表示, 一条 persisting 的消息, 投送给一个 durable 的队列成功, 并且数据已经成功写到磁盘. 当然, 因为系统缓存的问题, 为确保数据成功落地, 得到确认信息有时可能需要长达几百毫秒的时间, 应用对此应该有所准备, 而不至于在性能上受此影响.</p>
<h3 id="消息提取的确认"><a href="#消息提取的确认" class="headerlink" title="消息提取的确认"></a>消息提取的确认</h3><p>在未关闭消息的 ack 机制的情况下, 当消息被 Consuming 从队列中提取后, 在未明确获取确认信息之前, 队列中的消息是不会被删除的. 这样, 流程上就变成, 当消息被提取之后, 队列中的这条消息处于”等待确认”的状态. 如果 Consuming 反馈”成功”给队列, 则消息可以安全地被删除了. 如果反馈”拒绝”给队列, 则消息可能还需要再次被其它 Consuming 提取.</p>
<p>看下面的例子, 我们先创建顺序的 10 个数字为内容的 10 条消息:</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="comment"># -*- coding: utf-8 -*-</span></span><br><span class="line"></span><br><span class="line"><span class="keyword">import</span> pika</span><br><span class="line"></span><br><span class="line">connection = pika.BlockingConnection(pika.ConnectionParameters(<span class="string">'localhost'</span>))</span><br><span class="line">channel = connection.channel()</span><br><span class="line"></span><br><span class="line">channel.exchange_declare(exchange=<span class="string">'first'</span>, type=<span class="string">'fanout'</span>)</span><br><span class="line">channel.queue_declare(queue=<span class="string">'A'</span>)</span><br><span class="line"></span><br><span class="line">channel.queue_bind(exchange=<span class="string">'first'</span>, queue=<span class="string">'A'</span>)</span><br><span class="line"></span><br><span class="line"><span class="keyword">for</span> i <span class="keyword">in</span> range(<span class="number">10</span>):</span><br><span class="line">    channel.basic_publish(exchange=<span class="string">'first'</span>, routing_key=<span class="string">''</span>, body=str(i))</span><br></pre></td></tr></table></figure>
<p>提取消息的逻辑:</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="comment"># -*- coding: utf-8 -*-</span></span><br><span class="line"></span><br><span class="line"><span class="keyword">import</span> pika</span><br><span class="line"></span><br><span class="line">connection = pika.BlockingConnection(pika.ConnectionParameters(<span class="string">'localhost'</span>))</span><br><span class="line">channel = connection.channel()</span><br><span class="line">r = channel.basic_get(queue=<span class="string">'A'</span>, no_ack=<span class="literal">False</span>) <span class="comment">#0</span></span><br><span class="line"><span class="keyword">print</span> r[<span class="number">-1</span>], r[<span class="number">0</span>].delivery_tag</span><br></pre></td></tr></table></figure>
<p>上面的代码会提取第一条消息, 但是并没有向 Queue 反馈此消息是否被正确处理, 所以这条消息在队列中仍然存在, 直到 Connection 被释放后, 被提取过但是未被确认的消息的状态被重置, 它就可以被重新提取.</p>
<p>要确认消息, 或者拒绝消息, 使用对应的 basic_ack 和 baskc_reject 方法:</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="comment"># -*- coding: utf-8 -*-</span></span><br><span class="line"></span><br><span class="line"><span class="keyword">import</span> pika</span><br><span class="line"></span><br><span class="line">connection = pika.BlockingConnection(pika.ConnectionParameters(<span class="string">'localhost'</span>))</span><br><span class="line">channel = connection.channel()</span><br><span class="line">r = channel.basic_get(queue=<span class="string">'A'</span>, no_ack=<span class="literal">False</span>) <span class="comment">#0</span></span><br><span class="line"><span class="keyword">print</span> r[<span class="number">-1</span>], r[<span class="number">0</span>].delivery_tag</span><br><span class="line"><span class="comment">#channel.basic_ack(delivery_tag=r[0].delivery_tag)</span></span><br><span class="line">channel.basic_reject(delivery_tag=r[<span class="number">0</span>].delivery_tag)</span><br></pre></td></tr></table></figure>
<p>AMQP 协议中, 只提供了 reject 方法, 它只能处理一条消息. 因为 Consuming 是可以一次性提取多条消息的, 所以 RabbitMQ 为此做了扩展, 提供了 basic_nack 方法, 它和 basic_reject 的唯一区别就是支持一次性拒绝多条消息.</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="comment"># -*- coding: utf-8 -*-</span></span><br><span class="line"></span><br><span class="line"><span class="keyword">import</span> pika</span><br><span class="line"></span><br><span class="line">connection = pika.BlockingConnection(pika.ConnectionParameters(<span class="string">'localhost'</span>))</span><br><span class="line">channel = connection.channel()</span><br><span class="line">r = channel.basic_get(queue=<span class="string">'A'</span>, no_ack=<span class="literal">False</span>) <span class="comment">#0</span></span><br><span class="line">r = channel.basic_get(queue=<span class="string">'A'</span>, no_ack=<span class="literal">False</span>) <span class="comment">#1</span></span><br><span class="line">r = channel.basic_get(queue=<span class="string">'A'</span>, no_ack=<span class="literal">False</span>) <span class="comment">#2</span></span><br><span class="line">channel.basic_nack(delivery_tag=r[<span class="number">0</span>].delivery_tag, multiple=<span class="literal">True</span>)</span><br></pre></td></tr></table></figure>
<p>delivery_tag 是在 channel 中的一个消息计数, 每次消息提取行为都对应一个数字. nack 的 multiple 机制会自动把不大于指定 delivery_tag 的消息提取都 reject 掉.</p>
<p>在 reject 和 nack 中还有一个 requeue 参数, 表示被拒绝的消息是否可以被重新分配. 默认是 True . 如果消息被 reject 之后, 不希望再被其它的 Consuming 得到, 可以把 requeue 参数设置成 False :</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="comment"># -*- coding: utf-8 -*-</span></span><br><span class="line"></span><br><span class="line"><span class="keyword">import</span> pika</span><br><span class="line"></span><br><span class="line">connection = pika.BlockingConnection(pika.ConnectionParameters(<span class="string">'localhost'</span>))</span><br><span class="line">channel = connection.channel()</span><br><span class="line">r = channel.basic_get(queue=<span class="string">'A'</span>, no_ack=<span class="literal">False</span>) <span class="comment">#0</span></span><br><span class="line">channel.basic_nack(delivery_tag=r[<span class="number">0</span>].delivery_tag, multiple=<span class="literal">False</span>, requeue=<span class="literal">False</span>)</span><br></pre></td></tr></table></figure>
<p>basic_consume 和 basic_get 都是从指定 queue 中提取消息, 前者是一个更高层的方法, 还支持 qos 等.</p>
]]></content>
      <categories>
        <category>技术</category>
        <category>消息队列</category>
        <category>RabbitMQ</category>
      </categories>
      <tags>
        <tag>消息队列</tag>
        <tag>RabbitMQ</tag>
      </tags>
  </entry>
  <entry>
    <title>spring事务管理</title>
    <url>/2016/11/23/spring%E4%BA%8B%E5%8A%A1%E7%AE%A1%E7%90%86/</url>
    <content><![CDATA[<h2 id="事务是什么"><a href="#事务是什么" class="headerlink" title="事务是什么"></a>事务是什么</h2><p>弄清spring事务管理机制，首先要弄清什么是事务。<br>人们创建了一个术语来表示事务：ACID。ACID代表四个特性，相信大家都很熟悉，但我也要贴出来。</p>
<blockquote>
<p>原子性：一个事务（transaction）中的所有操作，要么全部完成，要么全部不完成，不会结束在中间某个环节。事务在执行过程中发生错误，会被回滚（Rollback）到事务开始前的状态，就像这个事务从来没有执行过一样。</p>
</blockquote>
<blockquote>
<p>一致性：在事务开始之前和事务结束以后，数据库的完整性没有被破坏。这表示写入的资料必须完全符合所有的预设规则，这包含资料的精确度、串联性以及后续数据库可以自发性地完成预定的工作。</p>
</blockquote>
<blockquote>
<p>隔离性：数据库允许多个并发事务同时对齐数据进行读写和修改的能力，隔离性可以防止多个事务并发执行时由于交叉执行而导致数据的不一致。事务隔离分为不同级别，包括读未提交（Read uncommitted）、读提交（read committed）、可重复读（repeatable read）和串行化（Serializable）。</p>
</blockquote>
<blockquote>
<p>持久性：事务处理结束后，对数据的修改就是永久的，即便系统故障也不会丢失。</p>
</blockquote>
<p>（以上内容来自维基百科）</p>
<p>但ACID还是太过抽象，事务到底是怎么创建出来的？下面通过具体的代码来描述下。</p>
<a id="more"></a>
<h2 id="如何开启事务"><a href="#如何开启事务" class="headerlink" title="如何开启事务"></a>如何开启事务</h2><p>mysql中默认是自动提交事务的，可以通过</p>
<figure class="highlight sql"><table><tr><td class="code"><pre><span class="line"><span class="keyword">set</span> autocommit = <span class="number">0</span>;</span><br></pre></td></tr></table></figure>
<p>关闭自动提交。</p>
<p>或者通过</p>
<figure class="highlight sql"><table><tr><td class="code"><pre><span class="line"><span class="keyword">begin</span>;</span><br></pre></td></tr></table></figure>
<p>显示指定开启一个事务。</p>
<p><strong><em>这是什么意思呢？</em></strong><br>不特殊指定，<strong>每条DML语句都是个事务</strong>；若指定了begin，则遇到commit或ddl语句事务结束。<br>现在就很清楚了，原来事务是这样产生的，原来这就是一个事务。<br>那多个事务如何协同工作？有的事务是查找，有的是删除，根据acid特性，事务间是有隔离性的，那到底要隔离到什么程度呢？并发的事务如何相互影响？<br>这就牵扯出了另外一个经典话题——</p>
<h2 id="事务隔离级别"><a href="#事务隔离级别" class="headerlink" title="事务隔离级别"></a>事务隔离级别</h2><blockquote>
<p>可序列化(Serializable)<br>最高的隔离级别。在基于锁机制并发控制的DBMS实现可序列化，要求在选定对象上的读锁和写锁保持直到事务结束后才能释放。在SELECT 的查询中使用一个“WHERE”子句来描述一个范围时应该获得一个“范围锁(range-locks)”。这种机制可以避免“幻影读(phantom reads)”现象（详见下文）。当采用不基于锁的并发控制时不用获取锁。但当系统探测到几个并发事务有“写冲突”的时候，只有其中一个是允许提交的。这种机制的详细描述见“快照隔离”</p>
</blockquote>
<blockquote>
<p>可重复读(Repeatable reads)<br>在可重复读(REPEATABLE READS)隔离级别中，基于锁机制并发控制的DBMS需要对选定对象的读锁(read locks)和写锁(write locks)一直保持到事务结束，但不要求“范围锁(range-locks)”，因此可能会发生“幻读(phantom reads)”。</p>
</blockquote>
<blockquote>
<p>提交读(Read committed)<br>在提交读(READ COMMITTED)级别中，基于锁机制并发控制的DBMS需要对选定对象的写锁(write locks)一直保持到事务结束，但是读锁(read locks)在SELECT操作完成后马上释放（因此“不可重复读”现象可能会发生，见下面描述）。和前一种隔离级别一样，也不要求“范围锁(range-locks)”。</p>
</blockquote>
<blockquote>
<p>未提交读(Read uncommitted)<br>未提交读(READ UNCOMMITTED)是最低的隔离级别。允许脏读(dirty reads)，事务可以看到其他事务“尚未提交”的修改。</p>
</blockquote>
<blockquote>
<p>通过比低一级的隔离级别要求更多的限制，高一级的级别提供更强的隔离性。标准允许事务运行在更强的事务隔离级别上。(如在可重复读(REPEATABLE READS)隔离级别上执行提交读(READ COMMITTED)的事务是没有问题的)</p>
</blockquote>
<p>（以上内容来自维基百科.)</p>
<p>不同的隔离级别并发时产生的结果也不一样。mysql中默认的隔离级别是 可重复读，在这个隔离级别下，同一个事务内多次读得到的结果是一样的，即使有其他事务删除了数据，仍不影响读事务的结果。</p>
<p>下面我们就以可重复读为例，看看事务是否是可重复读的。</p>
<h3 id="验证可重复读"><a href="#验证可重复读" class="headerlink" title="验证可重复读"></a>验证可重复读</h3><h4 id="在表中预置两条数据"><a href="#在表中预置两条数据" class="headerlink" title="在表中预置两条数据"></a>在表中预置两条数据</h4><table>
<thead>
<tr>
<th>id</th>
<th>tenant_id</th>
<th>modify_time</th>
</tr>
</thead>
<tbody>
<tr>
<td>4</td>
<td>2</td>
<td>2016-11-16 17:06:25</td>
</tr>
<tr>
<td>8</td>
<td>1</td>
<td>2016-11-16 17:06:25</td>
</tr>
</tbody>
</table>
<h4 id="开启查询事务-事务A"><a href="#开启查询事务-事务A" class="headerlink" title="开启查询事务(事务A)"></a>开启查询事务(事务A)</h4><figure class="highlight sql"><table><tr><td class="code"><pre><span class="line"><span class="keyword">begin</span>;</span><br><span class="line"><span class="keyword">select</span> * <span class="keyword">from</span> tenant;</span><br></pre></td></tr></table></figure>
<table>
<thead>
<tr>
<th>id</th>
<th>tenant_id</th>
<th>modify_time</th>
</tr>
</thead>
<tbody>
<tr>
<td>4</td>
<td>2</td>
<td>2016-11-16 17:06:25</td>
</tr>
<tr>
<td>8</td>
<td>1</td>
<td>2016-11-16 17:06:25</td>
</tr>
</tbody>
</table>
<p>可以看到此时表中仍有两条数据。</p>
<h4 id="另启一个删除事务（事务B）"><a href="#另启一个删除事务（事务B）" class="headerlink" title="另启一个删除事务（事务B）"></a>另启一个删除事务（事务B）</h4><p>由于mysql每个dml语句都是自动提交的，这里我们直接写delete语句即可：</p>
<figure class="highlight sql"><table><tr><td class="code"><pre><span class="line"><span class="keyword">delete</span> <span class="keyword">from</span> tenant <span class="keyword">where</span> tenant_id = <span class="number">1</span>;</span><br><span class="line"><span class="keyword">select</span> * <span class="keyword">from</span> tenant;</span><br></pre></td></tr></table></figure>
<table>
<thead>
<tr>
<th>id</th>
<th>tenant_id</th>
<th>modify_time</th>
</tr>
</thead>
<tbody>
<tr>
<td>4</td>
<td>2</td>
<td>2016-11-16 17:06:25</td>
</tr>
</tbody>
</table>
<p>可以看到tenant_id为1的记录已经被删除，表中只剩下一条记录。</p>
<h4 id="回到事务A查看表中记录"><a href="#回到事务A查看表中记录" class="headerlink" title="回到事务A查看表中记录"></a>回到事务A查看表中记录</h4><p>还记得事务A第一次查询时有两条记录么？现在表中数据已经被删除了一条，按照“可重复读”的隔离级别，在事务A中再次执行select操作，看到的应该还是两条记录，执行下看看</p>
<figure class="highlight sql"><table><tr><td class="code"><pre><span class="line"><span class="keyword">select</span> * <span class="keyword">from</span> tenant;</span><br></pre></td></tr></table></figure>
<table>
<thead>
<tr>
<th>id</th>
<th>tenant_id</th>
<th>modify_time</th>
</tr>
</thead>
<tbody>
<tr>
<td>4</td>
<td>2</td>
<td>2016-11-16 17:06:25</td>
</tr>
<tr>
<td>8</td>
<td>1</td>
<td>2016-11-16 17:06:25</td>
</tr>
</tbody>
</table>
<p>果然，和第一次的select结果相同。</p>
<p>看到没，就是这么神奇。事务B虽然已经把tenant_id为1的记录删除了，但事务A仍然可以看到那条记录，就好像事务A完全不知道有事务B，丝毫没受事务B的影响。</p>
<p>这是“可重复读”隔离级别下的结果，大家可以去验证下“读以提交”的结果。</p>
<h4 id="提交事务A再查"><a href="#提交事务A再查" class="headerlink" title="提交事务A再查"></a>提交事务A再查</h4><figure class="highlight sql"><table><tr><td class="code"><pre><span class="line"><span class="keyword">commit</span>;</span><br><span class="line"><span class="keyword">select</span> * <span class="keyword">from</span> tenant_wechat_auth;</span><br></pre></td></tr></table></figure>
<table>
<thead>
<tr>
<th>id</th>
<th>tenant_id</th>
<th>modify_time</th>
</tr>
</thead>
<tbody>
<tr>
<td>4</td>
<td>2</td>
<td>2016-11-16 17:06:25</td>
</tr>
</tbody>
</table>
<p>提交之后事务结束，然后再次查询时就看不到已经被删除的记录了。</p>
<p>如此下来，不禁要问，mysql是如何做到的？<br>这里就引出了另外一个经典方案——</p>
<h3 id="MVCC"><a href="#MVCC" class="headerlink" title="MVCC"></a>MVCC</h3><p>mysql给每个表隐含加了两列：创建版本号，结束版本号。<br>mysql每当新开启一个事务时，事务版本号会自动递增。事务开始时刻的系统版本号会作为事务的版本号，用来喝查询到的每行记录的版本号进行比较。</p>
<p>在“可重复读”隔离级别下的mcvv的具体操作：</p>
<blockquote>
<p>SELECT<br>InnoDB会根据以下两个条件检查每条记录：<br>a.InnoDB只查找版本遭遇当前事务版本的数据行（也就是，行的系统版本号小于或等于事务的系统版本号），这样可以确保事务读取的行，要么是在事务开始前已经存在的，要么是事务自身插入或者修改过的。<br>b.行的删除版本要么未定义，要么大于当前事务版本号。这样可以确保事务读取到的行，在事务开始之前未被删除。<br>INSERT<br>InnoDB为新插入的每一行保存当前系统版本号座位行版本号。<br>DELETE<br>InnoDB为删除的每一行保存当前系统版本号座位删除标识。<br>UPDATE<br>InnoDB为插入一行新纪录，保存当前系统版本号作为行版本号，同时保存当前系统版本号到原来的行作为删除标识。</p>
</blockquote>
<p>（以上内容来自《高性能MYSQL》）</p>
<p>所以这就很好解释了我们的结果（结果自己分析下吧，看我写的分析过程的时间自己完全可以分析出来）。</p>
<h2 id="spring事务管理机制"><a href="#spring事务管理机制" class="headerlink" title="spring事务管理机制"></a>spring事务管理机制</h2><p>前面弄清了什么是事务，下面就可以谈一下spring是如何管理事务了。</p>
<h3 id="spring中事务属性"><a href="#spring中事务属性" class="headerlink" title="spring中事务属性"></a>spring中事务属性</h3><figure class="highlight java"><table><tr><td class="code"><pre><span class="line"><span class="keyword">public</span> <span class="class"><span class="keyword">interface</span> <span class="title">TransactionDefinition</span></span>&#123;</span><br><span class="line">    <span class="function"><span class="keyword">int</span> <span class="title">getIsolationLevel</span><span class="params">()</span></span>;</span><br><span class="line">    <span class="function"><span class="keyword">int</span> <span class="title">getPropagationBehavior</span><span class="params">()</span></span>;</span><br><span class="line">    <span class="function"><span class="keyword">int</span> <span class="title">getTimeout</span><span class="params">()</span></span>;</span><br><span class="line">    <span class="function"><span class="keyword">boolean</span> <span class="title">isReadOnly</span><span class="params">()</span></span>;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<p>也许你会奇怪，为什么接口只提供了获取属性的方法，而没有提供相关设置属性的方法。其实道理很简单，事务属性的设置完全是程序员控制的，因此程序员可以自定义任何设置属性的方法，而且保存属性的字段也没有任何要求。唯一的要求的是，Spring 进行事务操作的时候，通过调用以上接口提供的方法必须能够返回事务相关的属性取值。</p>
<h3 id="事务隔离级别-1"><a href="#事务隔离级别-1" class="headerlink" title="事务隔离级别"></a>事务隔离级别</h3><p>隔离级别是指若干个并发的事务之间的隔离程度。TransactionDefinition 接口中定义了五个表示隔离级别的常量：</p>
<ul>
<li>TransactionDefinition.ISOLATION_DEFAULT：这是默认值，表示使用底层数据库的默认隔离级别。对大部分数据库而言，通常这值就是TransactionDefinition.ISOLATION_READ_COMMITTED。</li>
<li>TransactionDefinition.ISOLATION_READ_UNCOMMITTED：该隔离级别表示一个事务可以读取另一个事务修改但还没有提交的数据。该级别不能防止脏读和不可重复读，因此很少使用该隔离级别。</li>
<li>TransactionDefinition.ISOLATION_READ_COMMITTED：该隔离级别表示一个事务只能读取另一个事务已经提交的数据。该级别可以防止脏读，这也是大多数情况下的推荐值。</li>
<li>TransactionDefinition.ISOLATION_REPEATABLE_READ：该隔离级别表示一个事务在整个过程中可以多次重复执行某个查询，并且每次返回的记录都相同。即使在多次查询之间有新增的数据满足该查询，这些新增的记录也会被忽略。该级别可以防止脏读和不可重复读。</li>
<li>TransactionDefinition.ISOLATION_SERIALIZABLE：所有的事务依次逐个执行，这样事务之间就完全不可能产生干扰，也就是说，该级别可以防止脏读、不可重复读以及幻读。但是这将严重影响程序的性能。通常情况下也不会用到该级别。</li>
</ul>
<h3 id="事务传播行为"><a href="#事务传播行为" class="headerlink" title="事务传播行为"></a>事务传播行为</h3><p>所谓事务的传播行为是指，如果在开始当前事务之前，一个事务上下文已经存在，此时有若干选项可以指定一个事务性方法的执行行为。在TransactionDefinition定义中包括了如下几个表示传播行为的常量：</p>
<ul>
<li>TransactionDefinition.PROPAGATION_REQUIRED：如果当前存在事务，则加入该事务；如果当前没有事务，则创建一个新的事务。</li>
<li>TransactionDefinition.PROPAGATION_REQUIRES_NEW：创建一个新的事务，如果当前存在事务，则把当前事务挂起。</li>
<li>TransactionDefinition.PROPAGATION_SUPPORTS：如果当前存在事务，则加入该事务；如果当前没有事务，则以非事务的方式继续运行。</li>
<li>TransactionDefinition.PROPAGATION_NOT_SUPPORTED：以非事务方式运行，如果当前存在事务，则把当前事务挂起。</li>
<li>TransactionDefinition.PROPAGATION_NEVER：以非事务方式运行，如果当前存在事务，则抛出异常。</li>
<li>TransactionDefinition.PROPAGATION_MANDATORY：如果当前存在事务，则加入该事务；如果当前没有事务，则抛出异常。</li>
<li>TransactionDefinition.PROPAGATION_NESTED：如果当前存在事务，则创建一个事务作为当前事务的嵌套事务来运行；如果当前没有事务，则该取值等价于TransactionDefinition.PROPAGATION_REQUIRED。</li>
</ul>
<p>这里需要指出的是，前面的六种事务传播行为是 Spring 从 EJB 中引入的，他们共享相同的概念。而 PROPAGATION_NESTED是 Spring 所特有的。以 PROPAGATION_NESTED 启动的事务内嵌于外部事务中（如果存在外部事务的话），此时，内嵌事务并不是一个独立的事务，它依赖于外部事务的存在，只有通过外部的事务提交，才能引起内部事务的提交，嵌套的子事务不能单独提交。如果熟悉 JDBC 中的保存点（SavePoint）的概念，那嵌套事务就很容易理解了，其实嵌套的子事务就是保存点的一个应用，一个事务中可以包括多个保存点，每一个嵌套子事务。另外，外部事务的回滚也会导致嵌套子事务的回滚。</p>
<h3 id="事务超时"><a href="#事务超时" class="headerlink" title="事务超时"></a>事务超时</h3><p>所谓事务超时，就是指一个事务所允许执行的最长时间，如果超过该时间限制但事务还没有完成，则自动回滚事务。在 TransactionDefinition 中以 int 的值来表示超时时间，其单位是秒。</p>
<h3 id="事务的只读属性"><a href="#事务的只读属性" class="headerlink" title="事务的只读属性"></a>事务的只读属性</h3><p>事务的只读属性是指，对事务性资源进行只读操作或者是读写操作。所谓事务性资源就是指那些被事务管理的资源，比如数据源、 JMS 资源，以及自定义的事务性资源等等。如果确定只对事务性资源进行只读操作，那么我们可以将事务标志为只读的，以提高事务处理的性能。在 TransactionDefinition 中以 boolean 类型来表示该事务是否只读。</p>
<h3 id="事务的回滚规则"><a href="#事务的回滚规则" class="headerlink" title="事务的回滚规则"></a>事务的回滚规则</h3><p>通常情况下，如果在事务中抛出了未检查异常（继承自 RuntimeException 的异常），则默认将回滚事务。如果没有抛出任何异常，或者抛出了已检查异常，则仍然提交事务。这通常也是大多数开发者希望的处理方式，也是 EJB 中的默认处理方式。但是，我们可以根据需要人为控制事务在抛出某些未检查异常时任然提交事务，或者在抛出某些已检查异常时回滚事务。</p>
<h2 id="Spring-事务管理-API-分析"><a href="#Spring-事务管理-API-分析" class="headerlink" title="Spring 事务管理 API 分析"></a>Spring 事务管理 API 分析</h2><p>spring并不直接管理事务，而是提供了多种事务管理器，它们将事务管理职责委托给JTA或者其他其他持久化机制所提供的平台相关的事务实现。</p>
<p>Spring 框架中，涉及到事务管理的 API 大约有100个左右，其中最重要的有三个：TransactionDefinition、PlatformTransactionManager、TransactionStatus。所谓事务管理，其实就是“按照给定的事务规则来执行提交或者回滚操作”。“给定的事务规则”就是用 TransactionDefinition 表示的，“按照……来执行提交或者回滚操作”便是用 PlatformTransactionManager 来表示，而 TransactionStatus 用于表示一个运行着的事务的状态。</p>
<h3 id="TransactionDefinition"><a href="#TransactionDefinition" class="headerlink" title="TransactionDefinition"></a>TransactionDefinition</h3><p>该接口在前面已经介绍过，它用于定义一个事务。它包含了事务的静态属性，比如：事务传播行为、超时时间等等。Spring 为我们提供了一个默认的实现类：DefaultTransactionDefinition，该类适用于大多数情况。如果该类不能满足需求，可以通过实现 TransactionDefinition 接口来实现自己的事务定义。</p>
<h3 id="PlatformTransactionManager"><a href="#PlatformTransactionManager" class="headerlink" title="PlatformTransactionManager"></a>PlatformTransactionManager</h3><p>PlatformTransactionManager 用于执行具体的事务操作。接口定义如下：</p>
<figure class="highlight java"><table><tr><td class="code"><pre><span class="line">Public <span class="class"><span class="keyword">interface</span> <span class="title">PlatformTransactionManager</span></span>&#123;</span><br><span class="line">  <span class="function">TransactionStatus <span class="title">getTransaction</span><span class="params">(TransactionDefinition definition)</span></span></span><br><span class="line"><span class="function">   <span class="keyword">throws</span> TransactionException</span>;</span><br><span class="line">   <span class="function"><span class="keyword">void</span> <span class="title">commit</span><span class="params">(TransactionStatus status)</span><span class="keyword">throws</span> TransactionException</span>;</span><br><span class="line">   <span class="function"><span class="keyword">void</span> <span class="title">rollback</span><span class="params">(TransactionStatus status)</span><span class="keyword">throws</span> TransactionException</span>;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<p>根据底层所使用的不同的持久化 API 或框架，PlatformTransactionManager 的主要实现类大致如下：</p>
<ul>
<li>DataSourceTransactionManager：适用于使用JDBC和iBatis进行数据持久化操作的情况。</li>
<li>HibernateTransactionManager：适用于使用Hibernate进行数据持久化操作的情况。</li>
<li>JpaTransactionManager：适用于使用JPA进行数据持久化操作的情况。</li>
<li>另外还有JtaTransactionManager 、JdoTransactionManager、JmsTransactionManager等等。</li>
</ul>
<p>如果我们使用JTA进行事务管理，我们可以通过 JNDI 和 Spring 的 JtaTransactionManager 来获取一个容器管理的 DataSource。JtaTransactionManager 不需要知道 DataSource 和其他特定的资源，因为它将使用容器提供的全局事务管理。而对于其他事务管理器，比如DataSourceTransactionManager，在定义时需要提供底层的数据源作为其属性，也就是 DataSource。与 HibernateTransactionManager 对应的是 SessionFactory，与 JpaTransactionManager 对应的是 EntityManagerFactory 等等。</p>
<p>各部分关系如下图：<br><img src="/img/Spring%E4%BA%8B%E5%8A%A1%E9%85%8D%E7%BD%AE.png" alt="Spring事务配置"></p>
<h3 id="TransactionStatus"><a href="#TransactionStatus" class="headerlink" title="TransactionStatus"></a>TransactionStatus</h3><p>PlatformTransactionManager.getTransaction(…) 方法返回一个 TransactionStatus 对象。返回的TransactionStatus 对象可能代表一个新的或已经存在的事务（如果在当前调用堆栈有一个符合条件的事务）。TransactionStatus 接口提供了一个简单的控制事务执行和查询事务状态的方法。该接口定义如清单3所示：</p>
<figure class="highlight java"><table><tr><td class="code"><pre><span class="line"><span class="keyword">public</span>  <span class="class"><span class="keyword">interface</span> <span class="title">TransactionStatus</span></span>&#123;</span><br><span class="line">   <span class="function"><span class="keyword">boolean</span> <span class="title">isNewTransaction</span><span class="params">()</span></span>;</span><br><span class="line">   <span class="function"><span class="keyword">void</span> <span class="title">setRollbackOnly</span><span class="params">()</span></span>;</span><br><span class="line">   <span class="function"><span class="keyword">boolean</span> <span class="title">isRollbackOnly</span><span class="params">()</span></span>;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<h3 id="基于注解的声明式事务实现"><a href="#基于注解的声明式事务实现" class="headerlink" title="基于注解的声明式事务实现"></a>基于注解的声明式事务实现</h3><p>目前这种方式是最流行的，上古的编程式事务并没有接触过，感兴趣可以上网搜下。</p>
<p>@Transactional 可以作用于接口、接口方法、类以及类方法上。当作用于类上时，该类的所有 public 方法将都具有该类型的事务属性，同时，我们也可以在方法级别使用该标注来覆盖类级别的定义。</p>
<figure class="highlight java"><table><tr><td class="code"><pre><span class="line"><span class="meta">@Transactional</span>(propagation = Propagation.REQUIRED)</span><br><span class="line">    <span class="function"><span class="keyword">public</span> <span class="keyword">boolean</span> <span class="title">transfer</span><span class="params">(Long fromId， Long toId， <span class="keyword">double</span> amount)</span> </span>&#123;</span><br><span class="line">        <span class="keyword">return</span> bankDao.transfer(fromId， toId， amount);</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<p>Spring 使用 BeanPostProcessor 来处理 Bean 中的标注，因此我们需要在配置文件中作如下声明来激活该后处理 Bean:</p>
<figure class="highlight xml"><table><tr><td class="code"><pre><span class="line"><span class="tag">&lt;<span class="name">tx:annotation-driven</span> <span class="attr">transaction-manager</span>=<span class="string">"transactionManager"</span>/&gt;</span></span><br></pre></td></tr></table></figure>
<p>与前面相似，transaction-manager 属性的默认值是 transactionManager，如果事务管理器 Bean 的名字即为该值，则可以省略该属性。</p>
<p>虽然 @Transactional 注解可以作用于接口、接口方法、类以及类方法上，但是 Spring 小组建议不要在接口或者接口方法上使用该注解，因为这只有在使用基于接口的代理时它才会生效。另外， @Transactional 注解应该只被应用到 public 方法上，这是由 Spring AOP 的本质决定的。如果你在 protected、private 或者默认可见性的方法上使用 @Transactional 注解，这将被忽略，也不会抛出任何异常。</p>
]]></content>
      <categories>
        <category>技术</category>
        <category>Spring</category>
      </categories>
      <tags>
        <tag>数据库</tag>
        <tag>Spring</tag>
        <tag>事务</tag>
      </tags>
  </entry>
  <entry>
    <title>spring bean初始化过程</title>
    <url>/2016/11/06/spring-bean%E5%88%9D%E5%A7%8B%E5%8C%96%E8%BF%87%E7%A8%8B/</url>
    <content><![CDATA[<h2 id="实例化过程"><a href="#实例化过程" class="headerlink" title="实例化过程"></a>实例化过程</h2><p><img src="/img/spring%20bean%E5%AE%9E%E4%BE%8B%E5%8C%96%E8%BF%87%E7%A8%8B.png" alt="spring bean实例化过程"></p>
<a id="more"></a>
<h2 id="验证"><a href="#验证" class="headerlink" title="验证"></a>验证</h2><h3 id="applicationContext-xml"><a href="#applicationContext-xml" class="headerlink" title="applicationContext.xml:"></a>applicationContext.xml:</h3><figure class="highlight"><table><tr><td class="code"><pre><span class="line">&lt;?xml version=<span class="string">"1.0"</span> encoding=<span class="string">"UTF-8"</span>?&gt;</span><br><span class="line">&lt;beans xmlns=<span class="string">"http://www.springframework.org/schema/beans"</span></span><br><span class="line">       xmlns:xsi=<span class="string">"http://www.w3.org/2001/XMLSchema-instance"</span> xmlns:spring=<span class="string">"http://www.springframework.org/schema/tool"</span></span><br><span class="line">       xmlns:context=<span class="string">"http://www.springframework.org/schema/context"</span></span><br><span class="line">       xsi:schemaLocation=<span class="string">"http://www.springframework.org/schema/beans http://www.springframework.org/schema/beans/spring-beans.xsd http://www.springframework.org/schema/tool http://www.springframework.org/schema/tool/spring-tool.xsd http://www.springframework.org/schema/context http://www.springframework.org/schema/context/spring-context.xsd"</span>&gt;</span><br><span class="line"> </span><br><span class="line">    &lt;context:annotation-config/&gt;</span><br><span class="line">    &lt;context:component-scan base-package="com.ytf.spring"&gt;&lt;/context:component-scan&gt;</span><br><span class="line"> </span><br><span class="line">    &lt;bean id="beanPost" class="com.ytf.spring.InitBeanProcess.BeanPost"&gt;&lt;/bean&gt;</span><br><span class="line">    &lt;bean name=<span class="string">"animal"</span> <span class="class"><span class="keyword">class</span></span>=<span class="string">"com.ytf.spring.InitBeanProcess.Animal"</span> init-method=<span class="string">"animalInit"</span></span><br><span class="line">          destroy-method=<span class="string">"animalDestroy"</span>&gt;</span><br><span class="line">        &lt;property name="spiece" value="dog"&gt;&lt;/property&gt;</span><br><span class="line">        &lt;property name="sex" value="male"&gt;&lt;/property&gt;</span><br><span class="line">    &lt;/bean&gt;</span><br><span class="line"> </span><br><span class="line">&lt;/beans&gt;</span><br></pre></td></tr></table></figure>
<h3 id="Animal-java实现了各种接口"><a href="#Animal-java实现了各种接口" class="headerlink" title="Animal.java实现了各种接口"></a>Animal.java实现了各种接口</h3><figure class="highlight java"><table><tr><td class="code"><pre><span class="line"><span class="keyword">package</span> com.ytf.spring.InitBeanProcess;</span><br><span class="line"> </span><br><span class="line"><span class="keyword">import</span> org.springframework.beans.BeansException;</span><br><span class="line"><span class="keyword">import</span> org.springframework.beans.factory.*;</span><br><span class="line"><span class="keyword">import</span> org.springframework.context.ApplicationContext;</span><br><span class="line"><span class="keyword">import</span> org.springframework.context.ApplicationContextAware;</span><br><span class="line"> </span><br><span class="line"><span class="comment">//@Component</span></span><br><span class="line"><span class="keyword">public</span> <span class="class"><span class="keyword">class</span> <span class="title">Animal</span> <span class="keyword">implements</span> <span class="title">BeanNameAware</span>, <span class="title">BeanFactoryAware</span>, <span class="title">ApplicationContextAware</span>, <span class="title">InitializingBean</span>,<span class="title">DisposableBean</span> </span>&#123;</span><br><span class="line">    <span class="keyword">private</span> String spiece;</span><br><span class="line">    <span class="keyword">private</span> String sex;</span><br><span class="line"> </span><br><span class="line">    <span class="function"><span class="keyword">public</span> String <span class="title">getSpiece</span><span class="params">()</span> </span>&#123;</span><br><span class="line">        <span class="keyword">return</span> spiece;</span><br><span class="line">    &#125;</span><br><span class="line"> </span><br><span class="line">    <span class="function"><span class="keyword">public</span> <span class="keyword">void</span> <span class="title">setSpiece</span><span class="params">(String spiece)</span> </span>&#123;</span><br><span class="line">        <span class="keyword">this</span>.spiece = spiece;</span><br><span class="line">        System.out.println(<span class="string">"Set Spiece:"</span> + <span class="keyword">this</span>.spiece);</span><br><span class="line">    &#125;</span><br><span class="line"> </span><br><span class="line">    <span class="function"><span class="keyword">public</span> String <span class="title">getSex</span><span class="params">()</span> </span>&#123;</span><br><span class="line">        <span class="keyword">return</span> sex;</span><br><span class="line">    &#125;</span><br><span class="line"> </span><br><span class="line">    <span class="function"><span class="keyword">public</span> <span class="keyword">void</span> <span class="title">setSex</span><span class="params">(String sex)</span> </span>&#123;</span><br><span class="line">        <span class="keyword">this</span>.sex = sex;</span><br><span class="line">        System.out.println(<span class="string">"Set Sex:"</span> + <span class="keyword">this</span>.sex);</span><br><span class="line">    &#125;</span><br><span class="line"> </span><br><span class="line">    <span class="function"><span class="keyword">public</span> <span class="title">Animal</span><span class="params">()</span> </span>&#123;</span><br><span class="line">        System.out.println(<span class="string">"Animal Instantiation"</span>);</span><br><span class="line">    &#125;</span><br><span class="line"> </span><br><span class="line"> </span><br><span class="line">    <span class="function"><span class="keyword">public</span> <span class="keyword">void</span> <span class="title">setBeanFactory</span><span class="params">(BeanFactory beanFactory)</span> <span class="keyword">throws</span> BeansException </span>&#123;</span><br><span class="line">        System.out.println(<span class="string">"BeanFactoryAware.setBeanFactory"</span>);</span><br><span class="line">        beanFactory.getBean(Animal<span class="class">.<span class="keyword">class</span>)</span>;</span><br><span class="line">    &#125;</span><br><span class="line"> </span><br><span class="line">    <span class="function"><span class="keyword">public</span> <span class="keyword">void</span> <span class="title">setBeanName</span><span class="params">(String s)</span> </span>&#123;</span><br><span class="line">        System.out.println(<span class="string">"BeanNameAware.setBeanName,beanId: "</span> + s);</span><br><span class="line">    &#125;</span><br><span class="line"> </span><br><span class="line">    <span class="function"><span class="keyword">public</span> <span class="keyword">void</span> <span class="title">afterPropertiesSet</span><span class="params">()</span> <span class="keyword">throws</span> Exception </span>&#123;</span><br><span class="line">        System.out.println(<span class="string">"InitializingBean.afterPropertiesSet"</span>);</span><br><span class="line"> </span><br><span class="line">    &#125;</span><br><span class="line"> </span><br><span class="line">    <span class="function"><span class="keyword">public</span> <span class="keyword">void</span> <span class="title">setApplicationContext</span><span class="params">(ApplicationContext applicationContext)</span> <span class="keyword">throws</span> BeansException </span>&#123;</span><br><span class="line">        System.out.println(<span class="string">"ApplicationContextAware.setApplicationContext"</span>);</span><br><span class="line">    &#125;</span><br><span class="line">     </span><br><span class="line">    <span class="comment">//@PostConstruct</span></span><br><span class="line">    <span class="function"><span class="keyword">public</span> <span class="keyword">void</span> <span class="title">animalInit</span><span class="params">()</span></span>&#123;</span><br><span class="line">        System.out.println(<span class="string">"Animal Init"</span>);</span><br><span class="line">    &#125;</span><br><span class="line">     </span><br><span class="line">    <span class="comment">//@PreDestroy</span></span><br><span class="line">    <span class="function"><span class="keyword">public</span> <span class="keyword">void</span> <span class="title">animalDestroy</span><span class="params">()</span></span>&#123;</span><br><span class="line">        System.out.println(<span class="string">"Animal Destroy"</span>);</span><br><span class="line">    &#125;</span><br><span class="line">    <span class="function"><span class="keyword">public</span> <span class="keyword">void</span> <span class="title">destroy</span><span class="params">()</span> <span class="keyword">throws</span> Exception </span>&#123;</span><br><span class="line">        System.out.println(<span class="string">"DisposableBean.destroy"</span>);</span><br><span class="line">    &#125;</span><br><span class="line">     </span><br><span class="line">    <span class="function"><span class="keyword">public</span> String <span class="title">toString</span><span class="params">()</span></span>&#123;</span><br><span class="line">        <span class="keyword">return</span> <span class="string">"Spiece:"</span> + <span class="keyword">this</span>.spiece + <span class="string">";Sex:"</span> + <span class="keyword">this</span>.sex;</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<h3 id="BeanPost-java实现BeanPostProcessor接口"><a href="#BeanPost-java实现BeanPostProcessor接口" class="headerlink" title="BeanPost.java实现BeanPostProcessor接口"></a>BeanPost.java实现BeanPostProcessor接口</h3><figure class="highlight java"><table><tr><td class="code"><pre><span class="line"><span class="keyword">package</span> com.ytf.spring.InitBeanProcess;</span><br><span class="line"> </span><br><span class="line"><span class="keyword">import</span> org.springframework.beans.BeansException;</span><br><span class="line"><span class="keyword">import</span> org.springframework.beans.factory.config.BeanPostProcessor;</span><br><span class="line"> </span><br><span class="line"><span class="comment">//@Component</span></span><br><span class="line"><span class="keyword">public</span> <span class="class"><span class="keyword">class</span> <span class="title">BeanPost</span> <span class="keyword">implements</span> <span class="title">BeanPostProcessor</span> </span>&#123;</span><br><span class="line"> </span><br><span class="line">    <span class="function"><span class="keyword">public</span> Object <span class="title">postProcessBeforeInitialization</span><span class="params">(Object o, String s)</span> <span class="keyword">throws</span> BeansException </span>&#123;</span><br><span class="line">        <span class="keyword">if</span> (o <span class="keyword">instanceof</span> Animal) &#123;</span><br><span class="line">            Animal animal = (Animal) o;</span><br><span class="line">            System.out.println(<span class="string">"BeanPostProcessor.postProcessBeforeInitialization"</span>);</span><br><span class="line">            animal.setSpiece(<span class="string">"monkey"</span>);</span><br><span class="line">            <span class="keyword">return</span> animal;</span><br><span class="line">        &#125;</span><br><span class="line"> </span><br><span class="line">        <span class="keyword">return</span> o;</span><br><span class="line">    &#125;</span><br><span class="line"> </span><br><span class="line">    <span class="function"><span class="keyword">public</span> Object <span class="title">postProcessAfterInitialization</span><span class="params">(Object o, String s)</span> <span class="keyword">throws</span> BeansException </span>&#123;</span><br><span class="line">        <span class="keyword">if</span> (o <span class="keyword">instanceof</span> Animal) &#123;</span><br><span class="line">            Animal animal = (Animal) o;</span><br><span class="line">            System.out.println(<span class="string">"BeanPostProcessor.postProcessAfterInitialization"</span>);</span><br><span class="line">            animal.setSex(<span class="string">"female"</span>);</span><br><span class="line">            <span class="keyword">return</span> animal;</span><br><span class="line">        &#125;</span><br><span class="line">        <span class="keyword">return</span> o;</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<h3 id="ProveBeanInit-java-是测试类"><a href="#ProveBeanInit-java-是测试类" class="headerlink" title="ProveBeanInit.java 是测试类"></a>ProveBeanInit.java 是测试类</h3><figure class="highlight java"><table><tr><td class="code"><pre><span class="line"><span class="keyword">package</span> com.ytf.spring.InitBeanProcess;</span><br><span class="line"> </span><br><span class="line"><span class="keyword">import</span> org.springframework.context.support.ClassPathXmlApplicationContext;</span><br><span class="line"> </span><br><span class="line"><span class="keyword">public</span> <span class="class"><span class="keyword">class</span> <span class="title">ProveBeanInit</span> </span>&#123;</span><br><span class="line">    <span class="function"><span class="keyword">public</span> <span class="keyword">static</span> <span class="keyword">void</span> <span class="title">main</span><span class="params">(String[] args)</span></span>&#123;</span><br><span class="line">        ClassPathXmlApplicationContext cpa = <span class="keyword">new</span> ClassPathXmlApplicationContext(<span class="string">"application.xml"</span>);</span><br><span class="line">        Animal animal = (Animal)cpa.getBean(<span class="string">"animal"</span>);</span><br><span class="line">        System.out.println(animal);</span><br><span class="line">        cpa.close();</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<h2 id="结果"><a href="#结果" class="headerlink" title="结果"></a>结果</h2><blockquote>
<p>Animal Instantiation<br>Set Spiece:dog<br>Set Sex:male<br>BeanNameAware.setBeanName,beanId: animal<br>BeanFactoryAware.setBeanFactory<br>ApplicationContextAware.setApplicationContext<br>BeanPostProcessor.postProcessBeforeInitialization<br>Set Spiece:monkey<br>InitializingBean.afterPropertiesSet<br>Animal Init<br>BeanPostProcessor.postProcessAfterInitialization<br>Set Sex:female<br>Spiece:monkey;Sex:female<br>DisposableBean.destroy<br>Animal Destroy</p>
</blockquote>
<p>可见，初始化顺序确实如图说明。</p>
<h2 id="注意问题"><a href="#注意问题" class="headerlink" title="注意问题"></a>注意问题</h2><ol>
<li>如果去掉BeanPost,改为Animal实现BeanPostProcessor，会导致BeanPostProcessor的两个方法不运行。</li>
<li>网上有说使用注解@PostConstruct、@PreDestroy 代替 init-method,destroy-method，实际运行发现并不是一样的，换成注解，产生的结果如下：</li>
</ol>
<blockquote>
<p>Animal Instantiation<br>BeanNameAware.setBeanName,beanId: animal<br>BeanFactoryAware.setBeanFactory<br>ApplicationContextAware.setApplicationContext<br>BeanPostProcessor.postProcessBeforeInitialization<br>Set Spiece:monkey<br><strong><em>Animal Init<br>InitializingBean.afterPropertiesSet</em></strong><br>BeanPostProcessor.postProcessAfterInitialization<br>Set Sex:female<br>Spiece:monkey;Sex:female<br><strong><em>Animal Destroy</em></strong><br><strong><em>DisposableBean.destroy</em></strong></p>
</blockquote>
]]></content>
      <categories>
        <category>技术</category>
        <category>Spring</category>
      </categories>
      <tags>
        <tag>Spring</tag>
      </tags>
  </entry>
  <entry>
    <title>springmvc 请求处理过程</title>
    <url>/2016/11/03/springmvc-%E8%AF%B7%E6%B1%82%E5%A4%84%E7%90%86%E8%BF%87%E7%A8%8B/</url>
    <content><![CDATA[<p>一个请求到达服务器之后，springmvc处理过程：<br><img src="/img/springmvc%20%E8%AF%B7%E6%B1%82%E5%A4%84%E7%90%86%E8%BF%87%E7%A8%8B.png" alt="springmvc 请求处理过程"></p>
<a id="more"></a>
<ul>
<li>(1) <strong>Http请求</strong>：客户端请求提交到DispatcherServlet。 </li>
<li>(2) <strong>寻找处理器</strong>：由DispatcherServlet控制器查询一个或多个HandlerMapping，找到处理请求的Controller。 </li>
<li>(3) <strong>调用处理器</strong>：DispatcherServlet将请求提交到Controller。 </li>
<li>(4)(5)<strong>调用业务处理和返回结果</strong>：Controller调用业务逻辑处理后，返回ModelAndView。 </li>
<li>(6)(7)<strong>处理视图映射并返回模型</strong>： DispatcherServlet查询一个或多个ViewResoler视图解析器，找到ModelAndView指定的视图。 </li>
<li>(8) <strong>Http响应</strong>：视图负责将结果显示到客户端。</li>
</ul>
<p>图中有些过程没有说清楚，比如怎么找到HandlerMapping以及业务逻辑代码怎么被调用？<br>这就需要看DispatcherServlet源码了。<br>先上一段关键代码，DispatcherServlet.doDispatcher() 方法,核心流程都在这个方法里。</p>
<h2 id="DispatcherServlet-doDispatch"><a href="#DispatcherServlet-doDispatch" class="headerlink" title="DispatcherServlet.doDispatch"></a>DispatcherServlet.doDispatch</h2><figure class="highlight java"><table><tr><td class="code"><pre><span class="line"><span class="function"><span class="keyword">protected</span> <span class="keyword">void</span> <span class="title">doDispatch</span><span class="params">(HttpServletRequest request, HttpServletResponse response)</span> <span class="keyword">throws</span> Exception </span>&#123;</span><br><span class="line">   HttpServletRequest processedRequest = request;</span><br><span class="line">   HandlerExecutionChain mappedHandler = <span class="keyword">null</span>;</span><br><span class="line">   <span class="keyword">boolean</span> multipartRequestParsed = <span class="keyword">false</span>;</span><br><span class="line"> </span><br><span class="line">   WebAsyncManager asyncManager = WebAsyncUtils.getAsyncManager(request);</span><br><span class="line"> </span><br><span class="line">   <span class="keyword">try</span> &#123;</span><br><span class="line">      ModelAndView mv = <span class="keyword">null</span>;</span><br><span class="line">      Exception dispatchException = <span class="keyword">null</span>;</span><br><span class="line"> </span><br><span class="line">      <span class="keyword">try</span> &#123;</span><br><span class="line">         processedRequest = checkMultipart(request);</span><br><span class="line">         multipartRequestParsed = (processedRequest != request);</span><br><span class="line"> </span><br><span class="line">         <span class="comment">// Determine handler for the current request.</span></span><br><span class="line">         mappedHandler = getHandler(processedRequest);</span><br><span class="line">         <span class="keyword">if</span> (mappedHandler == <span class="keyword">null</span> || mappedHandler.getHandler() == <span class="keyword">null</span>) &#123;</span><br><span class="line">            noHandlerFound(processedRequest, response);</span><br><span class="line">            <span class="keyword">return</span>;</span><br><span class="line">         &#125;</span><br><span class="line"> </span><br><span class="line">         <span class="comment">// Determine handler adapter for the current request.</span></span><br><span class="line">         HandlerAdapter ha = getHandlerAdapter(mappedHandler.getHandler());</span><br><span class="line"> </span><br><span class="line">         <span class="comment">// Process last-modified header, if supported by the handler.</span></span><br><span class="line">         String method = request.getMethod();</span><br><span class="line">         <span class="keyword">boolean</span> isGet = <span class="string">"GET"</span>.equals(method);</span><br><span class="line">         <span class="keyword">if</span> (isGet || <span class="string">"HEAD"</span>.equals(method)) &#123;</span><br><span class="line">            <span class="keyword">long</span> lastModified = ha.getLastModified(request, mappedHandler.getHandler());</span><br><span class="line">            <span class="keyword">if</span> (logger.isDebugEnabled()) &#123;</span><br><span class="line">               logger.debug(<span class="string">"Last-Modified value for ["</span> + getRequestUri(request) + <span class="string">"] is: "</span> + lastModified);</span><br><span class="line">            &#125;</span><br><span class="line">            <span class="keyword">if</span> (<span class="keyword">new</span> ServletWebRequest(request, response).checkNotModified(lastModified) &amp;&amp; isGet) &#123;</span><br><span class="line">               <span class="keyword">return</span>;</span><br><span class="line">            &#125;</span><br><span class="line">         &#125;</span><br><span class="line"> </span><br><span class="line">         <span class="keyword">if</span> (!mappedHandler.applyPreHandle(processedRequest, response)) &#123;</span><br><span class="line">            <span class="keyword">return</span>;</span><br><span class="line">         &#125;</span><br><span class="line"> </span><br><span class="line">         <span class="comment">// Actually invoke the handler.</span></span><br><span class="line">         mv = ha.handle(processedRequest, response, mappedHandler.getHandler());</span><br><span class="line"> </span><br><span class="line">         <span class="keyword">if</span> (asyncManager.isConcurrentHandlingStarted()) &#123;</span><br><span class="line">            <span class="keyword">return</span>;</span><br><span class="line">         &#125;</span><br><span class="line"> </span><br><span class="line">         applyDefaultViewName(processedRequest, mv);</span><br><span class="line">         mappedHandler.applyPostHandle(processedRequest, response, mv);</span><br><span class="line">      &#125;</span><br><span class="line">      <span class="keyword">catch</span> (Exception ex) &#123;</span><br><span class="line">         dispatchException = ex;</span><br><span class="line">      &#125;</span><br><span class="line">      processDispatchResult(processedRequest, response, mappedHandler, mv, dispatchException);</span><br><span class="line">   &#125;</span><br><span class="line">   <span class="keyword">catch</span> (Exception ex) &#123;</span><br><span class="line">      triggerAfterCompletion(processedRequest, response, mappedHandler, ex);</span><br><span class="line">   &#125;</span><br><span class="line">   <span class="keyword">catch</span> (Error err) &#123;</span><br><span class="line">      triggerAfterCompletionWithError(processedRequest, response, mappedHandler, err);</span><br><span class="line">   &#125;</span><br><span class="line">   <span class="keyword">finally</span> &#123;</span><br><span class="line">      <span class="keyword">if</span> (asyncManager.isConcurrentHandlingStarted()) &#123;</span><br><span class="line">         <span class="comment">// Instead of postHandle and afterCompletion</span></span><br><span class="line">         <span class="keyword">if</span> (mappedHandler != <span class="keyword">null</span>) &#123;</span><br><span class="line">            mappedHandler.applyAfterConcurrentHandlingStarted(processedRequest, response);</span><br><span class="line">         &#125;</span><br><span class="line">      &#125;</span><br><span class="line">      <span class="keyword">else</span> &#123;</span><br><span class="line">         <span class="comment">// Clean up any resources used by a multipart request.</span></span><br><span class="line">         <span class="keyword">if</span> (multipartRequestParsed) &#123;</span><br><span class="line">            cleanupMultipart(processedRequest);</span><br><span class="line">         &#125;</span><br><span class="line">      &#125;</span><br><span class="line">   &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<p>第一个出现的核心接口：getHandler()</p>
<figure class="highlight java"><table><tr><td class="code"><pre><span class="line">mappedHandler = getHandler(processedRequest);</span><br></pre></td></tr></table></figure>
<p>它是在org.springframework.web.servlet包中定义的HandlerMapping接口：</p>
<h3 id="HandlerMapping"><a href="#HandlerMapping" class="headerlink" title="HandlerMapping"></a>HandlerMapping</h3><figure class="highlight java"><table><tr><td class="code"><pre><span class="line"><span class="keyword">package</span> org.springframework.web.servlet;</span><br><span class="line"> </span><br><span class="line"><span class="keyword">import</span> javax.servlet.http.HttpServletRequest;</span><br><span class="line"> </span><br><span class="line"><span class="keyword">public</span> <span class="class"><span class="keyword">interface</span> <span class="title">HandlerMapping</span> </span>&#123;</span><br><span class="line"> </span><br><span class="line">    String PATH_WITHIN_HANDLER_MAPPING_ATTRIBUTE = HandlerMapping.class.getName() + ".pathWithinHandlerMapping";</span><br><span class="line"> </span><br><span class="line">    String BEST_MATCHING_PATTERN_ATTRIBUTE = HandlerMapping.class.getName() + ".bestMatchingPattern";</span><br><span class="line"> </span><br><span class="line">    String INTROSPECT_TYPE_LEVEL_MAPPING = HandlerMapping.class.getName() + ".introspectTypeLevelMapping";</span><br><span class="line"> </span><br><span class="line">    String URI_TEMPLATE_VARIABLES_ATTRIBUTE = HandlerMapping.class.getName() + ".uriTemplateVariables";</span><br><span class="line"> </span><br><span class="line">    String PRODUCIBLE_MEDIA_TYPES_ATTRIBUTE = HandlerMapping.class.getName() + ".producibleMediaTypes";</span><br><span class="line"> </span><br><span class="line">    <span class="function">HandlerExecutionChain <span class="title">getHandler</span><span class="params">(HttpServletRequest request)</span> <span class="keyword">throws</span> Exception</span>;</span><br><span class="line"> </span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<p>为了阅读方便，去掉了源码中的注释，类中定义的几个常量先不管。关键在于这个接口中唯一的方法：</p>
<figure class="highlight java"><table><tr><td class="code"><pre><span class="line"><span class="function">HandlerExecutionChain <span class="title">getHandler</span><span class="params">(HttpServletRequest request)</span> <span class="keyword">throws</span> Exception</span>;</span><br></pre></td></tr></table></figure>
<p>回到DispatcherServlet的处理流程，当DispatcherServlet接收到web请求后，由标准Servlet类处理方法doGet或者doPost，经过几次转发后，遍历DispatcherServlet中所有<br>HandlerMapping实现类（容器启动时会将实现类注入进来，看源码！）。<br>web请求的HttpServletRequest对象为参数，依次调用HandlerMapping实现类的getHandler方法，第一个不为null的作为结果返回。<br>DispatcherServlet类中的这个遍历方法不长，贴一下:</p>
<h3 id="getHandler"><a href="#getHandler" class="headerlink" title="getHandler()"></a>getHandler()</h3><figure class="highlight java"><table><tr><td class="code"><pre><span class="line"><span class="comment">/** * Return the HandlerExecutionChain for this request. * &lt;p&gt;Tries all handler mappings in order. * <span class="doctag">@param</span> request current HTTP request * <span class="doctag">@return</span> the HandlerExecutionChain, or &lt;code&gt;null&lt;/code&gt; if no handler could be found */</span></span><br><span class="line">    <span class="function"><span class="keyword">protected</span> HandlerExecutionChain <span class="title">getHandler</span><span class="params">(HttpServletRequest request)</span> <span class="keyword">throws</span> Exception </span>&#123;</span><br><span class="line">        <span class="keyword">for</span> (HandlerMapping hm : <span class="keyword">this</span>.handlerMappings) &#123;</span><br><span class="line">            <span class="keyword">if</span> (logger.isTraceEnabled()) &#123;</span><br><span class="line">                logger.trace(</span><br><span class="line">                        <span class="string">"Testing handler map ["</span> + hm + <span class="string">"] in DispatcherServlet with name '"</span> + getServletName() + <span class="string">"'"</span>);</span><br><span class="line">            &#125;</span><br><span class="line">            HandlerExecutionChain handler = hm.getHandler(request);</span><br><span class="line">            <span class="keyword">if</span> (handler != <span class="keyword">null</span>) &#123;</span><br><span class="line">                <span class="keyword">return</span> handler;</span><br><span class="line">            &#125;</span><br><span class="line">        &#125;</span><br><span class="line">        <span class="keyword">return</span> <span class="keyword">null</span>;</span><br><span class="line">    &#125;</span><br></pre></td></tr></table></figure>
<p>可以看到，一个web请求经过处理后，会得到一个HandlerExecutionChain对象，这就是SpringMVC对URl映射给出的回答。<br>需要留意的是，HandlerMapping接口的getHandler方法参数是HttpServletRequest，这意味着，HandlerMapping的实现类可以利用HttpServletRequest中的 所有信息来做出这个HandlerExecutionChain对象的生成”决策“。这包括，请求头、url路径、cookie、session、参数等等一切你从一个web请求中可以得到的任何东西（最常用的是url路径）。<br>getHandler()的具体实现有兴趣饿的可以跟进去看下。</p>
<p>HandlerExecutionChain是我们接触的第二个核心类，从名字可以直观的看得出，这个对象是一个执行链的封装。<br>HandlerExecutionChain类的代码不长，它定义在org.springframework.web.servlet包中， 为了更直观的理解，先上代码:</p>
<h3 id="HandlerExecutionChain"><a href="#HandlerExecutionChain" class="headerlink" title="HandlerExecutionChain"></a>HandlerExecutionChain</h3><figure class="highlight java"><table><tr><td class="code"><pre><span class="line"><span class="keyword">package</span> org.springframework.web.servlet;</span><br><span class="line"> </span><br><span class="line"><span class="keyword">import</span> java.util.ArrayList;</span><br><span class="line"><span class="keyword">import</span> java.util.Arrays;</span><br><span class="line"><span class="keyword">import</span> java.util.List;</span><br><span class="line"> </span><br><span class="line"><span class="keyword">import</span> org.springframework.util.CollectionUtils;</span><br><span class="line"> </span><br><span class="line"><span class="keyword">public</span> <span class="class"><span class="keyword">class</span> <span class="title">HandlerExecutionChain</span> </span>&#123;</span><br><span class="line"> </span><br><span class="line">    <span class="keyword">private</span> <span class="keyword">final</span> Object handler;</span><br><span class="line"> </span><br><span class="line">    <span class="keyword">private</span> HandlerInterceptor[] interceptors;</span><br><span class="line"> </span><br><span class="line">    <span class="keyword">private</span> List&lt;HandlerInterceptor&gt; interceptorList;</span><br><span class="line"> </span><br><span class="line">    <span class="function"><span class="keyword">public</span> <span class="title">HandlerExecutionChain</span><span class="params">(Object handler)</span> </span>&#123;</span><br><span class="line">        <span class="keyword">this</span>(handler, <span class="keyword">null</span>);</span><br><span class="line">    &#125;</span><br><span class="line"> </span><br><span class="line">    <span class="function"><span class="keyword">public</span> <span class="title">HandlerExecutionChain</span><span class="params">(Object handler, HandlerInterceptor[] interceptors)</span> </span>&#123;</span><br><span class="line">        <span class="keyword">if</span> (handler <span class="keyword">instanceof</span> HandlerExecutionChain) &#123;</span><br><span class="line">            HandlerExecutionChain originalChain = (HandlerExecutionChain) handler;</span><br><span class="line">            <span class="keyword">this</span>.handler = originalChain.getHandler();</span><br><span class="line">            <span class="keyword">this</span>.interceptorList = <span class="keyword">new</span> ArrayList&lt;HandlerInterceptor&gt;();</span><br><span class="line">            CollectionUtils.mergeArrayIntoCollection(originalChain.getInterceptors(), <span class="keyword">this</span>.interceptorList);</span><br><span class="line">            CollectionUtils.mergeArrayIntoCollection(interceptors, <span class="keyword">this</span>.interceptorList);</span><br><span class="line">        &#125;</span><br><span class="line">        <span class="keyword">else</span> &#123;</span><br><span class="line">            <span class="keyword">this</span>.handler = handler;</span><br><span class="line">            <span class="keyword">this</span>.interceptors = interceptors;</span><br><span class="line">        &#125;</span><br><span class="line">    &#125;</span><br><span class="line"> </span><br><span class="line">    <span class="function"><span class="keyword">public</span> Object <span class="title">getHandler</span><span class="params">()</span> </span>&#123;</span><br><span class="line">        <span class="keyword">return</span> <span class="keyword">this</span>.handler;</span><br><span class="line">    &#125;</span><br><span class="line"> </span><br><span class="line">    <span class="function"><span class="keyword">public</span> <span class="keyword">void</span> <span class="title">addInterceptor</span><span class="params">(HandlerInterceptor interceptor)</span> </span>&#123;</span><br><span class="line">        initInterceptorList();</span><br><span class="line">        <span class="keyword">this</span>.interceptorList.add(interceptor);</span><br><span class="line">    &#125;</span><br><span class="line"> </span><br><span class="line">    <span class="function"><span class="keyword">public</span> <span class="keyword">void</span> <span class="title">addInterceptors</span><span class="params">(HandlerInterceptor[] interceptors)</span> </span>&#123;</span><br><span class="line">        <span class="keyword">if</span> (interceptors != <span class="keyword">null</span>) &#123;</span><br><span class="line">            initInterceptorList();</span><br><span class="line">            <span class="keyword">this</span>.interceptorList.addAll(Arrays.asList(interceptors));</span><br><span class="line">        &#125;</span><br><span class="line">    &#125;</span><br><span class="line"> </span><br><span class="line">    <span class="function"><span class="keyword">private</span> <span class="keyword">void</span> <span class="title">initInterceptorList</span><span class="params">()</span> </span>&#123;</span><br><span class="line">        <span class="keyword">if</span> (<span class="keyword">this</span>.interceptorList == <span class="keyword">null</span>) &#123;</span><br><span class="line">            <span class="keyword">this</span>.interceptorList = <span class="keyword">new</span> ArrayList&lt;HandlerInterceptor&gt;();</span><br><span class="line">        &#125;</span><br><span class="line">        <span class="keyword">if</span> (<span class="keyword">this</span>.interceptors != <span class="keyword">null</span>) &#123;</span><br><span class="line">            <span class="keyword">this</span>.interceptorList.addAll(Arrays.asList(<span class="keyword">this</span>.interceptors));</span><br><span class="line">            <span class="keyword">this</span>.interceptors = <span class="keyword">null</span>;</span><br><span class="line">        &#125;</span><br><span class="line">    &#125;</span><br><span class="line"> </span><br><span class="line">    <span class="keyword">public</span> HandlerInterceptor[] getInterceptors() &#123;</span><br><span class="line">        <span class="keyword">if</span> (<span class="keyword">this</span>.interceptors == <span class="keyword">null</span> &amp;&amp; <span class="keyword">this</span>.interceptorList != <span class="keyword">null</span>) &#123;</span><br><span class="line">            <span class="keyword">this</span>.interceptors = <span class="keyword">this</span>.interceptorList.toArray(<span class="keyword">new</span> HandlerInterceptor[<span class="keyword">this</span>.interceptorList.size()]);</span><br><span class="line">        &#125;</span><br><span class="line">        <span class="keyword">return</span> <span class="keyword">this</span>.interceptors;</span><br><span class="line">    &#125;</span><br><span class="line"> </span><br><span class="line">    <span class="meta">@Override</span></span><br><span class="line">    <span class="function"><span class="keyword">public</span> String <span class="title">toString</span><span class="params">()</span> </span>&#123;</span><br><span class="line">        <span class="keyword">if</span> (<span class="keyword">this</span>.handler == <span class="keyword">null</span>) &#123;</span><br><span class="line">            <span class="keyword">return</span> <span class="string">"HandlerExecutionChain with no handler"</span>;</span><br><span class="line">        &#125;</span><br><span class="line">        StringBuilder sb = <span class="keyword">new</span> StringBuilder();</span><br><span class="line">        sb.append(<span class="string">"HandlerExecutionChain with handler ["</span>).append(<span class="keyword">this</span>.handler).append(<span class="string">"]"</span>);</span><br><span class="line">        <span class="keyword">if</span> (!CollectionUtils.isEmpty(<span class="keyword">this</span>.interceptorList)) &#123;</span><br><span class="line">            sb.append(<span class="string">" and "</span>).append(<span class="keyword">this</span>.interceptorList.size()).append(<span class="string">" interceptor"</span>);</span><br><span class="line">            <span class="keyword">if</span> (<span class="keyword">this</span>.interceptorList.size() &gt; <span class="number">1</span>) &#123;</span><br><span class="line">                sb.append(<span class="string">"s"</span>);</span><br><span class="line">            &#125;</span><br><span class="line">        &#125;</span><br><span class="line">        <span class="keyword">return</span> sb.toString();</span><br><span class="line">    &#125;</span><br></pre></td></tr></table></figure>
<p>关注两行即可知道这个类的作用：</p>
<figure class="highlight java"><table><tr><td class="code"><pre><span class="line"><span class="keyword">private</span> <span class="keyword">final</span> Object handler;</span><br><span class="line"> </span><br><span class="line"><span class="keyword">private</span> HandlerInterceptor[] interceptors;</span><br></pre></td></tr></table></figure>
<p>一个实质执行对象，还有一堆拦截器。<br>HandlerInterceptor也是SpringMVC的核心接口，定义如下：</p>
<h3 id="HandlerInterceptor"><a href="#HandlerInterceptor" class="headerlink" title="HandlerInterceptor"></a>HandlerInterceptor</h3><figure class="highlight java"><table><tr><td class="code"><pre><span class="line"><span class="keyword">package</span> org.springframework.web.servlet;</span><br><span class="line"> </span><br><span class="line"><span class="keyword">import</span> javax.servlet.http.HttpServletRequest;</span><br><span class="line"><span class="keyword">import</span> javax.servlet.http.HttpServletResponse;</span><br><span class="line"> </span><br><span class="line"><span class="keyword">public</span> <span class="class"><span class="keyword">interface</span> <span class="title">HandlerInterceptor</span> </span>&#123;</span><br><span class="line"> </span><br><span class="line">    <span class="function"><span class="keyword">boolean</span> <span class="title">preHandle</span><span class="params">(HttpServletRequest request, HttpServletResponse response, Object handler)</span></span></span><br><span class="line"><span class="function">        <span class="keyword">throws</span> Exception</span>;</span><br><span class="line"> </span><br><span class="line">    <span class="function"><span class="keyword">void</span> <span class="title">postHandle</span><span class="params">(</span></span></span><br><span class="line"><span class="function"><span class="params">            HttpServletRequest request, HttpServletResponse response, Object handler, ModelAndView modelAndView)</span></span></span><br><span class="line"><span class="function">            <span class="keyword">throws</span> Exception</span>;</span><br><span class="line"> </span><br><span class="line">    <span class="function"><span class="keyword">void</span> <span class="title">afterCompletion</span><span class="params">(</span></span></span><br><span class="line"><span class="function"><span class="params">            HttpServletRequest request, HttpServletResponse response, Object handler, Exception ex)</span></span></span><br><span class="line"><span class="function">            <span class="keyword">throws</span> Exception</span>;</span><br><span class="line"> </span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<p>拦截器就是我们定义的interceptor，关于拦截器的讲解在 <a href="https://mastertf.github.io/2016/10/09/spring-%E6%8B%A6%E6%88%AA%E5%99%A8/" target="_blank" rel="noopener">spring拦截器</a><br>至此，HandlerExecutionChain整个执行脉络也就清楚了：在真正调用其handler对象前，HandlerInterceptor接口实现类组成的数组将会被遍历，其preHandle方法会被依次调用，然后真正的handler对象将被调用。<br>handler对象被调用后，就生成了需要的响应数据，在将处理结果写到HttpServletResponse对象之前（SpringMVC称为渲染视图），其postHandle方法会被依次调用。视图渲染完成后，最后afterCompletion方法会被依次调用，整个web请求的处理过程就结束了。</p>
<p>这个HandlerExecutionChain类中以Object引用所声明的handler对象，到底是什么？它是怎么被调用的？<br>继续看DispatcherServlet.doDispatch()方法24行：</p>
<figure class="highlight java"><table><tr><td class="code"><pre><span class="line">HandlerAdapter ha = getHandlerAdapter(mappedHandler.getHandler());</span><br></pre></td></tr></table></figure>
<h3 id="getHandlerAdapter-："><a href="#getHandlerAdapter-：" class="headerlink" title="getHandlerAdapter()："></a>getHandlerAdapter()：</h3><figure class="highlight java"><table><tr><td class="code"><pre><span class="line"><span class="comment">/**</span></span><br><span class="line"><span class="comment"> * Return the HandlerAdapter for this handler object.</span></span><br><span class="line"><span class="comment"> * <span class="doctag">@param</span> handler the handler object to find an adapter for</span></span><br><span class="line"><span class="comment"> * <span class="doctag">@throws</span> ServletException if no HandlerAdapter can be found for the handler. This is a fatal error.</span></span><br><span class="line"><span class="comment"> */</span></span><br><span class="line"><span class="function"><span class="keyword">protected</span> HandlerAdapter <span class="title">getHandlerAdapter</span><span class="params">(Object handler)</span> <span class="keyword">throws</span> ServletException </span>&#123;</span><br><span class="line">   <span class="keyword">for</span> (HandlerAdapter ha : <span class="keyword">this</span>.handlerAdapters) &#123;</span><br><span class="line">      <span class="keyword">if</span> (logger.isTraceEnabled()) &#123;</span><br><span class="line">         logger.trace(<span class="string">"Testing handler adapter ["</span> + ha + <span class="string">"]"</span>);</span><br><span class="line">      &#125;</span><br><span class="line">      <span class="keyword">if</span> (ha.supports(handler)) &#123;</span><br><span class="line">         <span class="keyword">return</span> ha;</span><br><span class="line">      &#125;</span><br><span class="line">   &#125;</span><br><span class="line">   <span class="keyword">throw</span> <span class="keyword">new</span> ServletException(<span class="string">"No adapter for handler ["</span> + handler +</span><br><span class="line">         <span class="string">"]: The DispatcherServlet configuration needs to include a HandlerAdapter that supports this handler"</span>);</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<p>这段代码已经很明显了，HandlerExecutionChain中的handler对象会被作为参数传递进去，在DispatcherServlet类中注册的HandlerAdapter实现类列表会被遍历，然后返回第一个supports方法返回true的HandlerAdapter对象。<br>获得到HandlerAdapter对象后，调用handle方法处理handler对象，并返回ModelAndView这个包含了视图和数据的对象。</p>
<figure class="highlight java"><table><tr><td class="code"><pre><span class="line">mv = ha.handle(processedRequest, response, mappedHandler.getHandler());</span><br></pre></td></tr></table></figure>
<p>ModelAndView对象的代码就不贴了，它是SpringMVC中对视图和数据的一个聚合类。其中的视图，就是由SpringMVC的最后一个核心接口View所抽象：</p>
<h3 id="handle"><a href="#handle" class="headerlink" title="handle"></a>handle</h3><figure class="highlight java"><table><tr><td class="code"><pre><span class="line"><span class="keyword">package</span> org.springframework.web.servlet;</span><br><span class="line"> </span><br><span class="line"><span class="keyword">import</span> java.util.Map;</span><br><span class="line"> </span><br><span class="line"><span class="keyword">import</span> javax.servlet.http.HttpServletRequest;</span><br><span class="line"><span class="keyword">import</span> javax.servlet.http.HttpServletResponse;</span><br><span class="line"> </span><br><span class="line"><span class="keyword">public</span> <span class="class"><span class="keyword">interface</span> <span class="title">View</span> </span>&#123;</span><br><span class="line"> </span><br><span class="line">    String RESPONSE_STATUS_ATTRIBUTE = View.class.getName() + ".responseStatus";</span><br><span class="line"> </span><br><span class="line">    String PATH_VARIABLES = View.class.getName() + ".pathVariables";</span><br><span class="line"> </span><br><span class="line">    <span class="function">String <span class="title">getContentType</span><span class="params">()</span></span>;</span><br><span class="line"> </span><br><span class="line">    <span class="function"><span class="keyword">void</span> <span class="title">render</span><span class="params">(Map&lt;String, ?&gt; model, HttpServletRequest request, HttpServletResponse response)</span> <span class="keyword">throws</span> Exception</span>;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<p>所有的数据，最后会作为一个Map对象传递到View实现类中的render方法，调用这个render方法，就完成了视图到响应的渲染。这个View实现类，就是来自HandlerAdapter中的handle方法的返回结果。当然从ModelAndView到真正的View实现类有一个解析的过程，ModelAndView中可以有真正的视图对象，也可以只是有一个视图的名字，SpringMVC会负责将视图名称解析为真正的视图对象。</p>
<p>至此，我们了解了一个典型的完整的web请求在SpringMVC中的处理过程和其中涉及到的核心类和接口。</p>
<p>在一个典型的SpringMVC调用中，HandlerExecutionChain中封装handler对象就是用@Controller注解标识的类的一个实例，根据类级别和方法级别的@RequestMapping注解，由默认注册的DefaultAnnotationHandlerMapping（3.1.3中更新为RequestMappingHandlerMapping类，但是为了向后兼容，DefaultAnnotationHandlerMapping也可以使用）生成HandlerExecutionChain对象，再由AnnotationMethodHandlerAdapter（3.1.3中更新为RequestMappingHandlerAdapter类，但是为了向后兼容，AnnotationMethodHandlerAdapter也可以使用）来执行这个HandlerExecutionChain对象，生成最终的ModelAndView对象后，再由具体的View对象的render方法渲染视图。</p>
]]></content>
      <categories>
        <category>技术</category>
        <category>Spring</category>
      </categories>
      <tags>
        <tag>Spring</tag>
      </tags>
  </entry>
  <entry>
    <title>spring 拦截器</title>
    <url>/2016/10/09/spring-%E6%8B%A6%E6%88%AA%E5%99%A8/</url>
    <content><![CDATA[<h2 id="处理器拦截器简介"><a href="#处理器拦截器简介" class="headerlink" title="处理器拦截器简介"></a>处理器拦截器简介</h2><p>Spring Web MVC的处理器拦截器（如无特殊说明，下文所说的拦截器即处理器拦截器）<br>类似于Servlet开发中的过滤器Filter，用于对处理器进行预处理和后处理。</p>
<h2 id="常见应用场景"><a href="#常见应用场景" class="headerlink" title="常见应用场景"></a>常见应用场景</h2><ol>
<li>日志记录：记录请求信息的日志，以便进行信息监控、信息统计、计算PV（Page View）等。</li>
<li>权限检查：如登录检测，进入处理器检测检测是否登录，如果没有直接返回到登录页面；</li>
<li>性能监控：有时候系统在某段时间莫名其妙的慢，可以通过拦截器在进入处理器之前记录开始时间，在处理完后记录结束时间，从而得到该请求的处理时间（如果有反向代理，如apache可以自动记录）；</li>
<li>通用行为：读取cookie得到用户信息并将用户对象放入请求，从而方便后续流程使用，还有如提取Locale、Theme信息等，只要是多个处理器都需要的即可使用拦截器实现。</li>
<li>OpenSessionInView：如Hibernate，在进入处理器打开Session，在完成后关闭Session。</li>
</ol>
<p>…………本质也是AOP（面向切面编程），也就是说符合横切关注点的所有功能都可以放入拦截器实现。</p>
<a id="more"></a>
<h2 id="拦截器接口"><a href="#拦截器接口" class="headerlink" title="拦截器接口"></a>拦截器接口</h2><figure class="highlight java"><table><tr><td class="code"><pre><span class="line"><span class="keyword">public</span> <span class="class"><span class="keyword">interface</span> <span class="title">HandlerInterceptor</span> </span>&#123;</span><br><span class="line">    <span class="function"><span class="keyword">boolean</span> <span class="title">preHandle</span><span class="params">(HttpServletRequest var1, HttpServletResponse var2, Object var3)</span> <span class="keyword">throws</span> Exception</span>;</span><br><span class="line"> </span><br><span class="line">    <span class="function"><span class="keyword">void</span> <span class="title">postHandle</span><span class="params">(HttpServletRequest var1, HttpServletResponse var2, Object var3, ModelAndView var4)</span> <span class="keyword">throws</span> Exception</span>;</span><br><span class="line"> </span><br><span class="line">    <span class="function"><span class="keyword">void</span> <span class="title">afterCompletion</span><span class="params">(HttpServletRequest var1, HttpServletResponse var2, Object var3, Exception var4)</span> <span class="keyword">throws</span> Exception</span>;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<ol>
<li>preHandle：</li>
</ol>
<ul>
<li>预处理回调方法，实现处理器的预处理（如登录检查），第三个参数为响应的处理器（如Controller实现）；</li>
<li>返回值：true表示继续流程（如调用下一个拦截器或处理器）；false表示流程中断（如登录检查失败），不会继续调用其他的拦截器或处理器，此时我们需要通过response来产生响应。</li>
</ul>
<ol start="2">
<li>postHandle：后处理回调方法，实现处理器的后处理（但在渲染视图之前），此时我们可以通过modelAndView（模型和视图对象）对模型数据进行处理或对视图进行处理，modelAndView也可能为null。</li>
<li>afterCompletion：整个请求处理完毕回调方法，即在视图渲染完毕时回调，如性能监控中我们可以在此记录结束时间并输出消耗时间，还可以进行一些资源清理，类似于try-catch-finally中的finally，但仅调用处理器执行链中preHandle返回true的拦截器的afterCompletion。</li>
</ol>
<h2 id="拦截器适配器"><a href="#拦截器适配器" class="headerlink" title="拦截器适配器"></a>拦截器适配器</h2><p>有时候我们可能只需要实现三个回调方法中的某一个，如果实现HandlerInterceptor接口的话，三个方法必须实现，不管你需不需要，此时spring提供了一个HandlerInterceptorAdapter适配器（一种适配器设计模式的实现），允许我们只实现需要的回调方法。</p>
<figure class="highlight java"><table><tr><td class="code"><pre><span class="line"><span class="keyword">public</span> <span class="keyword">abstract</span> <span class="class"><span class="keyword">class</span> <span class="title">HandlerInterceptorAdapter</span> <span class="keyword">implements</span> <span class="title">AsyncHandlerInterceptor</span> </span>&#123;</span><br><span class="line">    <span class="function"><span class="keyword">public</span> <span class="title">HandlerInterceptorAdapter</span><span class="params">()</span> </span>&#123;</span><br><span class="line">    &#125;</span><br><span class="line"> </span><br><span class="line">    <span class="function"><span class="keyword">public</span> <span class="keyword">boolean</span> <span class="title">preHandle</span><span class="params">(HttpServletRequest request, HttpServletResponse response, Object handler)</span> <span class="keyword">throws</span> Exception </span>&#123;</span><br><span class="line">        <span class="keyword">return</span> <span class="keyword">true</span>;</span><br><span class="line">    &#125;</span><br><span class="line"> </span><br><span class="line">    <span class="function"><span class="keyword">public</span> <span class="keyword">void</span> <span class="title">postHandle</span><span class="params">(HttpServletRequest request, HttpServletResponse response, Object handler, ModelAndView modelAndView)</span> <span class="keyword">throws</span> Exception </span>&#123;</span><br><span class="line">    &#125;</span><br><span class="line"> </span><br><span class="line">    <span class="function"><span class="keyword">public</span> <span class="keyword">void</span> <span class="title">afterCompletion</span><span class="params">(HttpServletRequest request, HttpServletResponse response, Object handler, Exception ex)</span> <span class="keyword">throws</span> Exception </span>&#123;</span><br><span class="line">    &#125;</span><br><span class="line"> </span><br><span class="line">    <span class="function"><span class="keyword">public</span> <span class="keyword">void</span> <span class="title">afterConcurrentHandlingStarted</span><span class="params">(HttpServletRequest request, HttpServletResponse response, Object handler)</span> <span class="keyword">throws</span> Exception </span>&#123;</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<h2 id="运行流程图"><a href="#运行流程图" class="headerlink" title="运行流程图"></a>运行流程图</h2><h3 id="正常流程"><a href="#正常流程" class="headerlink" title="正常流程"></a>正常流程</h3><p><img src="/img/%E6%AD%A3%E5%B8%B8%E6%B5%81%E7%A8%8B.png" alt="正常流程"></p>
<h3 id="中断流程"><a href="#中断流程" class="headerlink" title="中断流程"></a>中断流程</h3><p><img src="/img/%E4%B8%AD%E6%96%AD%E6%B5%81%E7%A8%8B.png" alt="中断流程"></p>
<p>中断流程中，比如是HandlerInterceptor4中断的流程（preHandle返回false），此处仅调用它之前拦截器的preHandle返回true的afterCompletion方法。</p>
<h2 id="参考"><a href="#参考" class="headerlink" title="参考"></a>参考</h2><p><a href="http://jinnianshilongnian.iteye.com/blog/1670856" target="_blank" rel="noopener">http://jinnianshilongnian.iteye.com/blog/1670856</a></p>
]]></content>
      <categories>
        <category>技术</category>
        <category>Spring</category>
      </categories>
      <tags>
        <tag>Spring</tag>
      </tags>
  </entry>
  <entry>
    <title>详解CMS垃圾回收机制</title>
    <url>/2016/04/23/%E8%AF%A6%E8%A7%A3CMS%E5%9E%83%E5%9C%BE%E5%9B%9E%E6%94%B6%E6%9C%BA%E5%88%B6/</url>
    <content><![CDATA[<h2 id="什么是CMS？"><a href="#什么是CMS？" class="headerlink" title="什么是CMS？"></a>什么是CMS？</h2><p>Concurrent Mark Sweep。<br>看名字就知道，CMS是一款并发、使用标记-清除算法的gc。<br>CMS是针对老年代进行回收的GC。</p>
<a id="more"></a>
<h2 id="CMS有什么用？"><a href="#CMS有什么用？" class="headerlink" title="CMS有什么用？"></a>CMS有什么用？</h2><p>CMS以获取最小停顿时间为目的。<br>在一些对响应时间有很高要求的应用或网站中，用户程序不能有长时间的停顿，CMS 可以用于此场景。</p>
<h2 id="CMS如何执行？"><a href="#CMS如何执行？" class="headerlink" title="CMS如何执行？"></a>CMS如何执行？</h2><p>总体来说CMS的执行过程可以分为以下几个阶段：  </p>
<h3 id="初始标记"><a href="#初始标记" class="headerlink" title="初始标记"></a>初始标记</h3><p>初始标记阶段需要STW(Stop The World)。<br>该阶段进行可达性分析，标记GC ROOT能直接关联到的对象。<br>注意是<strong>直接关联</strong>,间接关联的对象在下一阶段标记。</p>
<h3 id="并发标记"><a href="#并发标记" class="headerlink" title="并发标记"></a>并发标记</h3><p>此阶段是和用户线程并发执行的过程。<br>该阶段进行GC ROOT TRACING，在第一个阶段被暂停的线程重新开始运行。<br>由前阶段标记过的对象出发，所有可到达的对象都在本阶段中标记。</p>
<h3 id="并发预清理"><a href="#并发预清理" class="headerlink" title="并发预清理"></a>并发预清理</h3><p>并发预处理阶段做的工作还是标记，与3.4的重标记功能相似。<br>既然相似为什么要有这一步？<br>前面我们讲过，CMS是以获取最短停顿时间为目的的GC。<br>重标记需要STW，因此重标记的工作尽可能多的在并发阶段完成来减少STW的时间。<br>此阶段标记<strong>从新生代晋升的对象、新分配到老年代的对象</strong>以及在<strong>并发阶段被修改了的对象</strong>。</p>
<hr>
<p>此阶段比较复杂，从大家容易忽略或者说不理解的地方抛出一个问题大家思考下：<br>  ● <strong>如何确定老年代的对象是活着的？</strong><br>答案很简单，通过GC ROOT TRACING可到达的对象就是活着的。<br>继续延伸，如果存在以下场景怎么办：<br><img src="/2016/04/23/详解CMS垃圾回收机制/new_reference_old.png" title="new reference old">   </p>
<p>老年代进行GC时如何确保上图中Current Obj标记为活着的？<br>（确认新生代的对象是活着的也存在相同问题，大家可以思考下，文章后面会给出答案）<br> 答案是必须扫描新生代来确保。<strong>这也是为什么CMS虽然是老年代的gc，但仍要扫描新生代的原因</strong>。(注意初始标记也会扫描新生代)<br>在CMS日志中我们可以清楚地看到扫描日志：</p>
<blockquote>
<p>[GC[YG occupancy: 820 K (6528 K)]<br>[Rescan (parallel) , 0.0024157 secs]<br>[weak refs processing, 0.0000143 secs]<br>[scrub string table, 0.0000258 secs]<br>[1 CMS-remark: 479379K(515960K)] 480200K(522488K), 0.0025249 secs]<br>[Times: user=0.01 sys=0.00, real=0.00 secs]<br>Rescan阶段(remark阶段的一个子阶段)会扫描新生代和老年代中的对象。在日志中可以看到此阶段标识为Rescan (parallel)，说明此阶段是并行进行的。</p>
</blockquote>
<p><strong>重点来了：全量的扫描新生代和老年代会不会很慢？</strong>肯定会。<br>CMS号称是停顿时间最短的GC，如此长的停顿时间肯定是不能接受的。<br>如何解决呢？<br>大家可以先思考下。</p>
<p><strong>必须要有一个能够快速识别新生代和老年代活着的对象的机制。</strong><br><strong>先说新生代。</strong><br>新生代垃圾回收完剩下的对象全是活着的，并且活着的对象很少。<br><strong>如果在扫描新生代前进行一次Minor GC，情况是不是就变得好很多？</strong><br>CMS 有两个参数：<strong>CMSScheduleRemarkEdenSizeThreshold</strong>、<strong>CMSScheduleRemarkEdenPenetration</strong>，默认值分别是2M、50%。两个参数组合起来的意思是预清理后，eden空间使用超过2M时启动可中断的并发预清理（CMS-concurrent-abortable-preclean），直到eden空间使用率达到50%时中断，进入remark阶段。<br>如果能在可中止的预清理阶段发生一次Minor GC,那就万事大吉、天下太平了。<br>这里有一个小问题,<strong>可终止的预清理要执行多长时间来保证发生一次Minor GC?</strong><br>答案是没法保证。道理很简单，因为垃圾回收是JVM自动调度的,什么时候进行GC我们控制不了。<br>但此阶段总有一个执行时间吧？是的。<br>CMS提供了一个参数<strong>CMSMaxAbortablePrecleanTime</strong> ，默认为5S。<br>只要到了5S，不管发没发生Minor GC，有没有到CMSScheduleRemardEdenPenetration都会中止此阶段，进入remark。<br>如果在5S内还是没有执行Minor GC怎么办？<br>CMS提供CMSScavengeBeforeRemark参数，使remark前强制进行一次Minor GC。<br>这样做利弊都有。好的一面是减少了remark阶段的停顿时间;坏的一面是Minor GC后紧跟着一个remark pause。如此一来，停顿时间也比较久。<br>CMS日志如下：</p>
<blockquote>
<p>7688.150: [CMS-concurrent-preclean-start]<br>7688.186: [CMS-concurrent-preclean: 0.034/0.035 secs]<br>7688.186: [CMS-concurrent-abortable-preclean-start]<br>7688.465: [GC 7688.465: [ParNew: 1040940K-&gt;1464K(1044544K), 0.0165840 secs] 1343593K-&gt;304365K(2093120K),<br>0.0167509 secs]7690.093: [CMS-concurrent-abortable-preclean: 1.012/1.907 secs]  7690.095: [GC[YG occupancy: 522484 K (1044544 K)]<br>7690.095: [Rescan (parallel) , 0.3665541 secs]7690.462: [weak refs processing, 0.0003850 secs] [1 CMS-remark: 302901K(1048576K)] 825385K(2093120K), 0.3670690 secs]</p>
</blockquote>
<p><strong>7688.186启动了可终止的预清理，在随后的三秒内启动了Minor GC，然后进入了Remark阶段.</strong><br>实际上为了减少remark阶段的STW时间，预清理阶段会尽可能多做一些事情来减少remark停顿时间。<br>remark的rescan阶段是多线程的，为了便于多线程扫描新生代，<strong>预清理阶段会将新生代分块</strong>。<br>每个块中存放着多个对象，这样remark阶段就不需要从头开始识别每个对象的起始位置。<br>多个线程的职责就很明确了，把分块分配给多个线程，很快就扫描完。<br>遗憾的是，这种办法仍然是建立在发生了Minor GC的条件下。<br>如果没有发生Minor GC，top（下一个可以分配的地址空间）以下的所有空间被认为是一个块(这个块包含了新生代大部分内容)。<br>这种块对于remark阶段并不会起到多少作用，因此并行效率也会降低。</p>
<hr>
<p><strong>ok，新生代的机制讲完了，下面讲讲老年代</strong>。<br>老年代的机制与一个叫<strong>CARD TABLE</strong>的东西（这个东西其实就是个数组,数组中每个位置存的是一个byte）密不可分。<br>CMS将老年代的空间分成大小为512bytes的块，card table中的每个元素对应着一个块。<br>并发标记时，如果某个对象的引用发生了变化，就标记该对象所在的块为<strong> dirty card</strong>。<br>并发预清理阶段就会重新扫描该块，将该对象引用的对象标识为可达。<br>举个例子：<br>并发标记时对象的状态：<br><img src="/2016/04/23/详解CMS垃圾回收机制/concurrent_mark.png" title="concurrent mark"></p>
<p><strong>但随后current obj的引用发生了变化：</strong><br><img src="/2016/04/23/详解CMS垃圾回收机制/referrence_changed.png" title="referrence changed"> </p>
<p>current obj所在的块被标记为了dirty card。<br>随后到了pre-cleaning阶段，还记得该阶段的任务之一就是标记这些在并发标记阶段被修改了的对象么？之后那些通过current obj变得可达的对象也被标记了，变成下面这样：<br><img src="/2016/04/23/详解CMS垃圾回收机制/dirty_card.png" title="dirty card"></p>
<p>同时dirty card标志也被清除。<br>老年代的机制就是这样。<br><strong>不过card table还有其他作用</strong>。<br>还记得前面提到的那个问题么？进行Minor GC时,如果有老年代引用新生代，怎么识别？<br>(有研究表明，在所有的引用中，老年代引用新生代这种场景不足1%.原因大家可以自己分析下)<br>当有老年代引用新生代，对应的card table被标识为相应的值（card table中是一个byte，有八位，约定好每一位的含义就可区分哪个是引用新生代，哪个是并发标记阶段修改过的）。<br><strong>所以，Minor GC通过扫描card table就可以很快的识别老年代引用新生代</strong>。<br>这里提一下，hotspot 虚拟机使用字节码解释器、JIT编译器、 write barrier维护 card table。<br>当字节码解释器或者JIT编译器更新了引用，就会触发write barrier操作card table.<br>再提一下，由于card table的存在，当老年代空间很大时会发生什么？（这里大家可以自由发挥想象）<br>至此，预清理阶段的工作讲完。</p>
<h3 id="重标记-STW"><a href="#重标记-STW" class="headerlink" title="重标记(STW)"></a>重标记(STW)</h3><p>暂停所有用户线程，重新扫描堆中的对象，进行可达性分析,标记活着的对象。<br>有了前面的基础，这个阶段的工作量被大大减轻，停顿时间因此也会减少。<br>注意这个阶段是多线程的。</p>
<h3 id="并发清理。"><a href="#并发清理。" class="headerlink" title="并发清理。"></a>并发清理。</h3><p>用户线程被重新激活，同时清理那些无效的对象。</p>
<h3 id="重置"><a href="#重置" class="headerlink" title="重置"></a>重置</h3><p>CMS清除内部状态，为下次回收做准备。 </p>
<hr>
<p>CMS执行过程讲完了，重点讲解了并发预清理时的操作及CMS几个关键参数。你们可以消化一下，消化完了可以休息一下，因为事情还没结束。</p>
<h2 id="CMS有什么问题"><a href="#CMS有什么问题" class="headerlink" title="CMS有什么问题"></a>CMS有什么问题</h2><p>every coin has two sides ——高中英语作文我经常用的一句话。<br>在我看来，<strong>CMS这三个字母就隐含了问题所在。并发+标记-清除算法 是问题的来源。</strong> </p>
<h3 id="并发"><a href="#并发" class="headerlink" title="并发"></a>并发</h3><h4 id="抢占CPU"><a href="#抢占CPU" class="headerlink" title="抢占CPU"></a>抢占CPU</h4><p>并发意味着多线程抢占CPU资源，即GC线程与用户线程抢占CPU。这可能会造成用户线程执行效率下降。<br>CMS默认的回收线程数是<strong>(CPU个数+3)/4</strong>。这个公式的意思是当CPU大于4个时,保证回收线程占用至少25%的CPU资源，这样用户线程占用75%的CPU，这是可以接受的。<br>但是，如果CPU资源很少，比如只有两个的时候怎么办？按照上面的公式，CMS会启动1个GC线程。相当于GC线程占用了50%的CPU资源，这就可能导致用户程序的执行速度忽然降低了50%，50%已经是很明显的降低了。<br>这种场景怎么处理呢？<br>我给的答案是可以不用考虑这种场景。现在的PC机中都至少有双核处理器，更别说大型的服务器了。<br>CMS的解决方案是提供了一个 incremental mode（增量模式）。<br>在这种模式下，进行并发标记、清理时让GC线程、用户线程交替运行，尽量减少GC线程独占CPU资源的时间。<br>这会造成GC时间更长，但对用户线程造成的影响就会少一些。<br>但实践证明，这种模式下CMS的表现很一般，并没有什么大的优化。<br>i-CMS已经被声明为“deprecated”，不再提倡使用。<br>(<a href="https://docs.oracle.com/javase/8/docs/technotes/guides/vm/gctuning/cms.html#concurrent_mark_sweep_cms_collector" target="_blank" rel="noopener">https://docs.oracle.com/javase/8/docs/technotes/guides/vm/gctuning/cms.html#concurrent_mark_sweep_cms_collector</a>)</p>
<h4 id="浮动垃圾"><a href="#浮动垃圾" class="headerlink" title="浮动垃圾"></a>浮动垃圾</h4><p>并发清理阶段用户线程还在运行，这段时间就可能产生新的垃圾，新的垃圾在此次GC无法清除，只能等到下次清理。这些垃圾有个专业名词：浮动垃圾。<br>由于垃圾回收阶段用户线程仍在执行，必需预留出内存空间给用户线程使用。因此不能像其他回收器那样，等到老年代满了再进行GC。<br>CMS 提供了CMSInitiatingOccupancyFraction参数来设置老年代空间使用百分比,达到百分比就进行垃圾回收。<br>这个参数默认是92%，参数选择需要看具体的应用场景。<br>设置的太小会导致频繁的CMS GC，产生大量的停顿；反过来想，设置的太高会发生什么？<br>假设现在设置为99%，还剩1%的空间可以使用。<br>在并发清理阶段，若用户线程需要使用的空间大于1%，就会产生Concurrent  Mode Failure错误，意思就是说并发模式失败。<br>这时，虚拟机就会启动备案：使用Serial Old收集器重新对老年代进行垃圾回收.如此一来，停顿时间变得更长。<br>所以CMSInitiatingOccupancyFraction的设置要具体问题具体分析。<br>网上有一些设置此参数的公式，个人认为不是很严谨(原因就是CMS另外一个问题导致的),因此不写出来以免大家疑惑。</p>
<p>其实CMS有动态检查机制。<br>CMS会根据历史记录，预测老年代还需要多久填满及进行一次回收所需要的时间。<br>在老年代空间用完之前，CMS可以根据自己的预测自动执行垃圾回收。<br>这个特性可以使用参数UseCMSInitiatingOccupancyOnly来关闭。</p>
<p>这里提个问题，如果让你设计，<strong>如何预测什么时候开始自动执行</strong>？</p>
<h3 id="标记-清除"><a href="#标记-清除" class="headerlink" title="标记-清除"></a>标记-清除</h3><p>4.3 前两个问题是由并发引起的，接下来要说的问题就是由标记-清除算法引起的。<br>使用标记-清除算法可能造成大量的空间碎片。空间碎片过多，就会给大对象分配带来麻烦。<br>往往老年代还有很大剩余空间，但无法找到足够大的连续空间来分配当前对象,不得不触发一次Full GC。<br>CMS的解决方案是使用UseCMSCompactAtFullCollection参数(默认开启)，在顶不住要进行Full GC时开启内存碎片整理。<br>这个过程需要STW，碎片问题解决了,但停顿时间又变长了。<br>虚拟机还提供了另外一个参数CMSFullGCsBeforeCompaction，用于设置执行多少次不压缩的Full GC后，跟着来一次带压缩的（默认为0，每次进入Full GC时都进行碎片整理）。<br>延伸一个“foreground collector”的东西给大家，这个玩意在Java8中也声明为deprecated。(<a href="https://bugs.openjdk.java.net/browse/JDK-8027132" target="_blank" rel="noopener">https://bugs.openjdk.java.net/browse/JDK-8027132</a>)<br>CMS存在的问题已经讲清楚，大家消化下。</p>
<hr>
<p>至此，CMS相关内容已经讲完。</p>
<h2 id="总结"><a href="#总结" class="headerlink" title="总结"></a>总结</h2><p><strong>CMS采用了多种方式尽可能降低GC的暂停时间,减少用户程序停顿</strong>。<br><strong>停顿时间降低的同时牺牲了CPU吞吐量</strong> 。<br><strong>这是在停顿时间和性能间做出的取舍，可以简单理解为”空间(性能)”换时间</strong>。</p>
<p>文中提到的几个问题大家可以把自己当成设计者来思考。</p>
<h2 id="参考资料"><a href="#参考资料" class="headerlink" title="参考资料"></a>参考资料</h2><p><a href="https://docs.oracle.com/javase/8/docs/technotes/guides/vm/gctuning/cms.html#concurrent_mark_sweep_cms_collector" target="_blank" rel="noopener">https://docs.oracle.com/javase/8/docs/technotes/guides/vm/gctuning/cms.html#concurrent_mark_sweep_cms_collector</a><br><a href="https://blogs.oracle.com/jonthecollector/entry/did_you_know" target="_blank" rel="noopener">https://blogs.oracle.com/jonthecollector/entry/did_you_know</a><br><a href="http://dept.cs.williams.edu/~freund/cs434/hotspot-gc.pdf" target="_blank" rel="noopener">http://dept.cs.williams.edu/~freund/cs434/hotspot-gc.pdf</a><br><a href="https://plumbr.eu/handbook/garbage-collection-algorithms-implementations" target="_blank" rel="noopener">https://plumbr.eu/handbook/garbage-collection-algorithms-implementations</a><br><a href="https://blogs.msdn.microsoft.com/abhinaba/2009/03/02/back-to-basics-generational-garbage-collection/" target="_blank" rel="noopener">https://blogs.msdn.microsoft.com/abhinaba/2009/03/02/back-to-basics-generational-garbage-collection/</a><br><a href="https://bugs.openjdk.java.net/browse/JDK-8027132" target="_blank" rel="noopener">https://bugs.openjdk.java.net/browse/JDK-8027132</a><br>《深入理解Java虚拟机 JVM高级特性与最佳实践》</p>
]]></content>
      <categories>
        <category>技术</category>
        <category>JAVA</category>
      </categories>
      <tags>
        <tag>JAVA</tag>
        <tag>CMS</tag>
      </tags>
  </entry>
</search>
